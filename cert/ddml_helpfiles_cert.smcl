{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:39:49
{txt}
{com}. log close
      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:39:49
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:39:49

Help file: ddml_example_partial_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:39:49
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear model - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros, set the seed and initialize the model.
Use 2-fold cross-fitting with two repetitions (resamples)
Use {help pystacked}'s default learners as the supervised learners: OLS, cross-validated lasso, and gradient boosting.
NB: The model specification and results will be stored on a Mata object
with the default name "m0".{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D e401

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42

{input}. ddml init partial, kfolds(2) reps(2)
{res}
{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (826.611)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (856.397)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494  (916.573)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7017.494  (916.980)

{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020


{pstd}Replicate the {opt ddml estimate} results for the 1st cross-fit estimation (resample 1) by hand,
using the estimated conditional expectations generated by {opt ddml} and {help pystacked};
"_1" means resample 1.
Compare using {opt ddml estimate, replay}.{p_end}

{input}. cap drop Yresid

{input}. cap drop Dresid

{input}. gen double Yresid = $Y - Y1_pystacked_1

{input}. gen double Dresid = $D - D1_pystacked_1

{input}. regress Yresid Dresid

{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}     9,915
{txt}{hline 13}{c +}{hline 34}   F(1, 9913)      = {res}    64.79
{txt}       Model {c |} {res} 8.6027e+10         1  8.6027e+10   {txt}Prob > F        ={res}    0.0000
{txt}    Residual {c |} {res} 1.3163e+13     9,913  1.3278e+09   {txt}R-squared       ={res}    0.0065
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}    0.0064
{txt}       Total {c |} {res} 1.3249e+13     9,914  1.3364e+09   {txt}Root MSE        =   {res}  36439

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 6653.485{col 26}{space 2} 826.6108{col 37}{space 1}    8.05{col 46}{space 3}0.000{col 54}{space 4}  5033.16{col 67}{space 3} 8273.811
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} 3.896799{col 26}{space 2} 365.9536{col 37}{space 1}    0.01{col 46}{space 3}0.992{col 54}{space 4}-713.4466{col 67}{space 3} 721.2402
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{input}. ddml estimate, mname(m0) spec(st) rep(1) notable replay
{res}
{txt}Stacking DDML model (sample=1)
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6653.485{col 26}{space 2} 826.6108{col 37}{space 1}    8.05{col 46}{space 3}0.000{col 54}{space 4} 5033.358{col 67}{space 3} 8273.613
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} 3.896799{col 26}{space 2} 365.9536{col 37}{space 1}    0.01{col 46}{space 3}0.992{col 54}{space 4} -713.359{col 67}{space 3} 721.1526
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1


{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:40:22

Help file: ddml_example_partial_pystacked_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:40:22
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear model - Detailed example with stacking regression using {help pystacked}}

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D e401

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42


{pstd}We next initialize the ddml estimation and select the model.
{it:partial} refers to the partially linear model.
The model will be stored on a Mata object with the default name "m0"
unless otherwise specified using the {opt mname(name)} option.{p_end}

{pstd}We set the number of random folds to 2 so that 
the model runs quickly. The default is {opt kfolds(5)}. We recommend 
considering at least 5-10 folds and even more if your sample size is small.{p_end}

{pstd}We recommend re-running the model multiple times on 
different random folds; see options {opt reps(integer)}.
Here we set the number of repetions to 2, again only so that the model runs quickly.{p_end}

{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}Stacking regression is a simple and powerful method for 
combining predictions from multiple learners.
Here we use {help pystacked} with the partially linear model,
but it can be used with any model supported by {cmd:ddml}.{p_end}

{pstd}Note: the additional support provided by {opt ddml} for {help pystacked} (see {help ddml##pystacked:above})
is available only if, as in this example, {help pystacked} is the only learner for each conditional expectation.
Mutliple learners are provided to {help pystacked}, not directly to {opt ddml}.

{pstd}Add supervised machine learners for estimating conditional expectations.
The first learner in the stacked ensemble is OLS.
We also use cross-validated lasso, ridge and two random forests with different settings, 
which we save in the following macros:{p_end}

{input}. global rflow max_features(5) min_samples_leaf(1) max_samples(.7)

{input}. global rfhigh max_features(5) min_samples_leaf(10) max_samples(.7)


{input}. ddml E[Y|X]: pystacked $Y $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner D1_pystacked added successfully.


{pstd}Note: Options before ":" and after the first comma refer to {cmd:ddml}. 
Options that come after the final comma refer to the estimation command. 
Make sure to not confuse the two types of options.{p_end}

{pstd}Check if learners were correctly added:{p_end}

{input}. ddml desc, learners
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt(max_features(5) min_samples_leaf(1) max_samples(.7)) || method(rf) opt(max_features(5) min_samples_leaf(10) max_samples(.7)), type(reg)
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt(max_features(5) min_samples_leaf(1) max_samples(.7)) || method(rf) opt(max_features(5) min_samples_leaf(10) max_samples(.7)), type(reg)


{pstd} Cross-fitting: The learners are iteratively fitted on the training data.
This step may take a while, depending on the number of learners, repetitions, folds, etc.
In addition to the standard stacking done by {help pystacked},
also request short-stacking to be done by {opt ddml}.
Whereas stacking relies on (out-of-sample) cross-validated predicted values
to obtain the relative weights for the base learners,
short-stacking uses the (out-of-sample) cross-fitted predicted values.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}

{pstd}Finally, we estimate the coefficients of interest.{p_end}

{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  7455.326  (947.699)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7451.662  (937.660)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7024.078  (918.991)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7159.673  (887.218)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7239.702  (957.628)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7305.668  (923.048)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7239.702  (958.036)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7305.668  (924.390)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7305.668{col 26}{space 2} 924.3896{col 37}{space 1}    7.90{col 46}{space 3}0.000{col 54}{space 4} 5493.898{col 67}{space 3} 9117.438
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7305.6677 7159.6733 7159.6733 7305.6677 7451.6621 7451.6621


{pstd}Examine the standard ({cmd:pystacked}) stacking weights as well as the {opt ddml} short-stacking weights.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .10215168    .07857077    .12573259
{txt}lassocv {res}           2    .25006817    .27612194    .22401441
{txt}ridgecv {res}           3    .00009901    5.472e-19    .00019802
{txt}     rf {res}           4    3.351e-17    5.107e-18    6.192e-17
{txt}     rf {res}           5    .64768114     .6453073    .65005498
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .12927046     .1525836    .10595731
{txt}lassocv {res}           2    .02219836            0    .04439672
{txt}ridgecv {res}           3    .13196658    .06929693    .19463623
{txt}     rf {res}           4    .73034407    .83795984    .62272829
{txt}     rf {res}           5    .04457685            0     .0891537
{reset}{res}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .00136454    .00272908    5.696e-18
{txt}lassocv {res}           2    .00003223    .00006446            0
{txt}ridgecv {res}           3    .28865826    .28855704    .28875948
{txt}     rf {res}           4    3.876e-17    7.286e-17    4.662e-18
{txt}     rf {res}           5    .70994496    .70864941    .71124052
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .11180479    .07224495    .15136463
{txt}lassocv {res}           2            0            0            0
{txt}ridgecv {res}           3            0            0            0
{txt}     rf {res}           4    .88819521    .92775505    .84863537
{txt}     rf {res}           5            0            0            0
{reset}{res}

{pstd}Replicate the {opt ddml estimate} short-stacking results for resample 2 by hand,
using the estimated conditional expectations generated by {opt ddml},
and compare using {opt ddml estimate, replay}:{p_end}

{input}. cap drop Yresid

{input}. cap drop Dresid

{input}. gen double Yresid = $Y - Y_net_tfa_ss_2

{input}. gen double Dresid = $D - D_e401_ss_2

{input}. regress Yresid Dresid, robust

{txt}Linear regression                               Number of obs     = {res}     9,915
                                                {txt}F(1, 9913)        =  {res}    65.12
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.0080
                                                {txt}Root MSE          =    {res}  35262

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 7159.673{col 26}{space 2} 887.2183{col 37}{space 1}    8.07{col 46}{space 3}0.000{col 54}{space 4} 5420.545{col 67}{space 3} 8898.802
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-286.1348{col 26}{space 2} 354.2125{col 37}{space 1}   -0.81{col 46}{space 3}0.419{col 54}{space 4}-980.4633{col 67}{space 3} 408.1936
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{input}. ddml estimate, mname(m0) spec(ss) rep(2) notable replay
{res}
{txt}Shortstack DDML model (sample=2)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss_2{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss_2 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7159.673{col 26}{space 2} 887.2183{col 37}{space 1}    8.07{col 46}{space 3}0.000{col 54}{space 4} 5420.757{col 67}{space 3} 8898.589
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-286.1348{col 26}{space 2} 354.2125{col 37}{space 1}   -0.81{col 46}{space 3}0.419{col 54}{space 4}-980.3785{col 67}{space 3} 408.1088
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{pstd}Obtain the estimated coefficient using ridge - the 3rd {help pystacked} learner - 
as the only learner for the 2nd cross-fit estimation (resample 2),
using the estimated conditional expectations generated by {opt ddml} and {help pystacked}.
This can be done using {opt ddml estimate} with the {opt y(.)} and {opt d(.)} options:
"L3" means the 3rd learner and "_2" means resample 2.
Then replicate by hand.{p_end}

{input}. ddml estimate, y(Y1_pystacked_L3_2) d(D1_pystacked_L3_2) robust
{res}
{txt}y-E[y|X]{col 11}= {res}Y1_pystacked_L3_2{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D1_pystacked_L3_2
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 4941.948{col 26}{space 2} 1075.687{col 37}{space 1}    4.59{col 46}{space 3}0.000{col 54}{space 4}  2833.64{col 67}{space 3} 7050.256
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-11.61225{col 26}{space 2} 394.8504{col 37}{space 1}   -0.03{col 46}{space 3}0.977{col 54}{space 4}-785.5048{col 67}{space 3} 762.2803
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{input}. cap drop Yresid

{input}. cap drop Dresid

{input}. gen double Yresid = $Y - Y1_pystacked_L3_2

{input}. gen double Dresid = $D - D1_pystacked_L3_2

{input}. regress Yresid Dresid, robust

{txt}Linear regression                               Number of obs     = {res}     9,915
                                                {txt}F(1, 9913)        =  {res}    21.11
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.0032
                                                {txt}Root MSE          =    {res}  39313

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 4941.948{col 26}{space 2} 1075.687{col 37}{space 1}    4.59{col 46}{space 3}0.000{col 54}{space 4} 2833.382{col 67}{space 3} 7050.513
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-11.61225{col 26}{space 2} 394.8504{col 37}{space 1}   -0.03{col 46}{space 3}0.977{col 54}{space 4}-785.5993{col 67}{space 3} 762.3748
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:41:24

Help file: ddml_example_partial_anylearner_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:41:24
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear model - Detailed general example with multiple learners} 

{pstd}Here we used {opt ddml} to add learners. This allows use of learners not supported by,
or as alternatives to, those available via {help pystacked}.
It is also possible to use {help pystacked} as a standalone learner in this way.{p_end}

{pstd}Preparation: load the data and define the globals.
Use the name "m1" for this new estimation, 
to distinguish it from any model estimated previously that uses the default name "m0".
This enables having multiple estimations available for comparison.
Also specify 5 resamplings.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D e401

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42

{input}. ddml init partial, kfolds(2) reps(5) mname(m1)
{res}

{pstd}We add supervised machine learners for estimating the conditional 
expectation E[Y|X].
In each step, we add the {opt mname(m1)} option to ensure that the learners
are added to correct model.
We also specify the names of the variables containing the estimated conditional
expectations using the {opt learner(varname)} option.
This avoids overwriting any variables created some other model using default naming.{p_end}

{pstd} We first add simple linear regression.{p_end}

{input}. ddml E[Y|X], mname(m1) learner(Y_m1_reg): reg $Y $X
{res}{txt}Learner Y_m1_reg added successfully.


{pstd}We can add more than one learner per reduced form equation. Here, we 
add a random forest learner. We do this using {help pystacked} to implement a single learner.{p_end}

{input}. ddml E[Y|X], mname(m1) learner(Y_m1_pys): pystacked $Y $X, type(reg) method(rf)
{res}{txt}Learner Y_m1_pys added successfully.


{pstd}We do the same for the conditional expectation E[D|X].{p_end}

{input}. ddml E[D|X], mname(m1) learner(D_m1_reg): reg $D $X
{res}{txt}Learner D_m1_reg added successfully.

{input}. ddml E[D|X], mname(m1) learner(D_m1_pys): pystacked $D $X, type(reg) method(rf)
{res}{txt}Learner D_m1_pys added successfully.


{pstd}Check if learners were correctly added:{p_end}

{input}. ddml desc, mname(m1) learners
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y_m1_reg Y_m1_pys
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D_m1_reg D_m1_pys

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y_m1_reg
{col 15}est cmd: reg net_tfa tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}Y_m1_pys
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D_m1_reg
{col 15}est cmd: reg e401 tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}D_m1_pys
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)


{pstd}Cross-fitting and estimation.
Since we added two learners for each of our two reduced form equations, 
there are four possible specifications. 
By default, the result shown corresponds to the specification 
with the lowest out-of-sample MSPE:{p_end}

{input}. ddml crossfit, mname(m1)
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate, mname(m1) robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y_m1_reg Y_m1_pys
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D_m1_reg D_m1_pys

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(mse) rep(1) notable replay: mse  1}{res}      Y_m1_pys      D_m1_reg  6934.059 (1115.680)
{stata ddml estimate, mname(m1) spec(mse) rep(2) notable replay: mse  2}      Y_m1_pys      D_m1_reg  7568.943  (961.984)
{stata ddml estimate, mname(m1) spec(mse) rep(3) notable replay: mse  3}      Y_m1_pys      D_m1_reg  6763.292  (938.991)
{stata ddml estimate, mname(m1) spec(mse) rep(4) notable replay: mse  4}      Y_m1_pys      D_m1_reg  6696.469 (1001.911)
{stata ddml estimate, mname(m1) spec(mse) rep(5) notable replay: mse  5}      Y_m1_pys      D_m1_reg  6410.047 (1113.142)
{txt}mse = minimum MSE specification for that resample.

Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(mse) rep(mn) notable replay: mse mn}     {res}[min-mse]     [min-mse]  6874.562 (1080.461)
{stata ddml estimate, mname(m1) spec(mse) rep(md) notable replay: mse md}     [min-mse]     [min-mse]  6763.292 (1128.673)

{txt}Median over 5 min-mse resamples
y-E[y|X]{col 11}= {res}y-Y_m1_pys{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_m1_reg 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6763.292{col 26}{space 2} 1128.673{col 37}{space 1}    5.99{col 46}{space 3}0.000{col 54}{space 4} 4551.134{col 67}{space 3}  8975.45
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 6874.5621 6410.0474 6696.4688 6763.2920 6934.0591 7568.9434


{pstd}To estimate all four specifications, we use the {cmd:allcombos} option:{p_end}

{input}. ddml estimate, mname(m1) robust allcombos
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y_m1_reg Y_m1_pys
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D_m1_reg D_m1_pys

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{res} {stata ddml estimate, mname(m1) spec(1) rep(1) notable replay:  1  1}      Y_m1_reg      D_m1_reg  5397.208 (1130.776)
 {stata ddml estimate, mname(m1) spec(2) rep(1) notable replay:  2  1}      Y_m1_reg      D_m1_pys  6651.343  (892.371)
*{stata ddml estimate, mname(m1) spec(3) rep(1) notable replay:  3  1}      Y_m1_pys      D_m1_reg  6934.059 (1115.680)
 {stata ddml estimate, mname(m1) spec(4) rep(1) notable replay:  4  1}      Y_m1_pys      D_m1_pys  6948.286  (773.032)
 {stata ddml estimate, mname(m1) spec(1) rep(2) notable replay:  1  2}      Y_m1_reg      D_m1_reg  4941.948 (1075.687)
 {stata ddml estimate, mname(m1) spec(2) rep(2) notable replay:  2  2}      Y_m1_reg      D_m1_pys  6429.783  (920.446)
*{stata ddml estimate, mname(m1) spec(3) rep(2) notable replay:  3  2}      Y_m1_pys      D_m1_reg  7568.943  (961.984)
 {stata ddml estimate, mname(m1) spec(4) rep(2) notable replay:  4  2}      Y_m1_pys      D_m1_pys  7049.313  (843.588)
 {stata ddml estimate, mname(m1) spec(1) rep(3) notable replay:  1  3}      Y_m1_reg      D_m1_reg  5054.250 (1082.173)
 {stata ddml estimate, mname(m1) spec(2) rep(3) notable replay:  2  3}      Y_m1_reg      D_m1_pys  6201.805  (873.064)
*{stata ddml estimate, mname(m1) spec(3) rep(3) notable replay:  3  3}      Y_m1_pys      D_m1_reg  6763.292  (938.991)
 {stata ddml estimate, mname(m1) spec(4) rep(3) notable replay:  4  3}      Y_m1_pys      D_m1_pys  6282.347  (769.125)
 {stata ddml estimate, mname(m1) spec(1) rep(4) notable replay:  1  4}      Y_m1_reg      D_m1_reg  4496.728 (1113.339)
 {stata ddml estimate, mname(m1) spec(2) rep(4) notable replay:  2  4}      Y_m1_reg      D_m1_pys  6305.684  (919.015)
*{stata ddml estimate, mname(m1) spec(3) rep(4) notable replay:  3  4}      Y_m1_pys      D_m1_reg  6696.469 (1001.911)
 {stata ddml estimate, mname(m1) spec(4) rep(4) notable replay:  4  4}      Y_m1_pys      D_m1_pys  6914.925  (874.286)
 {stata ddml estimate, mname(m1) spec(1) rep(5) notable replay:  1  5}      Y_m1_reg      D_m1_reg  5264.462 (1097.929)
 {stata ddml estimate, mname(m1) spec(2) rep(5) notable replay:  2  5}      Y_m1_reg      D_m1_pys  6231.522  (929.780)
*{stata ddml estimate, mname(m1) spec(3) rep(5) notable replay:  3  5}      Y_m1_pys      D_m1_reg  6410.047 (1113.142)
 {stata ddml estimate, mname(m1) spec(4) rep(5) notable replay:  4  5}      Y_m1_pys      D_m1_pys  6310.288  (813.804)
*{txt} = minimum MSE specification for that resample.

Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(mse) rep(mn) notable replay: mse mn}     {res}[min-mse]     [min-mse]  6874.562 (1080.461)
{stata ddml estimate, mname(m1) spec(mse) rep(md) notable replay: mse md}     [min-mse]     [min-mse]  6763.292 (1128.673)

{txt}Median over 5 min-mse resamples
y-E[y|X]{col 11}= {res}y-Y_m1_pys{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_m1_reg 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6763.292{col 26}{space 2} 1128.673{col 37}{space 1}    5.99{col 46}{space 3}0.000{col 54}{space 4} 4551.134{col 67}{space 3}  8975.45
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 6874.5621 6410.0474 6696.4688 6763.2920 6934.0591 7568.9434


{pstd}After having estimated all specifications, we can retrieve 
specific results. Here we use the specification relying on OLS for both
estimating both E[Y|X] and E[D|X], from the 4th cross-fit split ({opt rep(4))}.
(Note: Working interactively, the simplest way to do this
is to click on the hyperlink in the summary table in the {opt ddml estimate} output above.)
The {opt notable} option suppresses the summary table:{p_end}

{input}. ddml estimate, mname(m1) spec(1) rep(4) replay notable
{res}
{txt}DDML model, specification 1 (sample=4)
y-E[y|X]{col 11}= {res}y-Y_m1_reg_4{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_m1_reg_4 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 4496.728{col 26}{space 2} 1113.339{col 37}{space 1}    4.04{col 46}{space 3}0.000{col 54}{space 4} 2314.623{col 67}{space 3} 6678.834
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-41.08484{col 26}{space 2} 399.6619{col 37}{space 1}   -0.10{col 46}{space 3}0.918{col 54}{space 4}-824.4078{col 67}{space 3} 742.2381
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}


{pstd}You could manually retrieve the same point estimate by 
cacluating the orthogonalized versions of {opt net_tfa} and {opt e401}
from the 4th cross-fit estimation and then using {help regress}:{p_end}

{input}. cap drop Yresid

{input}. cap drop Dresid

{input}. gen double Yresid = $Y - Y_m1_reg_4

{input}. gen double Dresid = $D - D_m1_reg_4

{input}. regress Yresid Dresid

{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}     9,915
{txt}{hline 13}{c +}{hline 34}   F(1, 9913)      = {res}    25.49
{txt}       Model {c |} {res} 4.0358e+10         1  4.0358e+10   {txt}Prob > F        ={res}    0.0000
{txt}    Residual {c |} {res} 1.5695e+13     9,913  1.5833e+09   {txt}R-squared       ={res}    0.0026
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}    0.0025
{txt}       Total {c |} {res} 1.5735e+13     9,914  1.5872e+09   {txt}Root MSE        =   {res}  39790

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 4496.728{col 26}{space 2} 890.6476{col 37}{space 1}    5.05{col 46}{space 3}0.000{col 54}{space 4} 2750.878{col 67}{space 3} 6242.579
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-41.08484{col 26}{space 2} 399.6034{col 37}{space 1}   -0.10{col 46}{space 3}0.918{col 54}{space 4}-824.3887{col 67}{space 3}  742.219
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}

{pstd}You can also compare the estimated conditional expectations graphically:{p_end}

{input}. twoway (scatter $Y Y_m1_pys_4) 
{res}

{pstd}To describe the ddml model setup or results in detail,
you can use {cmd: ddml describe} with the relevant option ({opt sample}, {opt learners}, {opt crossfit}, {opt estimates}),
or just describe them all with the {opt all} option:{p_end}

{input}. ddml describe, mname(m1) all
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y_m1_reg Y_m1_pys
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D_m1_reg D_m1_pys
{txt}Specifications:{col 25}{res}4 possible specs * 5 crossfit splits = 20

{txt}ID:{col 25}{res}m1_id
{txt}Full sample indic.:{col 25}{res}m1_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m1_fid_1    m1_fid_2    m1_fid_3    m1_fid_4    m1_fid_5  
{txt}Fold sample indic.:{col 25}{res}m1_sample_1 m1_sample_2 m1_sample_3 m1_sample_4 m1_sample_5 
{txt}Estimation N:{col 25}    {res}9915        9915        9915        9915        9915    

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y_m1_reg
{col 15}est cmd: reg net_tfa tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}Y_m1_pys
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D_m1_reg
{col 15}est cmd: reg e401 tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}D_m1_pys
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}

{txt}Median over 5 min-mse resamples
y-E[y|X]{col 11}= {res}y-Y_m1_pys{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_m1_reg 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6763.292{col 26}{space 2} 1128.673{col 37}{space 1}    5.99{col 46}{space 3}0.000{col 54}{space 4} 4551.134{col 67}{space 3}  8975.45
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 6874.5621 6410.0474 6696.4688 6763.2920 6934.0591 7568.9434


{pstd}If there is a previously-estimated {opt ddml} model called "m0",
we can load it using {opt ddml estimate} with the {opt mname(m0)} and {opt replay} options and compare.{p_end}

{input}. ddml estimate, mname(m0) replay
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}{res}  Y1_pystacked  D1_pystacked  7451.662  (937.660)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7451.662  (937.660)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  Y1_pystacked  D1_pystacked  7159.673  (887.218)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7159.673  (887.218)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}{res}  Y1_pystacked  D1_pystacked  7305.668  (923.048)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7305.668  (923.048)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  Y1_pystacked  D1_pystacked  7305.668  (924.390)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7305.668  (924.390)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7305.668{col 26}{space 2} 924.3896{col 37}{space 1}    7.90{col 46}{space 3}0.000{col 54}{space 4} 5493.898{col 67}{space 3} 9117.438
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7305.6677 7159.6733 7159.6733 7305.6677 7451.6621 7451.6621

{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:42:14

Help file: ddml_example_partial_pystacked_multitreat.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:42:14
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear model - Multiple treatments with {help pystacked}}

{pstd}We can also run the partially-linear model with multiple treatments. 
In this simple example, we estimate the effect of both 401k elligibility 
{cmd:e401} and education {cmd:educ}. 
Note that we remove {cmd:educ} from the set of controls.
We again use {help pystacked} as the single learner provided to {opt ddml};
the two base learners, OLS and random forest, are provided via {help pystacked}.
We use the simplified syntax supported by {help pystacked}.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D1 e401

{input}. global D2 educ

{input}. global X tw age inc fsize db marr twoearn pira hown

{input}. set seed 42


{pstd}Initialize the model.{p_end}

{input}. ddml init partial, kfolds(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}Add learners. Note that we add learners with both {cmd:$D1} and
{cmd:$D2} as the dependent variable.{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) methods(ols rf)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D1 $X, type(reg) methods(ols rf)
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D2 $X, type(reg) methods(ols rf)
{res}{txt}Learner D2_pystacked added successfully.


{pstd}Cross-fitting.{p_end}

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: educ
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}

{pstd}Estimation.{p_end}

{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (2):{col 25}{res}e401 educ
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked
{txt}{col 2}educ learners:{col 25}{res}D2_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6575.235 (1011.846)  D2_pystacked   -13.817  (180.738)

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D1-D1_pystacked_1 D2-D2_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6575.235{col 26}{space 2} 1011.846{col 37}{space 1}    6.50{col 46}{space 3}0.000{col 54}{space 4} 4592.054{col 67}{space 3} 8558.416
{txt}{space 8}educ {c |}{col 14}{res}{space 2}-13.81744{col 26}{space 2}  180.738{col 37}{space 1}   -0.08{col 46}{space 3}0.939{col 54}{space 4}-368.0574{col 67}{space 3} 340.4225
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-225.6904{col 26}{space 2} 357.6214{col 37}{space 1}   -0.63{col 46}{space 3}0.528{col 54}{space 4}-926.6154{col 67}{space 3} 475.2347
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{pstd}Because we have used {help pystacked} as the single {opt ddml} learner,
we can access the saved {opt pystacked} information.
Here we use the {opt pystacked} option to get the stacking weights and MSEs by cross-fit fold:{p_end}

{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for D1_pystacked (e401)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  .72587155  .71142712
{txt} rf {res}         2          1  .27412845  .28857288
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}         learner  mean_weight        rep_1
ols {res}           1    .71864934    .71864934
{txt} rf {res}           2    .28135066    .28135066
{reset}
{res}pystacked MSEs for D1_pystacked (e401)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1   .2050931  .19752967
{txt} rf {res}         2          1  .21760044  .20899576
{reset}
{res}mean stacking MSEs across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}       learner   mean_MSE      rep_1
ols {res}         1  .20131139  .20131139
{txt} rf {res}         2   .2132981   .2132981
{reset}
{res}pystacked weights for D2_pystacked (educ)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  .56766281  .62100559
{txt} rf {res}         2          1  .43233719  .37899441
{reset}
{res}mean stacking weights across folds/resamples for D2_pystacked (educ)
{res}final stacking estimator: nnls1
{txt}         learner  mean_weight        rep_1
ols {res}           1     .5943342     .5943342
{txt} rf {res}           2     .4056658     .4056658
{reset}
{res}pystacked MSEs for D2_pystacked (educ)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  6.1283809  5.9179008
{txt} rf {res}         2          1  6.2683575  6.1781066
{reset}
{res}mean stacking MSEs across folds/resamples for D2_pystacked (educ)
{res}final stacking estimator: nnls1
{txt}       learner   mean_MSE      rep_1
ols {res}         1  6.0231408  6.0231408
{txt} rf {res}         2  6.2232321  6.2232321
{reset}
{res}pystacked weights for Y1_pystacked (net_tfa)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  .52681726   .2326513
{txt} rf {res}         2          1  .47318274   .7673487
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}         learner  mean_weight        rep_1
ols {res}           1    .37973428    .37973428
{txt} rf {res}           2    .62026572    .62026572
{reset}
{res}pystacked MSEs for Y1_pystacked (net_tfa)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  1.524e+09  1.558e+09
{txt} rf {res}         2          1  1.553e+09  1.224e+09
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}       learner   mean_MSE      rep_1
ols {res}         1  1.541e+09  1.541e+09
{txt} rf {res}         2  1.388e+09  1.388e+09
{reset}{res}
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:43:25

Help file: ddml_example_interactive_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:43:25
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Interactive model - Basic example with {help pystacked}}{p_end}

{pstd}We need to estimate the conditional expectations of E[Y|X,D=0], E[Y|X,D=1] and E[D|X].
The first two conditional expectations are added jointly.
We use 5 cross-fit folds and 2 resamplings
(more resamplings would be advisable; we use 2 in this example so the code runs faster).
We specify two supervised learners: linear regression and gradient boosted
trees, stacked using {help pystacked}.
We use {help pystacked}'s 2nd syntax and stack using the single-best learner
(rather than the default constrained least squares).
Note that we use gradient boosted regression trees for E[Y|X,D],
but gradient boosted classification trees for E[D|X].{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)

{input}. global Y bweight

{input}. global D mbsmoke

{input}. global X prenatal1 mmarried fbaby mage medu

{input}. set seed 42

{input}. ddml init interactive, kfolds(5) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. ddml E[Y|X,D]: pystacked $Y $X || method(ols) || method(gradboost) || , type(reg) finalest(singlebest)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X || method(logit) || method(gradboost) || , type(class) finalest(singlebest)
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}

{pstd}{opt ddml estimate} reports the ATE (average treatment effect) by default:{p_end}

{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -207.548   (32.276)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -212.145   (29.030)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -209.846   (30.612)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -209.846   (30.782)

{txt}Median over 2 stacking resamples (ATE)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-209.8464{col 26}{space 2} 30.78171{col 37}{space 1}   -6.82{col 46}{space 3}0.000{col 54}{space 4}-270.1774{col 67}{space 3}-149.5154
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}singlebest
Warning{txt}: 2 resamples had propensity scores trimmed to lower limit .01.

Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -209.8464 -212.1452 -212.1452 -209.8464 -207.5476 -207.5476


{pstd}Request the ATET (average treatment effect on the treated) instead:{p_end}

{input}. ddml estimate, atet
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATET):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -234.766   (24.667)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -231.387   (25.228)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -233.077   (25.000)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -233.077   (25.006)

{txt}Median over 2 stacking resamples (ATET)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-233.0769{col 26}{space 2} 25.00582{col 37}{space 1}   -9.32{col 46}{space 3}0.000{col 54}{space 4}-282.0874{col 67}{space 3}-184.0664
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}singlebest
Warning{txt}: 2 resamples had propensity scores trimmed to lower limit .01.

Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -233.0769 -234.7664 -234.7664 -233.0769 -231.3873 -231.3873

{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:44:09

Help file: ddml_example_interactive_pystacked_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:44:09
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Interactive model - Detailed example with {help pystacked}}{p_end}

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)

{input}. global Y bweight

{input}. global D mbsmoke

{input}. global X prenatal1 mmarried fbaby mage medu

{input}. set seed 42


{pstd}We use 5 folds and 5 resamplings; that is, 
we estimate the model 5 times using randomly chosen folds.{p_end}

{input}. ddml init interactive, kfolds(5) reps(5)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}We need to estimate the conditional expectations of E[Y|X,D=0], 
E[Y|X,D=1] and E[D|X]. The first two conditional expectations 
are added jointly.{p_end} 
{pstd}We consider two supervised learners: linear regression and gradient boosted
trees, stacked using {helpb pystacked}.
Note that we use gradient boosted regression trees for E[Y|X,D], but
gradient boosted classification trees for E[D|X].{p_end}

{input}. ddml E[Y|X,D]: pystacked $Y $X, type(reg) methods(ols gradboost)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X, type(class) methods(logit gradboost)
{res}{txt}Learner D1_pystacked added successfully.


{pstd}Cross-fitting and short-stacking:{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}

{pstd}In the final estimation step, we can estimate
the average treatment effect (the default),
the average treatment effect on the treated ({opt atet}),
or the average treatment effect on the untreated ({opt ateu}).{p_end}

{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.583   (26.027)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]  -216.277   (26.756)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.967   (25.586)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]          [ss]  -218.975   (25.913)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -227.103   (26.256)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]          [ss]  -225.686   (26.477)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -221.207   (25.830)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]          [ss]  -221.029   (26.590)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -224.497   (25.840)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]          [ss]  -222.705   (26.775)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -222.672   (26.045)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}  [shortstack]          [ss]          [ss]  -220.934   (26.685)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -221.207   (26.049)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  [shortstack]          [ss]          [ss]  -221.029   (26.828)

{txt}Shortstack DDML model (median over 5 resamples) (ATE)
E[y|X,D=0]{col 14}= {res}Y_bweight_ss0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y_bweight_ss1
{txt}E[D|X]{col 14}= {res}D_mbsmoke_ss
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-221.0291{col 26}{space 2}  26.8275{col 37}{space 1}   -8.24{col 46}{space 3}0.000{col 54}{space 4}  -273.61{col 67}{space 3}-168.4481
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -220.9344 -225.6861 -222.7047 -221.0291 -218.9749 -216.2772

{input}. ddml estimate, atet
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATET):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -228.281   (23.768)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]  -230.567   (23.983)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -226.403   (24.073)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]          [ss]  -227.182   (24.275)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -235.118   (23.866)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]          [ss]  -235.587   (23.948)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -233.333   (23.664)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]          [ss]  -235.966   (23.885)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -230.264   (23.649)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]          [ss]  -231.205   (23.924)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -230.680   (24.010)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}  [shortstack]          [ss]          [ss]  -232.101   (24.222)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -230.264   (23.862)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  [shortstack]          [ss]          [ss]  -231.205   (24.346)

{txt}Shortstack DDML model (median over 5 resamples) (ATET)
E[y|X,D=0]{col 14}= {res}Y_bweight_ss0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y_bweight_ss1
{txt}E[D|X]{col 14}= {res}D_mbsmoke_ss
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-231.2049{col 26}{space 2} 24.34589{col 37}{space 1}   -9.50{col 46}{space 3}0.000{col 54}{space 4} -278.922{col 67}{space 3}-183.4878
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -232.1014 -235.9659 -235.5873 -231.2049 -230.5669 -227.1821

{input}. ddml estimate, ateu
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATEU):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -217.251   (28.232)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]  -212.719   (29.192)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.203   (27.646)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]          [ss]  -216.588   (28.080)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -225.630   (28.379)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]          [ss]  -223.817   (28.658)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -218.507   (27.799)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]          [ss]  -217.692   (28.808)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -223.173   (27.779)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]          [ss]  -220.725   (29.005)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.753   (28.132)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}  [shortstack]          [ss]          [ss]  -218.308   (28.977)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.203   (28.061)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  [shortstack]          [ss]          [ss]  -217.692   (29.163)

{txt}Shortstack DDML model (median over 5 resamples) (ATEU)
E[y|X,D=0]{col 14}= {res}Y_bweight_ss0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y_bweight_ss1
{txt}E[D|X]{col 14}= {res}D_mbsmoke_ss
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-217.6923{col 26}{space 2} 29.16286{col 37}{space 1}   -7.46{col 46}{space 3}0.000{col 54}{space 4}-274.8504{col 67}{space 3}-160.5341
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -218.3081 -223.8169 -220.7247 -217.6923 -216.5880 -212.7186


{pstd}Recall that we have specified 5 resampling iterations ({opt reps(5)})
By default, the median over short-stacked resampling iterations is shown.
At the bottom, a table of summary statistics over resampling iterations is shown. 
To display the mean over standard stacking results, i.e.,
the results where the weights derive from {helpb pystacked} and vary by cross-fit fold,
we use {opt ddml estimate, replay} with {opt spec(st)} and {opt rep(mn)}.{p_end}

{input}. ddml estimate, spec(st) rep(mn) notable replay
{res}
{txt}Mean over 5 stacking resamples (ATEU)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-220.7528{col 26}{space 2}  28.1325{col 37}{space 1}   -7.85{col 46}{space 3}0.000{col 54}{space 4}-275.8914{col 67}{space 3}-165.6141
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -220.7528 -225.6302 -223.1726 -219.2034 -218.5068 -217.2508


{pstd}Generate an overlap plot using {opt ddml overlap}:{p_end}

{input}. ddml overlap
{res}

{pstd}Report the standard stacking and short-stacking weights:{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for Y1_pystacked (bweight)
{res}final stacking estimator: nnls1
{txt}               learner        D=0/1  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1            0    .96570242     .9999956    .96016968    .97196735    .95501857    .94136089
{txt}gradboost {res}           2            0    .03429267    3.982e-11    .03983032    .02802434    .04496957    .05863911
{txt}      ols {res}           1            1    .94773816    .95897886    .97302404    .94535865    .92548652    .93584273
{txt}gradboost {res}           2            1    .05226184    .04102114    .02697596    .05464135    .07451348    .06415727
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (mbsmoke)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
    logit {res}           1    .26469509    .27914461    .25411088    .25036705    .25768503    .28216788
{txt}gradboost {res}           2    .73530491    .72085539    .74588912    .74963295    .74231497    .71783212
{reset}{res}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for bweight
{res}final stacking estimator: nnls1
{txt}               learner        D=0/1  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1            0    .98382895            1            1    .99892026     .9202245            1
{txt}gradboost {res}           2            0    .01617105            0            0    .00107974     .0797755    4.591e-17
{txt}      ols {res}           1            1    .89125977    .84721895    .85802465    .91334299    .95738422    .88032805
{txt}gradboost {res}           2            1    .10874023    .15278105    .14197535    .08665701    .04261578    .11967195
{reset}
{res}short-stacked weights across resamples for mbsmoke
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
    logit {res}           1    .18611935     .1780141    .20142045    .21745899     .1598537     .1738495
{txt}gradboost {res}           2    .81388065     .8219859    .79857955    .78254101     .8401463     .8261505
{reset}{res}
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:46:23

Help file: ddml_example_partialiv_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:46:23
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear IV model - Basic example with {help pystacked}} 

{pstd}The model has three conditional expectations: E[Y|X], E[D|X] and E[Z|X].
For each reduced form equation, we use {help pystacked}'s default learners: 
OLS, cross-validated lasso, and gradient boosting.
Since the data set is very small, we consider 30 cross-fitting folds.
NB: The model specification and results will be stored on a Mata object
with the default name "m0".{p_end}

{input}. use https://statalasso.github.io/dta/AJR.dta, clear

{input}. global Y logpgp95

{input}. global D avexpr

{input}. global Z logem4

{input}. global X lat_abst edes1975 avelf temp* humid* steplow-oilres

{input}. set seed 42

{input}. ddml init iv, kfolds(30)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml E[Z|X]: pystacked $Z $X
{res}{txt}Learner Z1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: logpgp95
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: avexpr
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[Z|X]: logem4
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}iv, crossfit folds k=30, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}logpgp95
{txt}{col 2}logpgp95 learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}avexpr
{txt}{col 2}avexpr learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}logem4
{txt}{col 2}logem4 learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked     2.376    (2.826)  Z1_pystacked

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z1_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2}  2.37577{col 26}{space 2} 2.826037{col 37}{space 1}    0.84{col 46}{space 3}0.401{col 54}{space 4}-3.163161{col 67}{space 3} 7.914701
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .1790394{col 26}{space 2} .5070894{col 37}{space 1}    0.35{col 46}{space 3}0.724{col 54}{space 4}-.8148375{col 67}{space 3} 1.172916
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{pstd}Replicate the {opt ddml estimate} results for the 1st cross-fit estimation (resample 1) by hand,
using the estimated conditional expectations generated by {opt ddml} and {help pystacked};
"_1" means resample 1.
Compare using {opt ddml estimate, replay}.{p_end}

{input}. cap drop Yresid

{input}. cap drop Dresid

{input}. cap drop Zresid

{input}. gen double Yresid = $Y - Y1_pystacked_1

{input}. gen double Dresid = $D - D1_pystacked_1

{input}. gen double Zresid = $Z - Z1_pystacked_1

{input}. ivreg Yresid (Dresid=Zresid)

{txt}Instrumental variables (2SLS) regression

      Source {c |}       SS           df       MS      Number of obs   ={res}        64
{txt}{hline 13}{c +}{hline 34}   F(1, 62)        = {res}     0.71
{txt}       Model {c |} {res}-701.578378         1 -701.578378   {txt}Prob > F        ={res}    0.4038
{txt}    Residual {c |} {res} 738.231487        62  11.9069595   {txt}R-squared       ={res}         .
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}         .
{txt}       Total {c |} {res} 36.6531083        63  .581795369   {txt}Root MSE        =   {res} 3.4506

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2}  2.37577{col 26}{space 2} 2.826037{col 37}{space 1}    0.84{col 46}{space 3}0.404{col 54}{space 4}-3.273398{col 67}{space 3} 8.024938
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .1790394{col 26}{space 2} .5070894{col 37}{space 1}    0.35{col 46}{space 3}0.725{col 54}{space 4}-.8346178{col 67}{space 3} 1.192697
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{p 0 15 43}Instrumented:{space 2}Dresid{p_end}
{p 0 15 43}Instruments:{space 3}Zresid{p_end}
{hline 78}

{input}. ddml estimate, mname(m0) spec(st) rep(1) notable replay
{res}
{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z1_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2}  2.37577{col 26}{space 2} 2.826037{col 37}{space 1}    0.84{col 46}{space 3}0.401{col 54}{space 4}-3.163161{col 67}{space 3} 7.914701
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .1790394{col 26}{space 2} .5070894{col 37}{space 1}    0.35{col 46}{space 3}0.724{col 54}{space 4}-.8148375{col 67}{space 3} 1.172916
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:48:51

Help file: ddml_example_partialiv_anylearner_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:48:51
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear IV model - Basic example with various learners} 

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. use https://statalasso.github.io/dta/AJR.dta, clear

{input}. global Y logpgp95

{input}. global D avexpr

{input}. global Z logem4

{input}. global X lat_abst edes1975 avelf temp* humid* steplow-oilres

{input}. set seed 42


{pstd}Preparation: we load the data, define global macros and set the seed. Since the
data set is very small, we consider 30 cross-fitting folds.{p_end}

{input}. ddml init iv, kfolds(30)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}The partially linear IV model has three conditional expectations: 
E[Y|X], E[D|X] and E[Z|X]. For each reduced form equation, we use two learners:
OLS and random forest.
To illustrate how {opt ddml} works with other packages,
instead of a single call to {opt pystacked} specifying two base learners
we specify Stata's {help regress} and {help rforest} by Zou and Schonlau as the two learners.
We need to add the option {opt vtype(none)} for {help rforest} to 
work with {cmd:ddml} since {help rforest}'s {cmd:predict} command doesn't
support variable types.{p_end}

{input}. ddml E[Y|X]: reg $Y $X
{res}{txt}Learner Y1_reg added successfully.

{input}. ddml E[Y|X], vtype(none): rforest $Y $X, type(reg)
{res}{txt}Learner Y2_rforest added successfully.

{input}. ddml E[D|X]: reg $D $X
{res}{txt}Learner D1_reg added successfully.

{input}. ddml E[D|X], vtype(none): rforest $D $X, type(reg)
{res}{txt}Learner D2_rforest added successfully.

{input}. ddml E[Z|X]: reg $Z $X
{res}{txt}Learner Z1_reg added successfully.

{input}. ddml E[Z|X], vtype(none): rforest $Z $X, type(reg)
{res}{txt}Learner Z2_rforest added successfully.


{pstd}Cross-fitting and estimation; report all combinations of estimated conditional expectations.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: logpgp95
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: avexpr
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[Z|X]: logem4
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting...completed short-stacking
{res}
{input}. ddml estimate, robust allcombos
{res}

{txt}Model:{col 25}{res}iv, crossfit folds k=30, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}logpgp95
{txt}{col 2}logpgp95 learners:{col 25}{res}Y1_reg Y2_rforest
{txt}D equations (1):{col 25}{res}avexpr
{txt}{col 2}avexpr learners:{col 25}{res}D1_reg D2_rforest
{txt}Z equations (1):{col 25}{res}logem4
{txt}{col 2}logem4 learners:{col 25}{res}Z1_reg Z2_rforest

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      Z learner
{res} {stata ddml estimate, mname(m0) spec(1) rep(1) notable replay:  1  1}        Y1_reg        D1_reg     0.378    (0.125)        Z1_reg
 {stata ddml estimate, mname(m0) spec(2) rep(1) notable replay:  2  1}        Y1_reg        D1_reg    -0.187    (1.573)    Z2_rforest
 {stata ddml estimate, mname(m0) spec(3) rep(1) notable replay:  3  1}        Y1_reg    D2_rforest     2.413    (3.594)        Z1_reg
 {stata ddml estimate, mname(m0) spec(4) rep(1) notable replay:  4  1}        Y1_reg    D2_rforest     0.083    (0.475)    Z2_rforest
 {stata ddml estimate, mname(m0) spec(5) rep(1) notable replay:  5  1}    Y2_rforest        D1_reg     0.123    (0.207)        Z1_reg
 {stata ddml estimate, mname(m0) spec(6) rep(1) notable replay:  6  1}    Y2_rforest        D1_reg    -1.749    (4.690)    Z2_rforest
 {stata ddml estimate, mname(m0) spec(7) rep(1) notable replay:  7  1}    Y2_rforest    D2_rforest     0.783    (0.504)        Z1_reg
*{stata ddml estimate, mname(m0) spec(8) rep(1) notable replay:  8  1}    Y2_rforest    D2_rforest     0.772    (0.207)    Z2_rforest
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]     0.716    (0.196)          [ss]
*{txt} = minimum MSE specification for that resample.

{res}{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_logpgp95_ss_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D_avexpr_ss_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z_logem4_ss_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2} .7158509{col 26}{space 2} .1958379{col 37}{space 1}    3.66{col 46}{space 3}0.000{col 54}{space 4} .3320156{col 67}{space 3} 1.099686
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0308504{col 26}{space 2} .0914997{col 37}{space 1}   -0.34{col 46}{space 3}0.736{col 54}{space 4}-.2101864{col 67}{space 3} .1484857
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1


	
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:49:02

Help file: ddml_example_flexiv_anylearner_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:49:02
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Flexible partially-linear IV model - Basic example with {help pystacked}}

{pstd}First load the data, define global macros, set the seed and initialize the model.
We add learners for E[Y|X] in the usual way.
We illustrate with single {help pystacked} estimations,
but the procedure applies to all learners.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/BLP.dta, clear

{input}. global Y share

{input}. global D price

{input}. global X hpwt air mpd space

{input}. global Z sum*

{input}. set seed 42

{input}. ddml init fiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}Adding learners for E[Y|X] is the same as for other {opt ddml} linear models:{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg)
{res}{txt}Learner Y1_pystacked added successfully.


{pstd}Adding learners for E[D|Z,X] and E[D|X] in the {opt fiv} model is different
from how it's done in the {opt partialiv} model.
The reason for this is that the estimation of E[D|X]
depends on the estimation of E[D|X,Z].{p_end}

{pstd}When adding learners for E[D|Z,X],
we need to provide a name for each learners using {opt learner(name)}.
Here we use the name "Dhat_pys".{p_end}

{input}. ddml E[D|Z,X], learner(Dhat_pys): pystacked $D $X $Z, type(reg)
{res}{txt}Learner Dhat_pys added successfully.


{pstd}When adding learners for E[D|X], we explicitly refer to the name of the learner from 
the previous step (here, "Dhat_pys").
We also provide the name of the treatment variable ({cmd:vname($D)}),
and we use the placeholder {cmd:{D}} in place of the dependent variable.{p_end}

{input}. ddml E[D|X], learner(Dhat_pys) vname($D): pystacked {D} $X, type(reg)
{res}{txt}Learner Dhat_pys_h added successfully.


{pstd}The crossfit and estimation commands with the {opt fiv} model are standard.{p_end}

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}Dhat_pys

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked      Dhat_pys    -0.098    (0.008)    Dhat_pys_h

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-Dhat_pys_1 
{txt}E[D^|X]{col 11}= {res}Dhat_pys_h_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0079847{col 37}{space 1}  -12.26{col 46}{space 3}0.000{col 54}{space 4} -.113534{col 67}{space 3}-.0822344
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215635{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390072{col 67}{space 3} .0455204
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1


{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:49:37

Help file: ddml_example_flexiv_anylearner_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:49:37
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Flexible partially-linear IV model - Detailed example with {help pystacked}}

{pstd}Here will illustrate how to do standard- and short-stacking with the flexible IV model.{p_end}

{pstd}Note: Support for {help pystacked} integration is relatively limited for the flexible IV model.
In particular, short-stacking requires that individual learners appear in separate {help pystacked} commands,
pooled stacking is not available, and re-stacking with {opt ddml estimate} is also not available.{p_end}

{pstd}First we illustrate how to do standard stacking with {help pystacked}.
To start, we load the data, define global macros, set the seed and initialize the model.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/BLP.dta, clear

{input}. global Y share

{input}. global D price

{input}. global X hpwt air mpd space

{input}. global Z sum*

{input}. set seed 42

{input}. ddml init fiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}Adding learners for E[Y|X] is the same as for other {opt ddml} linear models:{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg)
{res}{txt}Learner Y1_pystacked added successfully.


{pstd}Adding learners for E[D|Z,X] and E[D|X] in the {opt fiv} model is different
from how it's done in the {opt partialiv} model.
The reason for this is that the estimation of E[D|X]
depends on the estimation of E[D|X,Z].{p_end}

{pstd}When adding learners for E[D|Z,X],
we need to provide a name for each learners using {opt learner(name)}.
Here we use the name "Dhat_pys".{p_end}

{input}. ddml E[D|Z,X], learner(Dhat_pys): pystacked $D $X $Z, type(reg)
{res}{txt}Learner Dhat_pys added successfully.


{pstd}When adding learners for E[D|X], we explicitly refer to the name of the learner from 
the previous step (here, "Dhat_pys").
We also provide the name of the treatment variable ({cmd:vname($D)}),
and we use the placeholder {cmd:{D}} in place of the dependent variable.{p_end}

{input}. ddml E[D|X], learner(Dhat_pys) vname($D): pystacked {D} $X, type(reg)
{res}{txt}Learner Dhat_pys_h added successfully.


{pstd}The crossfit and estimation commands with the {opt fiv} model are standard.{p_end}

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}Dhat_pys

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked      Dhat_pys    -0.098    (0.008)    Dhat_pys_h

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-Dhat_pys_1 
{txt}E[D^|X]{col 11}= {res}Dhat_pys_h_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0075085{col 37}{space 1}  -13.04{col 46}{space 3}0.000{col 54}{space 4}-.1126006{col 67}{space 3}-.0831678
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215627{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390055{col 67}{space 3} .0455187
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{pstd}The stacking weights and other results from {help pystacked} are available via {help ddml extract}.
Note this is only the case if {help pystacked} is the single learner in each equation.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for Dhat_pys (price)
{res}final stacking estimator: nnls1
{txt}               learner        h=0/1  mean_weight        rep_1
      ols {res}           1            0    .00029361    .00029361
{txt}  lassocv {res}           2            0    3.869e-16    3.869e-16
{txt}gradboost {res}           3            0    .99970639    .99970639
{txt}      ols {res}           1            1            0            0
{txt}  lassocv {res}           2            1            0            0
{txt}gradboost {res}           3            1            1            1
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1
      ols {res}           1    .01072127    .01072127
{txt}  lassocv {res}           2    .00089782    .00089782
{txt}gradboost {res}           3    .98838092    .98838092
{reset}{res}
{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for Dhat_pys (price)
{txt}             learner          h   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          0          1  .00146806          0          0          0          0
{txt}  lassocv {res}         2          0          1  2.899e-17          0          0  1.905e-15          0
{txt}gradboost {res}         3          0          1  .99853194          1          1          1          1
{txt}      ols {res}         1          1          1          0          0          0          0          0
{txt}  lassocv {res}         2          1          1          0          0          0          0          0
{txt}gradboost {res}         3          1          1          1          1          1          1          1
{reset}
{res}mean stacking weights across folds/resamples for Dhat_pys (price)
{res}final stacking estimator: nnls1
{txt}               learner        h=0/1  mean_weight        rep_1
      ols {res}           1            0    .00029361    .00029361
{txt}  lassocv {res}           2            0    3.869e-16    3.869e-16
{txt}gradboost {res}           3            0    .99970639    .99970639
{txt}      ols {res}           1            1            0            0
{txt}  lassocv {res}           2            1            0            0
{txt}gradboost {res}           3            1            1            1
{reset}
{res}pystacked MSEs for Dhat_pys (price)
{txt}             learner          h   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          0          1  29.117492  28.750566  28.599294  27.609091  27.984089
{txt}  lassocv {res}         2          0          1  29.105272  28.733296  28.611895  27.596867  27.974163
{txt}gradboost {res}         3          0          1  12.489515  11.066737    11.8996  11.454903  11.792511
{txt}      ols {res}         1          1          1  22.708623  21.869205  22.138751  21.559765  22.334953
{txt}  lassocv {res}         2          1          1  22.708698  21.869208   22.13965  21.560209  22.335081
{txt}gradboost {res}         3          1          1  8.5356607  7.7975507  8.9779883  7.6268412   8.967218
{reset}
{res}mean stacking MSEs across folds/resamples for Dhat_pys (price)
{res}final stacking estimator: nnls1
{txt}             learner      h=0/1   mean_MSE      rep_1
      ols {res}         1          0  28.412106  28.412106
{txt}  lassocv {res}         2          0  28.404299  28.404299
{txt}gradboost {res}         3          0  11.740653  11.740653
{txt}      ols {res}         1          1  22.122259  22.122259
{txt}  lassocv {res}         2          1  22.122569  22.122569
{txt}gradboost {res}         3          1  8.3810518  8.3810518
{reset}
{res}pystacked weights for Y1_pystacked (share)
{txt}             learner   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          1          0  9.888e-17  9.565e-19  .04108882  .01251751
{txt}  lassocv {res}         2          1  1.388e-17  2.429e-17  6.072e-17          0  .00448908
{txt}gradboost {res}         3          1          1          1          1  .95891118  .98299341
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1
      ols {res}           1    .01072127    .01072127
{txt}  lassocv {res}           2    .00089782    .00089782
{txt}gradboost {res}           3    .98838092    .98838092
{reset}
{res}pystacked MSEs for Y1_pystacked (share)
{txt}             learner   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          1   1.410348  1.4521883  1.4141429  1.4309885  1.4682377
{txt}  lassocv {res}         2          1  1.4103449  1.4520901  1.4140542  1.4310193  1.4680032
{txt}gradboost {res}         3          1  1.1465506  1.2157637  1.1898038  1.2044167  1.2344672
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}             learner   mean_MSE      rep_1
      ols {res}         1  1.4351811  1.4351811
{txt}  lassocv {res}         2  1.4351023  1.4351023
{txt}gradboost {res}         3  1.1982004  1.1982004
{reset}{res}

{pstd}To replicate what {cmd:ddml} does in the background:{p_end}

{input}. cap drop Ytilde

{input}. cap drop Dtilde

{input}. cap drop Ztilde

{input}. gen double Ytilde = $Y - Y1_pystacked_1

{input}. gen Dtilde = $D - Dhat_pys_h_1

{input}. gen Zopt = Dhat_pys_1 - Dhat_pys_h_1

{input}. ivreg Ytilde (Dtilde=Zopt), robust

{txt}Instrumental variables (2SLS) regression        Number of obs     = {res}     2,217
                                                {txt}F(1, 2215)        =  {res}   169.95
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.1175
                                                {txt}Root MSE          =    {res} 1.0152

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Ytilde{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dtilde {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0075085{col 37}{space 1}  -13.04{col 46}{space 3}0.000{col 54}{space 4}-.1126087{col 67}{space 3}-.0831598
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215627{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390286{col 67}{space 3} .0455418
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{p 0 15 43}Instrumented:{space 2}Dtilde{p_end}
{p 0 15 43}Instruments:{space 3}Zopt{p_end}
{hline 78}


{pstd}Next we illustrate how to do short-stacking with the flexible IV model.
We again use {help pystacked}, but the procedure applies to any set of learners.
Here we use the same learners as in the standard stacking estimation with {help pystacked} above,
in order to facilitate direct comparison of the two sets of results.
We begin by re-initializing the model.{p_end}

{input}. set seed 42

{input}. ddml init fiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}We add learners for E[Y|X] in the usual way,
but we need to specify each {help pystacked} learner in a separate equation.{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) m(ols)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) m(lassocv)
{res}{txt}Learner Y2_pystacked added successfully.

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) m(gradboost)
{res}{txt}Learner Y3_pystacked added successfully.


{pstd}
As above, when adding learners for E[D|Z,X],
we need to provide a name for each learner using {opt learner(name)}.{p_end}

{input}. ddml E[D|Z,X], learner(Dhat_ols): pystacked $D $X $Z, type(reg) m(ols)
{res}{txt}Learner Dhat_ols added successfully.

{input}. ddml E[D|Z,X], learner(Dhat_lassocv): pystacked $D $X $Z, type(reg) m(lassocv)
{res}{txt}Learner Dhat_lassocv added successfully.

{input}. ddml E[D|Z,X], learner(Dhat_gradboost): pystacked $D $X $Z, type(reg) m(gradboost)
{res}{txt}Learner Dhat_gradboost added successfully.


{pstd}Again as above, when adding learners for E[D|X],
we explicitly refer to the learner from the previous step,
the name of the treatment variable ({cmd:vname($D)}),
and the placeholder {cmd:{D}} in place of the dependent variable.{p_end}

{input}. ddml E[D|X], learner(Dhat_ols) vname($D): pystacked {D} $X, type(reg) m(ols)
{res}{txt}Learner Dhat_ols_h added successfully.

{input}. ddml E[D|X], learner(Dhat_lassocv) vname($D): pystacked {D} $X, type(reg) m(lassocv)
{res}{txt}Learner Dhat_lassocv_h added successfully.

{input}. ddml E[D|X], learner(Dhat_gradboost) vname($D): pystacked {D} $X, type(reg) m(gradboost)
{res}{txt}Learner Dhat_gradboost_h added successfully.

 
{pstd}Short-stacking is requested when cross-fitting.
Short-stacking weights can be examined using {help ddml extract}.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting{res}{txt}...completed short-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked Y2_pystacked Y3_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}Dhat_ols Dhat_lassocv Dhat_gradboost

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(mse) rep(1) notable replay: mse  1}{res}  Y3_pystacked Dhat_gradbo~t    -0.098    (0.008) Dhat_gradbo~h
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]    -0.097    (0.007)          [ss]
{txt}mse = minimum MSE specification for that resample.

{res}{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_share_ss_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-D_price_ss_1 
{txt}E[D^|X]{col 11}= {res}D_price_h_ss_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2} -.097427{col 26}{space 2} .0074744{col 37}{space 1}  -13.03{col 46}{space 3}0.000{col 54}{space 4}-.1120765{col 67}{space 3}-.0827775
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0034453{col 26}{space 2} .0215529{col 37}{space 1}    0.16{col 46}{space 3}0.873{col 54}{space 4}-.0387976{col 67}{space 3} .0456882
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1


{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for price
{res}final stacking estimator: nnls1
{txt}                  learner        h=0/1  mean_weight        rep_1
    Dhat_ols {res}           1            0            0            0
{txt}Dhat_lassocv {res}           2            0            0            0
{txt}Dhat_gradb~t {res}           3            0            1            1
{txt}  Dhat_ols_h {res}           1            1            0            0
{txt}Dhat_lasso~h {res}           2            1            0            0
{txt}Dhat_gradb~h {res}           3            1            1            1
{reset}
{res}short-stacked weights across resamples for share
{res}final stacking estimator: nnls1
{txt}                  learner  mean_weight        rep_1
Y1_pystacked {res}           1            0            0
{txt}Y2_pystacked {res}           2            0            0
{txt}Y3_pystacked {res}           3            1            1
{reset}{res}
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:50:24

Help file: ddml_example_interactiveiv_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:50:24
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Interactive IV model (LATE) - Basic example with {help pystacked}}

{pstd}We use {help pystacked} with two base learners for each reduced form equation.{p_end}

{input}. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta, clear

{input}. global Y earnings

{input}. global D training

{input}. global Z assignmt

{input}. global X sex age married black hispanic

{input}. set seed 42

{input}. ddml init interactiveiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. ddml E[Y|X,Z]: pystacked $Y c.($X)# #c($X), type(reg) m(ols lassocv)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X,Z]: pystacked $D c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml E[Z|X]: pystacked $Z c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner Z1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  D1_pystacked  1817.232  (512.772)  Z1_pystacked

{txt}Stacking DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y1_pystacked0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y1_pystacked1_1
{txt}E[D|X,Z=0]{col 14}= {res}D1_pystacked0_1
{txt}E[D|X,Z=1]{col 14}= {res}D1_pystacked1_1
{txt}E[Z|X]{col 14}= {res}Z1_pystacked_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1817.232{col 26}{space 2} 512.7721{col 37}{space 1}    3.54{col 46}{space 3}0.000{col 54}{space 4} 812.2173{col 67}{space 3} 2822.247
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1


{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:53:04

Help file: ddml_example_interactiveiv_pystacked_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:53:04
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Interactive IV model (LATE) - Detailed example with {help pystacked}}

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta, clear

{input}. global Y earnings

{input}. global D training

{input}. global Z assignmt

{input}. global X sex age married black hispanic

{input}. set seed 42


{pstd}We initialize the model.{p_end}

{input}. ddml init interactiveiv, kfolds(5)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}We use {helpb pystacked} with two base learners for each reduced form equation.
Note that E[Y|X,Z] is a regression problem,
whereas E[D|X,Z] and E[Z|X] are classification problems.{p_end}

{input}. ddml E[Y|X,Z]: pystacked $Y c.($X)# #c($X), type(reg) m(ols lassocv)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X,Z]: pystacked $D c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml E[Z|X]: pystacked $Z c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner Z1_pystacked added successfully.


{pstd}Cross-fitting and estimation, with short-stacking implemented via {opt ddml}.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  D1_pystacked  1817.232  (512.772)  Z1_pystacked
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]          [ss]  1818.117  (513.944)          [ss]

{txt}Shortstack DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y_earnings_ss0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y_earnings_ss1_1
{txt}E[D|X,Z=0]{col 14}= {res}D_training_ss0_1
{txt}E[D|X,Z=1]{col 14}= {res}D_training_ss1_1
{txt}E[Z|X]{col 14}= {res}Z_assignmt_ss_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1818.117{col 26}{space 2} 513.9437{col 37}{space 1}    3.54{col 46}{space 3}0.000{col 54}{space 4}  810.806{col 67}{space 3} 2825.428
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{pstd}Compare the short-stacking estimation above with standard (within-cross-fit-fold) stacking:{p_end}

{input}. ddml estimate, spec(st) rep(1) replay notable
{res}
{txt}Stacking DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y1_pystacked0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y1_pystacked1_1
{txt}E[D|X,Z=0]{col 14}= {res}D1_pystacked0_1
{txt}E[D|X,Z=1]{col 14}= {res}D1_pystacked1_1
{txt}E[Z|X]{col 14}= {res}Z1_pystacked_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1817.232{col 26}{space 2} 512.7721{col 37}{space 1}    3.54{col 46}{space 3}0.000{col 54}{space 4} 812.2173{col 67}{space 3} 2822.247
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1



{pstd}Short-stacking is typically considerably faster than standard stacking.
We can estimate using short-stacking only by specifying the {opt nostd} option when cross-fitting.
We re-set the seed for comparability.{p_end}

{input}. set seed 42

{input}. ddml crossfit, shortstack nostdstack
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]          [ss]          [ss]  1814.245  (513.279)          [ss]

{txt}Shortstack DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y_earnings_ss0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y_earnings_ss1_1
{txt}E[D|X,Z=0]{col 14}= {res}D_training_ss0_1
{txt}E[D|X,Z=1]{col 14}= {res}D_training_ss1_1
{txt}E[Z|X]{col 14}= {res}Z_assignmt_ss_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1814.245{col 26}{space 2} 513.2794{col 37}{space 1}    3.53{col 46}{space 3}0.000{col 54}{space 4} 808.2361{col 67}{space 3} 2820.254
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}


{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 10:57:30

Help file: ddml_example_extract.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 10:57:30
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:ddml extract utility: Extracting stored information from ddml associative arrays}

{pstd}The examples below use the partially-linear model
and stacking regression using {helpb pystacked}.
We also request short-stacking.
The model name is the default name "m0".
For simplicity we use {helpb pystacked}'s default learners and settings.
{p_end}

{pstd}Preparation and estimation:{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42

{input}. ddml init partial, kfolds(3) reps(5)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. ddml E[Y|X]: pystacked net_tfa $X, type(reg)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked e401 $X, type(reg)
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=3, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  7971.516 (1157.199)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7467.899 (1059.748)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7103.917  (916.936)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7378.277  (895.972)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  D1_pystacked  7271.315  (928.559)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]  7302.977  (907.828)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  D1_pystacked  6887.581  (916.298)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]  6923.917  (913.388)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  D1_pystacked  6901.912  (896.746)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]  6985.731  (882.863)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7227.248 (1000.026)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7211.760  (949.927)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7103.917  (941.490)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7302.977  (938.132)

{txt}Shortstack DDML model (median over 5 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7302.977{col 26}{space 2}  938.132{col 37}{space 1}    7.78{col 46}{space 3}0.000{col 54}{space 4} 5464.272{col 67}{space 3} 9141.682
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7211.7602 6923.9165 6985.7310 7302.9771 7378.2773 7467.8989


{pstd}{ul:{opt show(something)} option examples}{p_end}

{pstd}{opt show} option examples: report standard (pystacked) and short-stacked weights.
Standard stacking weights displayed here are mean weights across cross-fit folds.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .08153887    .05608768     .0840624    .03251847    .14207861    .09294721
{txt}  lassocv {res}           2    .16367892     .1983422    .17484295    .21455488    .11080118     .1198534
{txt}gradboost {res}           3     .7547822    .74557012    .74109465    .75292665    .74712021     .7871994
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .28747183    .18398986    .36148227     .1103495    .41252374    .36901379
{txt}  lassocv {res}           2    .09613986    .05278333    .13207421    .29583822    1.063e-16    3.567e-06
{txt}gradboost {res}           3    .61858407    .76322682    .51839357    .59381228    .58650496    .63098273
{reset}{res}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .03049847    .15249237            0            0    2.846e-19    2.168e-19
{txt}  lassocv {res}           2    .20329907    .05653283    .23140523     .2290732    .27932792    .22015614
{txt}gradboost {res}           3    .76620246    .79097479    .76859477     .7709268    .72067208    .77984386
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .16952276    .62414185    1.588e-17            0    .22347198    6.647e-11
{txt}  lassocv {res}           2    .16130065            0    .19359176    .21773024    .15214415    .24303708
{txt}gradboost {res}           3    .66917659    .37585815    .80640824    .78226976    .62438388    .75696292
{reset}{res}

{pstd}The {opt show} option leaves results in r(.) macros.{p_end}

{input}. mat list r(Y_net_tfa_ss)
{res}
{txt}r(Y_net_tfa_ss)[3,7]
               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .16952276    .62414185    1.588e-17            0    .22347198    6.647e-11
{txt}  lassocv {res}           2    .16130065            0    .19359176    .21773024    .15214415    .24303708
{txt}gradboost {res}           3    .66917659    .37585815    .80640824    .78226976    .62438388    .75696292
{reset}
{input}. mat list r(D_e401_ss)
{res}
{txt}r(D_e401_ss)[3,7]
               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .03049847    .15249237            0            0    2.846e-19    2.168e-19
{txt}  lassocv {res}           2    .20329907    .05653283    .23140523     .2290732    .27932792    .22015614
{txt}gradboost {res}           3    .76620246    .79097479    .76859477     .7709268    .72067208    .77984386
{reset}

{pstd}{opt show} option examples: examine the learner weights and MSEs by fold reported by {cmd:pystacked}.{p_end}

{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for D1_pystacked (e401)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  .16826304          0          0
{txt}  lassocv {res}         2          1  .13109924  .23961713  .22431024
{txt}gradboost {res}         3          1  .70063771  .76038287  .77568976
{txt}      ols {res}         1          2          0  .24979577  .00239144
{txt}  lassocv {res}         2          2  .26607389          0  .25845497
{txt}gradboost {res}         3          2  .73392611  .75020423  .73915359
{txt}      ols {res}         1          3  .09755541          0  1.084e-18
{txt}  lassocv {res}         2          3  .12368253  .24396537  .27601674
{txt}gradboost {res}         3          3  .77876206  .75603463  .72398326
{txt}      ols {res}         1          4   .1894134  .14721477  .08960765
{txt}  lassocv {res}         2          4  .05381122   .1454022  .13319012
{txt}gradboost {res}         3          4  .75677539  .70738303  .77720222
{txt}      ols {res}         1          5  5.421e-20  .27884163          0
{txt}  lassocv {res}         2          5  .15552757          0  .20403262
{txt}gradboost {res}         3          5  .84447243  .72115837  .79596738
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .08153887    .05608768     .0840624    .03251847    .14207861    .09294721
{txt}  lassocv {res}           2    .16367892     .1983422    .17484295    .21455488    .11080118     .1198534
{txt}gradboost {res}           3     .7547822    .74557012    .74109465    .75292665    .74712021     .7871994
{reset}
{res}pystacked MSEs for D1_pystacked (e401)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  .20351577  .20225882  .19754608
{txt}  lassocv {res}         2          1   .2035348  .20225473    .197507
{txt}gradboost {res}         3          1  .19956581  .19769108  .19215809
{txt}      ols {res}         1          2  .20186788   .2013563  .19981196
{txt}  lassocv {res}         2          2  .20183337  .20137622  .19984606
{txt}gradboost {res}         3          2  .19713729   .1970131  .19555222
{txt}      ols {res}         1          3  .19656056  .20380581  .20229808
{txt}  lassocv {res}         2          3  .19657887  .20370893  .20223549
{txt}gradboost {res}         3          3  .19126091  .19870774   .1983283
{txt}      ols {res}         1          4   .2026485  .20058303   .1998553
{txt}  lassocv {res}         2          4  .20270242  .20057994  .19985482
{txt}gradboost {res}         3          4  .19747921  .19697907  .19476448
{txt}      ols {res}         1          5  .20091221  .19935736  .20305163
{txt}  lassocv {res}         2          5  .20089484  .19935905  .20298434
{txt}gradboost {res}         3          5  .19439272  .19568025   .1972188
{reset}
{res}mean stacking MSEs across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner   mean_MSE      rep_1      rep_2      rep_3      rep_4      rep_5
      ols {res}         1  .20102862  .20110689  .20101204  .20088815  .20102894  .20110707
{txt}  lassocv {res}         2  .20101672  .20109884  .20101855   .2008411  .20104573  .20107941
{txt}gradboost {res}         3  .19626194  .19647166  .19656754  .19609898  .19640759  .19576392
{reset}
{res}pystacked weights for Y1_pystacked (net_tfa)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  .27812564  1.058e-12  .27384393
{txt}  lassocv {res}         2          1          0  .15834998          0
{txt}gradboost {res}         3          1  .72187436  .84165002  .72615607
{txt}      ols {res}         1          2  .48876223          0  .59568458
{txt}  lassocv {res}         2          2  1.308e-17  .39622264          0
{txt}gradboost {res}         3          2  .51123777  .63962752  .40431542
{txt}      ols {res}         1          3  .33104848  4.487e-16  3.292e-08
{txt}  lassocv {res}         2          3  5.876e-14   .1875602  .69995446
{txt}gradboost {res}         3          3  .66895152   .8124398  .30004551
{txt}      ols {res}         1          4  .43531108  .39610026  .40615988
{txt}  lassocv {res}         2          4  3.182e-16  7.860e-19          0
{txt}gradboost {res}         3          4  .56468892  .60389974  .59092621
{txt}      ols {res}         1          5  .41850968   .4982584  .19027328
{txt}  lassocv {res}         2          5  1.305e-11          0   .0000107
{txt}gradboost {res}         3          5  .58149032  .50174186  .80971602
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .28747183    .18398986    .36148227     .1103495    .41252374    .36901379
{txt}  lassocv {res}           2    .09613986    .05278333    .13207421    .29583822    1.063e-16    3.567e-06
{txt}gradboost {res}           3    .61858407    .76322682    .51839357    .59381228    .58650496    .63098273
{reset}
{res}pystacked MSEs for Y1_pystacked (net_tfa)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  1.626e+09  1.495e+09  1.520e+09
{txt}  lassocv {res}         2          1  1.627e+09  1.495e+09  1.519e+09
{txt}gradboost {res}         3          1  1.385e+09  1.098e+09  1.272e+09
{txt}      ols {res}         1          2  1.623e+09  1.522e+09  1.673e+09
{txt}  lassocv {res}         2          2  1.623e+09  1.519e+09  1.674e+09
{txt}gradboost {res}         3          2  1.611e+09  1.378e+09  1.817e+09
{txt}      ols {res}         1          3  1.551e+09  1.824e+09  1.447e+09
{txt}  lassocv {res}         2          3  1.553e+09  1.823e+09  1.445e+09
{txt}gradboost {res}         3          3  1.339e+09  1.390e+09  1.653e+09
{txt}      ols {res}         1          4  1.758e+09  1.304e+09  1.610e+09
{txt}  lassocv {res}         2          4  1.759e+09  1.304e+09  1.612e+09
{txt}gradboost {res}         3          4  1.689e+09  1.203e+09  1.468e+09
{txt}      ols {res}         1          5  1.448e+09  1.652e+09  1.633e+09
{txt}  lassocv {res}         2          5  1.448e+09  1.654e+09  1.634e+09
{txt}gradboost {res}         3          5  1.346e+09  1.649e+09  1.278e+09
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner   mean_MSE      rep_1      rep_2      rep_3      rep_4      rep_5
      ols {res}         1  1.579e+09  1.547e+09  1.606e+09  1.608e+09  1.557e+09  1.578e+09
{txt}  lassocv {res}         2  1.579e+09  1.547e+09  1.605e+09  1.607e+09  1.558e+09  1.579e+09
{txt}gradboost {res}         3  1.438e+09  1.251e+09  1.602e+09  1.461e+09  1.453e+09  1.424e+09
{reset}{res}

{pstd}{ul:List keys examples}{p_end}

{pstd}List keys of associative arrays used in model m0.
Associative array m0.eqnAA is an "equation AA" and has one key,
which is is the name of the variable for which conditional expectations are estimated.
Associative array m0.estAA is an "estimation AA" and has two keys.
The objects stored on this AA are either estimation results,
AAs that have sets of estimation results, or objects with information about the estimations.{p_end}

{input}. ddml extract, keys
{res}{txt}AA keys for m0.eqnAA:
             1
    {c TLC}{hline 11}{c TRC}
  1 {c |}  {res}   e401{txt}  {c |}
  2 {c |}  {res}net_tfa{txt}  {c |}
    {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA:
         1    2
     {c TLC}{hline 11}{c TRC}
   1 {c |}  {res}ss    1{txt}  {c |}
   2 {c |}  {res}ss    2{txt}  {c |}
   3 {c |}  {res}ss    3{txt}  {c |}
   4 {c |}  {res}ss    4{txt}  {c |}
   5 {c |}  {res}ss    5{txt}  {c |}
   6 {c |}  {res}ss   md{txt}  {c |}
   7 {c |}  {res}ss   mn{txt}  {c |}
   8 {c |}  {res}st    1{txt}  {c |}
   9 {c |}  {res}st    2{txt}  {c |}
  10 {c |}  {res}st    3{txt}  {c |}
  11 {c |}  {res}st    4{txt}  {c |}
  12 {c |}  {res}st    5{txt}  {c |}
  13 {c |}  {res}st   md{txt}  {c |}
  14 {c |}  {res}st   mn{txt}  {c |}
     {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=1:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=2:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=3:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=4:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=5:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=md:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                depvar                     post{txt}  {c |}
  10 {c |}  {res}                  dh_m                    local{txt}  {c |}
  11 {c |}  {res}                dnames                    local{txt}  {c |}
  12 {c |}  {res}                 title                    local{txt}  {c |}
  13 {c |}  {res}                   vce                    local{txt}  {c |}
  14 {c |}  {res}               vcetype                    local{txt}  {c |}
  15 {c |}  {res}                     y                    local{txt}  {c |}
  16 {c |}  {res}                   y_m                    local{txt}  {c |}
  17 {c |}  {res}                 yname                    local{txt}  {c |}
  18 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=mn:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                depvar                     post{txt}  {c |}
  10 {c |}  {res}                  dh_m                    local{txt}  {c |}
  11 {c |}  {res}                dnames                    local{txt}  {c |}
  12 {c |}  {res}                 title                    local{txt}  {c |}
  13 {c |}  {res}                   vce                    local{txt}  {c |}
  14 {c |}  {res}               vcetype                    local{txt}  {c |}
  15 {c |}  {res}                     y                    local{txt}  {c |}
  16 {c |}  {res}                   y_m                    local{txt}  {c |}
  17 {c |}  {res}                 yname                    local{txt}  {c |}
  18 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=1:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=2:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=3:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=4:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=5:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=md:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                      depvar                           post{txt}  {c |}
  10 {c |}  {res}                        dh_m                          local{txt}  {c |}
  11 {c |}  {res}                      dnames                          local{txt}  {c |}
  12 {c |}  {res}                       title                          local{txt}  {c |}
  13 {c |}  {res}                         vce                          local{txt}  {c |}
  14 {c |}  {res}                     vcetype                          local{txt}  {c |}
  15 {c |}  {res}                           y                          local{txt}  {c |}
  16 {c |}  {res}                         y_m                          local{txt}  {c |}
  17 {c |}  {res}                       yname                          local{txt}  {c |}
  18 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=mn:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                      depvar                           post{txt}  {c |}
  10 {c |}  {res}                        dh_m                          local{txt}  {c |}
  11 {c |}  {res}                      dnames                          local{txt}  {c |}
  12 {c |}  {res}                       title                          local{txt}  {c |}
  13 {c |}  {res}                         vce                          local{txt}  {c |}
  14 {c |}  {res}                     vcetype                          local{txt}  {c |}
  15 {c |}  {res}                           y                          local{txt}  {c |}
  16 {c |}  {res}                         y_m                          local{txt}  {c |}
  17 {c |}  {res}                       yname                          local{txt}  {c |}
  18 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{res}

{pstd}List keys relating to equation for D variable, e401.
Keys for two associative arrays are reported.
Associative array e401.lrnAA is a "learner AA" and has two keys; it stores e.g. an estimation specification.
Associative array e401.resAA is a "results AA" and has three keys; it stores e.g. estimation results.{p_end}

{input}. ddml extract, keys vname(e401)
{res}{txt}AA keys for eqn e401.lrnAA:
                      1                 2
     {c TLC}{hline 37}{c TRC}
   1 {c |}  {res}   D1_pystacked               cmd{txt}  {c |}
   2 {c |}  {res}   D1_pystacked          est_main{txt}  {c |}
   3 {c |}  {res}   D1_pystacked       est_options{txt}  {c |}
   4 {c |}  {res}   D1_pystacked           estring{txt}  {c |}
   5 {c |}  {res}   D1_pystacked           predopt{txt}  {c |}
   6 {c |}  {res}   D1_pystacked    stack_base_est{txt}  {c |}
   7 {c |}  {res}   D1_pystacked   stack_final_est{txt}  {c |}
   8 {c |}  {res}   D1_pystacked        stack_type{txt}  {c |}
   9 {c |}  {res}   D1_pystacked             vtype{txt}  {c |}
  10 {c |}  {res}      D_e401_ss      ss_final_est{txt}  {c |}
  11 {c |}  {res}      D_e401_ss    stack_base_est{txt}  {c |}
  12 {c |}  {res}      D_e401_ss        stack_type{txt}  {c |}
  13 {c |}  {res}            opt                 1{txt}  {c |}
  14 {c |}  {res}            opt                 2{txt}  {c |}
  15 {c |}  {res}            opt                 3{txt}  {c |}
  16 {c |}  {res}            opt                 4{txt}  {c |}
  17 {c |}  {res}            opt                 5{txt}  {c |}
     {c BLC}{hline 37}{c BRC}
{txt}AA keys for eqn e401.resAA:
                    1               2               3
     {c TLC}{hline 49}{c TRC}
   1 {c |}  {res} D1_pystacked             MSE               1{txt}  {c |}
   2 {c |}  {res} D1_pystacked             MSE               2{txt}  {c |}
   3 {c |}  {res} D1_pystacked             MSE               3{txt}  {c |}
   4 {c |}  {res} D1_pystacked             MSE               4{txt}  {c |}
   5 {c |}  {res} D1_pystacked             MSE               5{txt}  {c |}
   6 {c |}  {res} D1_pystacked       MSE_folds               1{txt}  {c |}
   7 {c |}  {res} D1_pystacked       MSE_folds               2{txt}  {c |}
   8 {c |}  {res} D1_pystacked       MSE_folds               3{txt}  {c |}
   9 {c |}  {res} D1_pystacked       MSE_folds               4{txt}  {c |}
  10 {c |}  {res} D1_pystacked       MSE_folds               5{txt}  {c |}
  11 {c |}  {res} D1_pystacked               N               1{txt}  {c |}
  12 {c |}  {res} D1_pystacked               N               2{txt}  {c |}
  13 {c |}  {res} D1_pystacked               N               3{txt}  {c |}
  14 {c |}  {res} D1_pystacked               N               4{txt}  {c |}
  15 {c |}  {res} D1_pystacked               N               5{txt}  {c |}
  16 {c |}  {res} D1_pystacked         N_folds               1{txt}  {c |}
  17 {c |}  {res} D1_pystacked         N_folds               2{txt}  {c |}
  18 {c |}  {res} D1_pystacked         N_folds               3{txt}  {c |}
  19 {c |}  {res} D1_pystacked         N_folds               4{txt}  {c |}
  20 {c |}  {res} D1_pystacked         N_folds               5{txt}  {c |}
  21 {c |}  {res} D1_pystacked      stack_MSEs               1{txt}  {c |}
  22 {c |}  {res} D1_pystacked      stack_MSEs               2{txt}  {c |}
  23 {c |}  {res} D1_pystacked      stack_MSEs               3{txt}  {c |}
  24 {c |}  {res} D1_pystacked      stack_MSEs               4{txt}  {c |}
  25 {c |}  {res} D1_pystacked      stack_MSEs               5{txt}  {c |}
  26 {c |}  {res} D1_pystacked   stack_weights               1{txt}  {c |}
  27 {c |}  {res} D1_pystacked   stack_weights               2{txt}  {c |}
  28 {c |}  {res} D1_pystacked   stack_weights               3{txt}  {c |}
  29 {c |}  {res} D1_pystacked   stack_weights               4{txt}  {c |}
  30 {c |}  {res} D1_pystacked   stack_weights               5{txt}  {c |}
  31 {c |}  {res} D1_pystacked   y_stacking_cv               1{txt}  {c |}
  32 {c |}  {res} D1_pystacked   y_stacking_cv               2{txt}  {c |}
  33 {c |}  {res} D1_pystacked   y_stacking_cv               3{txt}  {c |}
  34 {c |}  {res} D1_pystacked   y_stacking_cv               4{txt}  {c |}
  35 {c |}  {res} D1_pystacked   y_stacking_cv               5{txt}  {c |}
  36 {c |}  {res}    D_e401_ss             MSE               1{txt}  {c |}
  37 {c |}  {res}    D_e401_ss             MSE               2{txt}  {c |}
  38 {c |}  {res}    D_e401_ss             MSE               3{txt}  {c |}
  39 {c |}  {res}    D_e401_ss             MSE               4{txt}  {c |}
  40 {c |}  {res}    D_e401_ss             MSE               5{txt}  {c |}
  41 {c |}  {res}    D_e401_ss       MSE_folds               1{txt}  {c |}
  42 {c |}  {res}    D_e401_ss       MSE_folds               2{txt}  {c |}
  43 {c |}  {res}    D_e401_ss       MSE_folds               3{txt}  {c |}
  44 {c |}  {res}    D_e401_ss       MSE_folds               4{txt}  {c |}
  45 {c |}  {res}    D_e401_ss       MSE_folds               5{txt}  {c |}
  46 {c |}  {res}    D_e401_ss               N               1{txt}  {c |}
  47 {c |}  {res}    D_e401_ss               N               2{txt}  {c |}
  48 {c |}  {res}    D_e401_ss               N               3{txt}  {c |}
  49 {c |}  {res}    D_e401_ss               N               4{txt}  {c |}
  50 {c |}  {res}    D_e401_ss               N               5{txt}  {c |}
  51 {c |}  {res}    D_e401_ss         N_folds               1{txt}  {c |}
  52 {c |}  {res}    D_e401_ss         N_folds               2{txt}  {c |}
  53 {c |}  {res}    D_e401_ss         N_folds               3{txt}  {c |}
  54 {c |}  {res}    D_e401_ss         N_folds               4{txt}  {c |}
  55 {c |}  {res}    D_e401_ss         N_folds               5{txt}  {c |}
  56 {c |}  {res}    D_e401_ss      ss_weights               1{txt}  {c |}
  57 {c |}  {res}    D_e401_ss      ss_weights               2{txt}  {c |}
  58 {c |}  {res}    D_e401_ss      ss_weights               3{txt}  {c |}
  59 {c |}  {res}    D_e401_ss      ss_weights               4{txt}  {c |}
  60 {c |}  {res}    D_e401_ss      ss_weights               5{txt}  {c |}
     {c BLC}{hline 49}{c BRC}
{res}

{pstd}{ul:Working with model estimation results}{p_end}

{pstd}Extract the estimated beta for the short-stack specification ("ss"), resample 2.
Provide the keys for the AA with the results for the specification and resampling,
and the subkeys for this AA to obtain the posted beta.{p_end}

{input}. ddml extract, key1(ss) key2(2) subkey1(b) subkey2(post)
{res}       {txt}           1              2
    {c TLC}{hline 31}{c TRC}
  1 {c |}  {res} 7378.277121   -263.4154308{txt}  {c |}
    {c BLC}{hline 31}{c BRC}


{pstd}As above, but store as a Mata object "bmat".
This is done by providing this name after "ddml extract".{p_end}

{input}. ddml extract bmat, key1(ss) key2(2) subkey1(b) subkey2(post)
{res}
{input}. mata: bmat
{res}       {txt}           1              2
    {c TLC}{hline 31}{c TRC}
  1 {c |}  {res} 7378.277121   -263.4154308{txt}  {c |}
    {c BLC}{hline 31}{c BRC}


{pstd}By default, the object is saved as a Mata object.
To save as a Stata macro r(bmat), use the {opt Stata} option:{p_end}

{input}. ddml extract bmat, key1(ss) key2(2) subkey1(b) subkey2(post) stata
{res}
{input}. mat list r(bmat)
{res}
{txt}r(bmat)[1,2]
            c1          c2
r1 {res}  7378.2771  -263.41543
{reset}

{pstd}More examples of the above, relating to specification ss and
various resamples or the mean/median across resamples.
{input}. ddml extract, keys
{res}{txt}AA keys for m0.eqnAA:
             1
    {c TLC}{hline 11}{c TRC}
  1 {c |}  {res}   e401{txt}  {c |}
  2 {c |}  {res}net_tfa{txt}  {c |}
    {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA:
         1    2
     {c TLC}{hline 11}{c TRC}
   1 {c |}  {res}ss    1{txt}  {c |}
   2 {c |}  {res}ss    2{txt}  {c |}
   3 {c |}  {res}ss    3{txt}  {c |}
   4 {c |}  {res}ss    4{txt}  {c |}
   5 {c |}  {res}ss    5{txt}  {c |}
   6 {c |}  {res}ss   md{txt}  {c |}
   7 {c |}  {res}ss   mn{txt}  {c |}
   8 {c |}  {res}st    1{txt}  {c |}
   9 {c |}  {res}st    2{txt}  {c |}
  10 {c |}  {res}st    3{txt}  {c |}
  11 {c |}  {res}st    4{txt}  {c |}
  12 {c |}  {res}st    5{txt}  {c |}
  13 {c |}  {res}st   md{txt}  {c |}
  14 {c |}  {res}st   mn{txt}  {c |}
     {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=1:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=2:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=3:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=4:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=5:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=md:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                depvar                     post{txt}  {c |}
  10 {c |}  {res}                  dh_m                    local{txt}  {c |}
  11 {c |}  {res}                dnames                    local{txt}  {c |}
  12 {c |}  {res}                 title                    local{txt}  {c |}
  13 {c |}  {res}                   vce                    local{txt}  {c |}
  14 {c |}  {res}               vcetype                    local{txt}  {c |}
  15 {c |}  {res}                     y                    local{txt}  {c |}
  16 {c |}  {res}                   y_m                    local{txt}  {c |}
  17 {c |}  {res}                 yname                    local{txt}  {c |}
  18 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=mn:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                depvar                     post{txt}  {c |}
  10 {c |}  {res}                  dh_m                    local{txt}  {c |}
  11 {c |}  {res}                dnames                    local{txt}  {c |}
  12 {c |}  {res}                 title                    local{txt}  {c |}
  13 {c |}  {res}                   vce                    local{txt}  {c |}
  14 {c |}  {res}               vcetype                    local{txt}  {c |}
  15 {c |}  {res}                     y                    local{txt}  {c |}
  16 {c |}  {res}                   y_m                    local{txt}  {c |}
  17 {c |}  {res}                 yname                    local{txt}  {c |}
  18 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=1:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=2:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=3:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=4:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=5:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=md:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                      depvar                           post{txt}  {c |}
  10 {c |}  {res}                        dh_m                          local{txt}  {c |}
  11 {c |}  {res}                      dnames                          local{txt}  {c |}
  12 {c |}  {res}                       title                          local{txt}  {c |}
  13 {c |}  {res}                         vce                          local{txt}  {c |}
  14 {c |}  {res}                     vcetype                          local{txt}  {c |}
  15 {c |}  {res}                           y                          local{txt}  {c |}
  16 {c |}  {res}                         y_m                          local{txt}  {c |}
  17 {c |}  {res}                       yname                          local{txt}  {c |}
  18 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=mn:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                      depvar                           post{txt}  {c |}
  10 {c |}  {res}                        dh_m                          local{txt}  {c |}
  11 {c |}  {res}                      dnames                          local{txt}  {c |}
  12 {c |}  {res}                       title                          local{txt}  {c |}
  13 {c |}  {res}                         vce                          local{txt}  {c |}
  14 {c |}  {res}                     vcetype                          local{txt}  {c |}
  15 {c |}  {res}                           y                          local{txt}  {c |}
  16 {c |}  {res}                         y_m                          local{txt}  {c |}
  17 {c |}  {res}                       yname                          local{txt}  {c |}
  18 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{res}

{input}. ddml extract, key1(ss) key2(1) subkey1(D_e401_ss_mse) subkey2(scalar)
{res}  .1958363362

{input}. ddml extract, key1(ss) key2(2) subkey1(D_e401_ss_mse_folds) subkey2(matrix)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1957355901   .1941540463   .1985244675{txt}  {c |}
    {c BLC}{hline 43}{c BRC}

{input}. ddml extract, key1(ss) key2(mn) subkey1(V) subkey2(post)
{res}  902361.1559

{input}. ddml extract, key1(ss) key2(md) subkey1(title) subkey2(local)
{res}  Shortstack DDML model (median over 5 resamples)


{pstd}{ul:Working with equation estimation results}{p_end}

{pstd}Display information stored on learner AA e401.lrnAA
about the specification of conditional expectations for variable e401.{p_end}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(est_main)
{res}  pystacked e401 tw age inc fsize educ db marr twoearn pira hown

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(stack_base_est)
{res}  ols lassocv gradboost


{pstd}Display information stored on results AA e401.resAA
about the estimation results for resamplings 1 and 2.{p_end}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(MSE_folds) key3(1)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1915497943   .1933662438   .2026450476{txt}  {c |}
    {c BLC}{hline 43}{c BRC}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(MSE_folds) key3(2)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1956606296   .1941944697   .1985518793{txt}  {c |}
    {c BLC}{hline 43}{c BRC}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(stack_weights) key3(1)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1682630405             0             0{txt}  {c |}
  2 {c |}  {res}.1310992449   .2396171276   .2243102368{txt}  {c |}
  3 {c |}  {res}.7006377146   .7603828724   .7756897632{txt}  {c |}
    {c BLC}{hline 43}{c BRC}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(stack_weights) key3(2)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}          0   .2497957652   .0023914381{txt}  {c |}
  2 {c |}  {res}.2660738854             0   .2584549675{txt}  {c |}
  3 {c |}  {res}.7339261146   .7502042348   .7391535944{txt}  {c |}
    {c BLC}{hline 43}{c BRC}


{pstd}{ul:Working directly with an equation associative array}{p_end}

{pstd}Extract the associative AA for the estimation of conditional expectations for variable e401.
Store it as a Mata object called AA_e401.
Note: the {cmd:crossfit} command returns an equation associative array,
so this step is unnecessary when using this command.{p_end}

{input}. ddml extract AA_e401, vname(e401)
{res}
{input}. mata: AA_e401
{res}  0x35d56ac0


{pstd}Examples of working with this equation associative array.
Note that the {opt ename} option must be used.{p_end}

{input}. ddml extract, ename(AA_e401) key1(D1_pystacked) key2(MSE) key3(1)
{res}  .1958536952

{input}. ddml extract, ename(AA_e401) key1(D1_pystacked) key2(MSE) key3(2)
{res}  .1961356595


{pstd}{ul:Using Mtata's associative array commands}{p_end}

{pstd}If preferred, Mata's associative array commands can be used directly.
Note that all keys are strings.{p_end}

{input}. mata: m0.estAA.keys()
{res}        {txt} 1    2
     {c TLC}{hline 11}{c TRC}
   1 {c |}  {res}ss    2{txt}  {c |}
   2 {c |}  {res}st    2{txt}  {c |}
   3 {c |}  {res}ss    3{txt}  {c |}
   4 {c |}  {res}st    3{txt}  {c |}
   5 {c |}  {res}st    4{txt}  {c |}
   6 {c |}  {res}st   md{txt}  {c |}
   7 {c |}  {res}st   mn{txt}  {c |}
   8 {c |}  {res}ss    1{txt}  {c |}
   9 {c |}  {res}st    5{txt}  {c |}
  10 {c |}  {res}ss    4{txt}  {c |}
  11 {c |}  {res}ss   md{txt}  {c |}
  12 {c |}  {res}st    1{txt}  {c |}
  13 {c |}  {res}ss   mn{txt}  {c |}
  14 {c |}  {res}ss    5{txt}  {c |}
     {c BLC}{hline 11}{c BRC}

{input}. mata: AA_e1_r2 = (m0.estAA).get(("ss","2"))
{res}
{input}. mata: AA_e1_r2.keys()
{res}        {txt}                     1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}                znames                    local{txt}  {c |}
   2 {c |}  {res}                dnames                    local{txt}  {c |}
   3 {c |}  {res}                 title                    local{txt}  {c |}
   4 {c |}  {res}                depvar                     post{txt}  {c |}
   5 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   6 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   7 {c |}  {res}                   vce                    local{txt}  {c |}
   8 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   9 {c |}  {res}                     V                     post{txt}  {c |}
  10 {c |}  {res}                   y_m                    local{txt}  {c |}
  11 {c |}  {res}                 yname                    local{txt}  {c |}
  12 {c |}  {res}                     N                     post{txt}  {c |}
  13 {c |}  {res}                     b                     post{txt}  {c |}
  14 {c |}  {res}               vcetype                    local{txt}  {c |}
  15 {c |}  {res}                     y                    local{txt}  {c |}
  16 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  17 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
  18 {c |}  {res}                   d_m                    local{txt}  {c |}
  19 {c |}  {res}                     d                    local{txt}  {c |}
  20 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
  21 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
     {c BLC}{hline 51}{c BRC}

{input}. mata: AA_e1_r2.get(("b","post"))
{res}       {txt}           1              2
    {c TLC}{hline 31}{c TRC}
  1 {c |}  {res} 7378.277121   -263.4154308{txt}  {c |}
    {c BLC}{hline 31}{c BRC}

{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 11:00:41

Help file: ddml_example_stacking.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 11:00:41
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:Partially-linear model with {help pystacked} and stacking}:{p_end}

{pstd}Preparation: load the data, define global macros, set the seed and initialize the model.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D e401

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42

{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized


{pstd}Add supervised machine learners for estimating conditional expectations.
For simplicity, we use {help pystacked}'s default learners:
OLS, cross-validated lasso, and gradient boosting.{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.


{pstd} Cross-fitting and estimation:
The learners are iteratively fitted on the training data to obtain the estimated conditional expectations,
and then the causal coefficient of interest is estimated along with heteroskedastic-consistent SEs.
Note that the initial stacking is specified at the {help ddml crossfit:cross-fitting} stage.
In addition to the standard stacking done by {helpb pystacked},
also request short-stacking and pooled-stacking to be done by {opt ddml}.{p_end}

{input}. ddml crossfit, shortstack poolstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (998.890)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7074.289  (966.832)
{stata ddml estimate, mname(m0) spec(ps) rep(1) notable replay:  ps  1}   [poolstack]          [ps]  6840.628  (977.354)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (964.328)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7433.262  (898.604)
{stata ddml estimate, mname(m0) spec(ps) rep(2) notable replay:  ps  2}   [poolstack]          [ps]  7013.319  (910.084)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494 (1046.569)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7253.775  (948.082)
{stata ddml estimate, mname(m0) spec(ps) rep(mn) notable replay noconstant:  ps mn}   [poolstack]          [ps]  6926.973  (945.891)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7017.494 (1047.070)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7253.775  (950.443)
{stata ddml estimate, mname(m0) spec(ps) rep(md) notable replay noconstant:  ps md}   [poolstack]          [ps]  6926.973  (948.257)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7253.775{col 26}{space 2} 950.4432{col 37}{space 1}    7.63{col 46}{space 3}0.000{col 54}{space 4} 5390.941{col 67}{space 3}  9116.61
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7253.7754 7074.2886 7074.2886 7253.7754 7433.2622 7433.2622


{pstd}Examine the standard ({cmd:pystacked}) stacking weights as well as
the {opt ddml} short-stacking and pooled-stacking weights.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .05613789    .05836149    .05391429
{txt}  lassocv {res}           2    .27554279    .24816003    .30292554
{txt}gradboost {res}           3    .66831932    .69347848    .64316016
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .57321109    .55513919    .59128299
{txt}  lassocv {res}           2    1.006e-08            0    2.011e-08
{txt}gradboost {res}           3    .42700058    .44528417    .40871699
{reset}{res}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .25052052    .23042397    .27061706
{txt}  lassocv {res}           2    .00153817    .00307633            0
{txt}gradboost {res}           3    .74794132     .7664997    .72938294
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1     .2246767    .21142516    .23792824
{txt}  lassocv {res}           2    .02898811    2.917e-06    .05797331
{txt}gradboost {res}           3    .74633519    .78857192    .70409845
{reset}{res}
{input}. ddml extract, show(psweights)
{res}
{res}pool-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .00823385    2.819e-18     .0164677
{txt}  lassocv {res}           2     .3228386    .30599574    .33968146
{txt}gradboost {res}           3    .66892755    .69400426    .64385084
{reset}
{res}pool-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .54463296    .58045718    .50880875
{txt}  lassocv {res}           2            0            0            0
{txt}gradboost {res}           3    .45536704    .41954282    .49119125
{reset}{res}

{pstd} Re-stack without cross-fitting, using the single-best learner
instead of the default constrained nonlinear least squares.
We do this using the {help ddml estimate} command.
Since no stacking method is specified,
restacking will be done for all three methods.{p_end}

{input}. ddml estimate, robust finalest(singlebest)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6455.251 (1001.440)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7124.950  (957.277)
{stata ddml estimate, mname(m0) spec(ps) rep(1) notable replay:  ps  1}   [poolstack]          [ps]  7074.448 (1008.427)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7877.428  (996.891)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7806.394  (926.937)
{stata ddml estimate, mname(m0) spec(ps) rep(2) notable replay:  ps  2}   [poolstack]          [ps]  6496.931  (997.313)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7166.339 (1226.365)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7465.672 (1001.535)
{stata ddml estimate, mname(m0) spec(ps) rep(mn) notable replay noconstant:  ps mn}   [poolstack]          [ps]  6785.690 (1043.574)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7166.339 (1226.371)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7465.672 (1001.942)
{stata ddml estimate, mname(m0) spec(ps) rep(md) notable replay noconstant:  ps md}   [poolstack]          [ps]  6785.690 (1043.629)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7465.672{col 26}{space 2} 1001.942{col 37}{space 1}    7.45{col 46}{space 3}0.000{col 54}{space 4} 5501.903{col 67}{space 3} 9429.442
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}singlebest

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7465.6721 7124.9502 7124.9502 7465.6721 7806.3940 7806.3940


{pstd} As above, but request short-stacking only at the cross-fitting stage.
Note the speed improvement.{p_end}

{input}. ddml crossfit, shortstack nostdstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]  7073.928  (967.615)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7406.747  (896.114)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  {res}[shortstack]          [ss]  7240.337  (944.666)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7240.337  (947.281)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7240.337{col 26}{space 2} 947.2813{col 37}{space 1}    7.64{col 46}{space 3}0.000{col 54}{space 4}   5383.7{col 67}{space 3} 9096.975
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7240.3374 7073.9282 7073.9282 7240.3374 7406.7466 7406.7466


{pstd} Re-stack the above without cross-fitting, using OLS as the final estimator.
Use the option {opt shortstack} since only these results are re-stacked.{p_end}

{input}. ddml estimate, robust shortstack finalest(ols)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]  7046.829  (966.256)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7424.263  (897.706)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  {res}[shortstack]          [ss]  7235.546  (949.141)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7235.546  (951.513)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7235.546{col 26}{space 2} 951.5133{col 37}{space 1}    7.60{col 46}{space 3}0.000{col 54}{space 4} 5370.614{col 67}{space 3} 9100.478
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}ols

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7235.5459 7046.8291 7046.8291 7235.5459 7424.2627 7424.2627

{input}. ddml estimate, robust shortstack finalest(ols)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]  7046.829  (966.256)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7424.263  (897.706)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  {res}[shortstack]          [ss]  7235.546  (949.141)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7235.546  (951.513)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7235.546{col 26}{space 2} 951.5133{col 37}{space 1}    7.60{col 46}{space 3}0.000{col 54}{space 4} 5370.614{col 67}{space 3} 9100.478
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}ols

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7235.5459 7046.8291 7046.8291 7235.5459 7424.2627 7424.2627


{pstd}{ul:Extended example with specified {help pystacked} learners and settings}:{p_end}

{pstd}Same example as above, but specify the base learners explicitly.
We again make use of {help pystacked} integration,
so there is a single call to {help pystacked} for each conditional expectation.
The first learner in the stacked ensemble is OLS.
We also use cross-validated lasso, ridge and two random forests with different settings.
The settings are stored in macros for readability.{p_end}

{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. global rflow max_features(5) min_samples_leaf(1) max_samples(.7)

{input}. global rfhigh max_features(5) min_samples_leaf(10) max_samples(.7)

{input}. ddml E[Y|X]: pystacked $Y $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner D1_pystacked added successfully.


{pstd}Note: Options before ":" and after the first comma refer to {cmd:ddml}. 
Options that come after the final comma refer to the estimation command. 
Make sure to not confuse the two types of options.{p_end}

{pstd}The learners are iteratively fitted on the training data.
In addition to the standard stacking done by {helpb pystacked},
also request short-stacking to be done by {opt ddml}.
Finally, estimate the coefficients of interest.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  7294.554 (1005.548)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7046.814  (979.169)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7114.501 (1033.362)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7234.312  (972.221)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7204.528 (1023.142)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7140.563  (980.171)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7204.528 (1023.517)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7140.563  (980.195)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7140.563{col 26}{space 2} 980.1951{col 37}{space 1}    7.28{col 46}{space 3}0.000{col 54}{space 4} 5219.416{col 67}{space 3}  9061.71
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7140.5632 7046.8140 7046.8140 7140.5632 7234.3125 7234.3125


{pstd}Examine the standard ({cmd:pystacked}) stacking weights as well as the {opt ddml} short-stacking weights.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    4.018e-20            0    8.036e-20
{txt}lassocv {res}           2    .22993114    .16362312    .29623916
{txt}ridgecv {res}           3    .11694608    .21786462    .01602755
{txt}     rf {res}           4    .01560619            0    .03121238
{txt}     rf {res}           5    .63751658    .61851226    .65652091
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .24179897    .05679108    .42680686
{txt}lassocv {res}           2    .02574689    .05149378            0
{txt}ridgecv {res}           3            0            0            0
{txt}     rf {res}           4     .6974316    .94665083    .44821237
{txt}     rf {res}           5    .08557162            0    .17114324
{reset}{res}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    1.952e-17            0    3.903e-17
{txt}lassocv {res}           2    .12439376    .24878753            0
{txt}ridgecv {res}           3    .16345225            0    .32690449
{txt}     rf {res}           4    2.404e-17    6.397e-18    4.169e-17
{txt}     rf {res}           5    .71215399    .75121247    .67309551
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1     .0644898            0     .1289796
{txt}lassocv {res}           2            0            0            0
{txt}ridgecv {res}           3    .09095584    .18191168            0
{txt}     rf {res}           4    .84455436    .81808832     .8710204
{txt}     rf {res}           5            0            0            0
{reset}{res}
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 11:03:18

Help file: ddml_example_describe.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 11:03:18
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:ddml describe utility - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros, set the seed and initialize the model.
Use 2-fold cross-fitting with two repetitions (resamples)
Use {help pystacked}'s default learners as the supervised learners.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D e401

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42

{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (826.611)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (856.397)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494  (916.573)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7017.494  (916.980)

{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020


{pstd}Default of {opt ddml describe} is to report a brief summary.{p_end}

{input}. ddml describe
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked


{pstd}Options: report details of the total and cross-fit samples,
learners (including the estimation strings),
cross-fit results,
and estimation results.{p_end}

{input}. ddml describe, sample
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}ID:{col 25}{res}m0_id
{txt}Full sample indic.:{col 25}{res}m0_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m0_fid_1    m0_fid_2  
{txt}Fold sample indic.:{col 25}{res}m0_sample_1 m0_sample_2 
{txt}Estimation N:{col 25}    {res}9915        9915    

{input}. ddml describe, learners
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown

{input}. ddml describe, crossfit
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}net_tfa{col 12}Y1_pysta~d{col 26} 1{col 34} 1.3e+09   1.4e+09   1.2e+09
{col 12}Y1_pysta~d{col 26} 2{col 34} 1.4e+09   1.3e+09   1.6e+09
e401{col 12}D1_pysta~d{col 26} 1{col 34}    0.20      0.19      0.20
{col 12}D1_pysta~d{col 26} 2{col 34}    0.20      0.20      0.20

{input}. ddml describe, estimates
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked


{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020


{pstd}The {opt all} option is equivalent to specifying all 4 options.{p_end}

{input}. ddml describe, all
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked
{txt}Specifications:{col 25}{res}1 possible specs * 2 crossfit splits = 2

{txt}ID:{col 25}{res}m0_id
{txt}Full sample indic.:{col 25}{res}m0_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m0_fid_1    m0_fid_2  
{txt}Fold sample indic.:{col 25}{res}m0_sample_1 m0_sample_2 
{txt}Estimation N:{col 25}    {res}9915        9915    

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}net_tfa{col 12}Y1_pysta~d{col 26} 1{col 34} 1.3e+09   1.4e+09   1.2e+09
{col 12}Y1_pysta~d{col 26} 2{col 34} 1.4e+09   1.3e+09   1.6e+09
e401{col 12}D1_pysta~d{col 26} 1{col 34}    0.20      0.19      0.20
{col 12}D1_pysta~d{col 26} 2{col 34}    0.20      0.20      0.20


{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020

{input}. ddml describe, sample learners crossfit estimates
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}ID:{col 25}{res}m0_id
{txt}Full sample indic.:{col 25}{res}m0_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m0_fid_1    m0_fid_2  
{txt}Fold sample indic.:{col 25}{res}m0_sample_1 m0_sample_2 
{txt}Estimation N:{col 25}    {res}9915        9915    

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}net_tfa{col 12}Y1_pysta~d{col 26} 1{col 34} 1.3e+09   1.4e+09   1.2e+09
{col 12}Y1_pysta~d{col 26} 2{col 34} 1.4e+09   1.3e+09   1.6e+09
e401{col 12}D1_pysta~d{col 26} 1{col 34}    0.20      0.19      0.20
{col 12}D1_pysta~d{col 26} 2{col 34}    0.20      0.20      0.20


{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020

{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 11:04:12

Help file: ddml_example_export.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 11:04:12
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:ddml export utility - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros, set the seed and initialize the model.
Use 2-fold cross-fitting with two repetitions (resamples)
Use {help pystacked}'s default learners as the supervised learners.
We explicitly name the model to be estimated as m_sip1991;
this is the name of the Mata global containing the model details,
and will also prefix the sample and fold indicators created by {opt ddml}.
{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear

{input}. global Y net_tfa

{input}. global D e401

{input}. global X tw age inc fsize educ db marr twoearn pira hown

{input}. set seed 42

{input}. ddml init partial, kfolds(2) reps(2) mname(m_sip1991)
{res}
{input}. ddml E[Y|X], mname(m_sip1991): pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X], mname(m_sip1991): pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit, mname(m_sip1991)
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate, mname(m_sip1991)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m_sip1991
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m_sip1991) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (826.611)
{stata ddml estimate, mname(m_sip1991) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (856.397)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m_sip1991) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494  (916.573)
{stata ddml estimate, mname(m_sip1991) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  D1_pystacked  7017.494  (916.980)

{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020


{pstd}It will often be a good idea to include an ID variable that identifies the observation number.
This dataset doesn't include an ID variable, so we create one.{p_end}

{input}. gen long m_sip1991_id = _n


{pstd}To include the ID variable with everything else, we use the {opt addvars(.)} option.
The data will be exported to a CSV file called "m_ddml_sip1991.csv".{p_end}

{input}. ddml export using m_ddml_sip1991.csv, mname(m_sip1991) replace addvars(m_sip1991_id)
{res}{txt}(note: file m_ddml_sip1991.csv not found)
{txt}file m_ddml_sip1991.csv saved

{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 11:05:05

Help file: ddml_example_overlap.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 11:05:05
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{smcl}
{pstd}{ul:ddml overlap utility - Overlap plots with interactive models (ATE etc.)}{p_end}

{pstd}We use the default of 5 cross-fit folds
and specify 2 resamplings with 2 supervised learners:
linear regression and gradient boosted trees, stacked using {help pystacked}.
Note that we use gradient boosted regression trees for E[Y|X,D],
but gradient boosted classification trees for E[D|X].{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)

{input}. global Y bweight

{input}. global D mbsmoke

{input}. global X prenatal1 mmarried fbaby mage medu

{input}. set seed 42

{input}. ddml init interactive, reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. ddml E[Y|X,D]: pystacked $Y $X || method(ols) || method(gradboost) || , type(reg)
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X || method(logit) || method(gradboost) || , type(class)
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.297   (25.985)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.083   (25.665)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.690   (25.826)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.690   (25.828)

{txt}Median over 2 stacking resamples (ATE)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-219.6899{col 26}{space 2} 25.82837{col 37}{space 1}   -8.51{col 46}{space 3}0.000{col 54}{space 4}-270.3125{col 67}{space 3}-169.0672
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -219.6899 -220.0827 -220.0827 -219.6899 -219.2971 -219.2971


{pstd}Default behavior of {opt ddml overlap} is to use all cross-fit resamples
and plot the stacked (ensemble) learner generated by {help pystacked}:{p_end}

{input}. ddml overlap
{res}

{pstd}Use just resample 1:{p_end}

{input}. ddml overlap, replist(1)
{res}

{pstd}Overlap plots for the predicted values of
the separate logit (#1) and gradboost (#2) learners:{p_end}

{input}. ddml overlap, pslist(D1_pystacked_L1 D1_pystacked_L2)
{res}

{pstd}Save the overlap plot using the default triangle kernel,
generate an overlap plot using the Epanechnikov, kernal,
and combine the two into a single graph:{p_end}

{input}. ddml overlap, name(triangle, replace) title(Propensity score - triangle kernel)
{res}
{input}. ddml overlap, kernel(epanechnikov) name(epanechnikov, replace) title(Propensity score - epanechnikov kernel)
{res}
{input}. graph combine triangle epanechnikov
{res}
{smcl}
{res}{sf}{ul off}{smcl}
{res}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}24 Jul 2023, 11:06:51

Help file: ddml_example_fcluster

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res}24 Jul 2023, 11:06:51
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{com}{sf}{ul off}{res}{smcl}
{pstd}{ul:Cluster sampling with cross-fit folds - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros and set the seed.{p_end}

{input}. webuse nlsw88, clear
{txt}(NLSW, 1988 extract)

{input}. gen lwage = ln(wage)

{input}. global Y lwage

{input}. global D union

{input}. global X age-c_city hours-tenure

{input}. set seed 42


{pstd}Initialize the model.
The {opt fcluster(industry)} ("fold-cluster") option tells {opt ddml}
to ensure that clusters (here, identified by the variable {opt industry})
are not split across cross-fit folds, i.e., each cluster appears in only one cross-fit fold.
Here we specify 2 cross-fit folds,
so all observations for each cluster will appear in either fold 1 or in fold 2.
NB: This example is somewhat artificial, because there are only 12 clusters (industries).{p_end}

{input}. ddml init partial, kfolds(2) fcluster(industry)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. tab industry m0_fid_1

                      {txt}{c |}   Fold ID (randomly
                      {c |}   generated) rep 1
             industry {c |}         1          2 {c |}     Total
{hline 22}{c +}{hline 22}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}        17          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          4 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}        29          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0        367 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0         90 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}       333          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0        192 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0         86 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}        97          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}        17          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0        824 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}       176          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 22}{c +}{hline 10}
                Total {c |}{res}       669      1,563 {txt}{c |}{res}     2,232 


{pstd}Since there are 12 clusters defined by {opt industry},
we could achieve the same cross-fit split either by specifying {opt fcluster(industry)},
or by using {opt fcluster(industry)} as the fold identifier and specifying {opt foldvar(industry)}.
(NB: The split is the same but the fold numbering is different.){p_end}

{input}. ddml init partial, foldvar(industry)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
note - fold variable missing for some observations
these observations will be excluded from the estimation sample

{input}. tab industry m0_fid_1

                      {txt}{c |}                             (based on industry)
             industry {c |}         1          2          3          4          5          6          7 {c |}     Total
{hline 22}{c +}{hline 77}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}        17          0          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          4          0          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0         29          0          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0        367          0          0          0 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0          0          0          0         90          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0          0        333          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0          0          0          0          0          0        192 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 77}{c +}{hline 10}
                Total {c |}{res}        17          4         29        367         90        333        192 {txt}{c |}{res}     2,232 


                      {txt}{c |}                  (based on industry)
             industry {c |}         8          9         10         11         12 {c |}     Total
{hline 22}{c +}{hline 55}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}        86          0          0          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0         97          0          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0          0         17          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0        824          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0        176 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 55}{c +}{hline 10}
                Total {c |}{res}        86         97         17        824        176 {txt}{c |}{res}     2,232 


{input}. ddml init partial, kfolds(12) fcluster(industry)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized

{input}. tab industry m0_fid_1

                      {txt}{c |}                      Fold ID (randomly generated) rep 1
             industry {c |}         1          2          3          4          5          6          7 {c |}     Total
{hline 22}{c +}{hline 77}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          0          4          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0          0         29          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0          0          0          0        367 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}       192          0          0          0          0          0          0 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0          0          0          0         97          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0         17          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0          0        176          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 77}{c +}{hline 10}
                Total {c |}{res}       192         17          4         29         97        176        367 {txt}{c |}{res}     2,232 


                      {txt}{c |}           Fold ID (randomly generated) rep 1
             industry {c |}         8          9         10         11         12 {c |}     Total
{hline 22}{c +}{hline 55}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}         0         17          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}        90          0          0          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0        333 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0          0         86          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0        824          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 55}{c +}{hline 10}
                Total {c |}{res}        90         17         86        824        333 {txt}{c |}{res}     2,232 


{pstd}Estimation is standard,
but to obtain cluster-robust SEs the covariance estimator
needs to be requested with {opt ddml estimate}:{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.

{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: lwage
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: union
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}...completed cross-fitting
{res}
{input}. ddml estimate, cluster(industry)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=12, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{col 25}Folds respect clustering by industry
{txt}Dependent variable (Y):{col 25}{res}lwage
{txt}{col 2}lwage learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}union
{txt}{col 2}union learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked     0.098    (0.057)

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     1852
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}{ralign 78:(Std. Err. adjusted for {res:12} clusters in industry)}
{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}       lwage{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}union {c |}{col 14}{res}{space 2} .0983255{col 26}{space 2} .0566405{col 37}{space 1}    1.74{col 46}{space 3}0.083{col 54}{space 4}-.0126879{col 67}{space 3} .2093388
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0256319{col 26}{space 2} .0473131{col 37}{space 1}   -0.54{col 46}{space 3}0.588{col 54}{space 4}-.1183639{col 67}{space 3} .0671001
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1


{smcl}
{res}{sf}{ul off}