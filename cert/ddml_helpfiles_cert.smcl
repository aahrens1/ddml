{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:12:57
{txt}
{com}. which ddml
{txt}C:\LocalStore\ecomes\Documents\GitHub\ddml\ddml.ado
{res}*! ddml v1.4.1
*! last edited: 28july2023
*! authors: aa/ms
{txt}
{com}. mata: whichddml()
{res}  
  Mata library for ddml and related programs,
  compiled 28 Jul 2023 under Stata 15.1 born 26 Aug 2019.
  authors AA/MS
{txt}
{com}. which qddml
{txt}C:\LocalStore\ecomes\Documents\GitHub\ddml\qddml.ado
{res}*! ddml v1.4.1
*! last edited: 28july2023
*! authors: aa/ms
{txt}
{com}. which crossfit
{txt}C:\LocalStore\ecomes\Documents\GitHub\ddml\crossfit.ado
{res}*! ddml v1.4.1
*! last edited: 3aug2023
*! authors: aa/ms
{txt}
{com}. which pystacked
{txt}C:\LocalStore\ecomes\Documents\GitHub\pystacked\pystacked.ado
{res}*! pystacked v0.7.5
*! last edited: 7aug2023
*! authors: aa/ms
{txt}
{com}. log close
      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:12:57
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:12:57

Help file: ddml_example_partial_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:12:57
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear model - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros, set the seed and initialize the model.
Use 2-fold cross-fitting with two repetitions (resamples)
Use {help pystacked}'s default learners as the supervised learners: OLS, cross-validated lasso, and gradient boosting.
NB: The model specification and results will be stored on a Mata object
with the default name "m0".{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(2) reps(2)
{res}{txt}
{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (826.611)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (856.397)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494  (916.573)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7017.494  (916.980)

{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020
{txt}

{pstd}Replicate the {opt ddml estimate} results for the 1st cross-fit estimation (resample 1) by hand,
using the estimated conditional expectations generated by {opt ddml} and {help pystacked};
"_1" means resample 1.
Compare using {opt ddml estimate, replay}.{p_end}

{input}. cap drop Yresid
{txt}
{input}. cap drop Dresid
{txt}
{input}. gen double Yresid = $Y - Y1_pystacked_1
{txt}
{input}. gen double Dresid = $D - D1_pystacked_1
{txt}
{input}. regress Yresid Dresid

{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}     9,915
{txt}{hline 13}{c +}{hline 34}   F(1, 9913)      = {res}    64.79
{txt}       Model {c |} {res} 8.6027e+10         1  8.6027e+10   {txt}Prob > F        ={res}    0.0000
{txt}    Residual {c |} {res} 1.3163e+13     9,913  1.3278e+09   {txt}R-squared       ={res}    0.0065
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}    0.0064
{txt}       Total {c |} {res} 1.3249e+13     9,914  1.3364e+09   {txt}Root MSE        =   {res}  36439

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 6653.485{col 26}{space 2} 826.6108{col 37}{space 1}    8.05{col 46}{space 3}0.000{col 54}{space 4}  5033.16{col 67}{space 3} 8273.811
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} 3.896799{col 26}{space 2} 365.9536{col 37}{space 1}    0.01{col 46}{space 3}0.992{col 54}{space 4}-713.4466{col 67}{space 3} 721.2402
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{input}. ddml estimate, mname(m0) spec(st) rep(1) notable replay
{res}
{txt}Stacking DDML model (sample=1)
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6653.485{col 26}{space 2} 826.6108{col 37}{space 1}    8.05{col 46}{space 3}0.000{col 54}{space 4} 5033.358{col 67}{space 3} 8273.613
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} 3.896799{col 26}{space 2} 365.9536{col 37}{space 1}    0.01{col 46}{space 3}0.992{col 54}{space 4} -713.359{col 67}{space 3} 721.1526
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:13:35

Help file: ddml_example_partial_pystacked_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:13:35
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear model - Detailed example with stacking regression using {help pystacked}}

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}

{pstd}We next initialize the ddml estimation and select the model.
{it:partial} refers to the partially linear model.
The model will be stored on a Mata object with the default name "m0"
unless otherwise specified using the {opt mname(name)} option.{p_end}

{pstd}We set the number of random folds to 2 so that 
the model runs quickly. The default is {opt kfolds(5)}. We recommend 
considering at least 5-10 folds and even more if your sample size is small.{p_end}

{pstd}We recommend re-running the model multiple times on 
different random folds; see options {opt reps(integer)}.
Here we set the number of repetions to 2, again only so that the model runs quickly.{p_end}

{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}Stacking regression is a simple and powerful method for 
combining predictions from multiple learners.
Here we use {help pystacked} with the partially linear model,
but it can be used with any model supported by {cmd:ddml}.{p_end}

{pstd}Note: the additional support provided by {opt ddml} for {help pystacked} (see {help ddml##pystacked:above})
is available only if, as in this example, {help pystacked} is the only learner for each conditional expectation.
Mutliple learners are provided to {help pystacked}, not directly to {opt ddml}.

{pstd}Add supervised machine learners for estimating conditional expectations.
The first learner in the stacked ensemble is OLS.
We also use cross-validated lasso, ridge and two random forests with different settings, 
which we save in the following macros:{p_end}

{input}. global rflow max_features(5) min_samples_leaf(1) max_samples(.7)
{txt}
{input}. global rfhigh max_features(5) min_samples_leaf(10) max_samples(.7)
{txt}

{input}. ddml E[Y|X]: pystacked $Y $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner D1_pystacked added successfully.
{txt}

{pstd}Note: Options before ":" and after the first comma refer to {cmd:ddml}. 
Options that come after the final comma refer to the estimation command. 
Make sure to not confuse the two types of options.{p_end}

{pstd}Check if learners were correctly added:{p_end}

{input}. ddml desc, learners
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt(max_features(5) min_samples_leaf(1) max_samples(.7)) || method(rf) opt(max_features(5) min_samples_leaf(10) max_samples(.7)), type(reg)
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt(max_features(5) min_samples_leaf(1) max_samples(.7)) || method(rf) opt(max_features(5) min_samples_leaf(10) max_samples(.7)), type(reg)
{txt}

{pstd} Cross-fitting: The learners are iteratively fitted on the training data.
This step may take a while, depending on the number of learners, repetitions, folds, etc.
In addition to the standard stacking done by {help pystacked},
also request short-stacking to be done by {opt ddml}.
Whereas stacking relies on (out-of-sample) cross-validated predicted values
to obtain the relative weights for the base learners,
short-stacking uses the (out-of-sample) cross-fitted predicted values.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}

{pstd}Finally, we estimate the coefficients of interest.{p_end}

{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  7455.326  (947.699)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7451.662  (937.660)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7024.078  (918.991)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7159.673  (887.218)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7239.702  (957.628)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7305.668  (923.048)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7239.702  (958.036)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7305.668  (924.390)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7305.668{col 26}{space 2} 924.3896{col 37}{space 1}    7.90{col 46}{space 3}0.000{col 54}{space 4} 5493.898{col 67}{space 3} 9117.438
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7305.6677 7159.6733 7159.6733 7305.6677 7451.6621 7451.6621
{txt}

{pstd}Examine the standard ({cmd:pystacked}) stacking weights as well as the {opt ddml} short-stacking weights.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .10215168    .07857077    .12573259
{txt}lassocv {res}           2    .25006817    .27612194    .22401441
{txt}ridgecv {res}           3    .00009901    5.472e-19    .00019802
{txt}     rf {res}           4    3.351e-17    5.107e-18    6.192e-17
{txt}     rf {res}           5    .64768114     .6453073    .65005498
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .12927046     .1525836    .10595731
{txt}lassocv {res}           2    .02219836            0    .04439672
{txt}ridgecv {res}           3    .13196658    .06929693    .19463623
{txt}     rf {res}           4    .73034407    .83795984    .62272829
{txt}     rf {res}           5    .04457685            0     .0891537
{reset}{res}{txt}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .00136454    .00272908    5.696e-18
{txt}lassocv {res}           2    .00003223    .00006446            0
{txt}ridgecv {res}           3    .28865826    .28855704    .28875948
{txt}     rf {res}           4    3.876e-17    7.286e-17    4.662e-18
{txt}     rf {res}           5    .70994496    .70864941    .71124052
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .11180479    .07224495    .15136463
{txt}lassocv {res}           2            0            0            0
{txt}ridgecv {res}           3            0            0            0
{txt}     rf {res}           4    .88819521    .92775505    .84863537
{txt}     rf {res}           5            0            0            0
{reset}{res}{txt}

{pstd}Replicate the {opt ddml estimate} short-stacking results for resample 2 by hand,
using the estimated conditional expectations generated by {opt ddml},
and compare using {opt ddml estimate, replay}:{p_end}

{input}. cap drop Yresid
{txt}
{input}. cap drop Dresid
{txt}
{input}. gen double Yresid = $Y - Y_net_tfa_ss_2
{txt}
{input}. gen double Dresid = $D - D_e401_ss_2
{txt}
{input}. regress Yresid Dresid, robust

{txt}Linear regression                               Number of obs     = {res}     9,915
                                                {txt}F(1, 9913)        =  {res}    65.12
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.0080
                                                {txt}Root MSE          =    {res}  35262

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 7159.673{col 26}{space 2} 887.2183{col 37}{space 1}    8.07{col 46}{space 3}0.000{col 54}{space 4} 5420.545{col 67}{space 3} 8898.802
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-286.1348{col 26}{space 2} 354.2125{col 37}{space 1}   -0.81{col 46}{space 3}0.419{col 54}{space 4}-980.4633{col 67}{space 3} 408.1936
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{input}. ddml estimate, mname(m0) spec(ss) rep(2) notable replay
{res}
{txt}Shortstack DDML model (sample=2)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss_2{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss_2 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7159.673{col 26}{space 2} 887.2183{col 37}{space 1}    8.07{col 46}{space 3}0.000{col 54}{space 4} 5420.757{col 67}{space 3} 8898.589
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-286.1348{col 26}{space 2} 354.2125{col 37}{space 1}   -0.81{col 46}{space 3}0.419{col 54}{space 4}-980.3785{col 67}{space 3} 408.1088
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Obtain the estimated coefficient using ridge - the 3rd {help pystacked} learner - 
as the only learner for the 2nd cross-fit estimation (resample 2),
using the estimated conditional expectations generated by {opt ddml} and {help pystacked}.
This can be done using {opt ddml estimate} with the {opt y(.)} and {opt d(.)} options:
"L3" means the 3rd learner and "_2" means resample 2.
Then replicate by hand.{p_end}

{input}. ddml estimate, y(Y1_pystacked_L3_2) d(D1_pystacked_L3_2) robust
{res}
{txt}y-E[y|X]{col 11}= {res}Y1_pystacked_L3_2{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D1_pystacked_L3_2
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 4941.948{col 26}{space 2} 1075.687{col 37}{space 1}    4.59{col 46}{space 3}0.000{col 54}{space 4}  2833.64{col 67}{space 3} 7050.256
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-11.61225{col 26}{space 2} 394.8504{col 37}{space 1}   -0.03{col 46}{space 3}0.977{col 54}{space 4}-785.5048{col 67}{space 3} 762.2803
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{txt}
{input}. cap drop Yresid
{txt}
{input}. cap drop Dresid
{txt}
{input}. gen double Yresid = $Y - Y1_pystacked_L3_2
{txt}
{input}. gen double Dresid = $D - D1_pystacked_L3_2
{txt}
{input}. regress Yresid Dresid, robust

{txt}Linear regression                               Number of obs     = {res}     9,915
                                                {txt}F(1, 9913)        =  {res}    21.11
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.0032
                                                {txt}Root MSE          =    {res}  39313

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 4941.948{col 26}{space 2} 1075.687{col 37}{space 1}    4.59{col 46}{space 3}0.000{col 54}{space 4} 2833.382{col 67}{space 3} 7050.513
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-11.61225{col 26}{space 2} 394.8504{col 37}{space 1}   -0.03{col 46}{space 3}0.977{col 54}{space 4}-785.5993{col 67}{space 3} 762.3748
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:14:39

Help file: ddml_example_partial_anylearner_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:14:39
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear model - Detailed general example with multiple learners} 

{pstd}Here we used {opt ddml} to add learners. This allows use of learners not supported by,
or as alternatives to, those available via {help pystacked}.
It is also possible to use {help pystacked} as a standalone learner in this way.{p_end}

{pstd}Preparation: load the data and define the globals.
Use the name "m1" for this new estimation, 
to distinguish it from any model estimated previously that uses the default name "m0".
This enables having multiple estimations available for comparison.
We also use the {opt prefix} option of {help ddml init}
so that all the estimated conditional expectations will be prefixed with the model name,
i.e., the names of all created variables will start with "m1".
This avoids overwriting any variables created for some other model using default naming.
Also specify 5 resamplings.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(2) reps(5) mname(m1) prefix
{res}{txt}

{pstd}We add supervised machine learners for estimating the conditional expectation E[Y|X].
In each step, we add the {opt mname(m1)} option to ensure that the learners are added to correct model.{p_end}

{pstd} We first add simple linear regression.{p_end}

{input}. ddml E[Y|X], mname(m1): reg $Y $X
{res}{txt}Learner m1_Y1_reg added successfully.
{txt}

{pstd}We can add more than one learner per reduced form equation.
Here, we add a random forest learner.
We do this using {help pystacked} to implement a single learner.{p_end}

{input}. ddml E[Y|X], mname(m1): pystacked $Y $X, type(reg) method(rf)
{res}{txt}Learner m1_Y2_pystacked added successfully.
{txt}

{pstd}We do the same for the conditional expectation E[D|X].{p_end}

{input}. ddml E[D|X], mname(m1): reg $D $X
{res}{txt}Learner m1_D1_reg added successfully.
{txt}
{input}. ddml E[D|X], mname(m1): pystacked $D $X, type(reg) method(rf)
{res}{txt}Learner m1_D2_pystacked added successfully.
{txt}

{pstd}Check if learners were correctly added:{p_end}

{input}. ddml desc, mname(m1) learners
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}m1_Y1_reg m1_Y2_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}m1_D1_reg m1_D2_pystacked

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}m1_Y1_reg
{col 15}est cmd: reg net_tfa tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}m1_Y2_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}m1_D1_reg
{col 15}est cmd: reg e401 tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}m1_D2_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)
{txt}

{pstd}Cross-fitting and estimation.
Since we added two learners for each of our two reduced form equations, 
there are four possible specifications. 
By default, the result shown corresponds to the specification 
with the lowest out-of-sample MSPE:{p_end}

{input}. ddml crossfit, mname(m1)
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate, mname(m1) robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}m1_Y1_reg m1_Y2_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}m1_D1_reg m1_D2_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(mse) rep(1) notable replay: mse  1}{res} m1_Y2_pysta~d     m1_D1_reg  6934.059 (1115.680)
{stata ddml estimate, mname(m1) spec(mse) rep(2) notable replay: mse  2} m1_Y2_pysta~d     m1_D1_reg  7568.943  (961.984)
{stata ddml estimate, mname(m1) spec(mse) rep(3) notable replay: mse  3} m1_Y2_pysta~d     m1_D1_reg  6763.292  (938.991)
{stata ddml estimate, mname(m1) spec(mse) rep(4) notable replay: mse  4} m1_Y2_pysta~d     m1_D1_reg  6696.469 (1001.911)
{stata ddml estimate, mname(m1) spec(mse) rep(5) notable replay: mse  5} m1_Y2_pysta~d     m1_D1_reg  6410.047 (1113.142)
{txt}mse = minimum MSE specification for that resample.

Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(mse) rep(mn) notable replay noconstant: mse mn}     {res}[min-mse]     [min-mse]  6874.562 (1080.461)
{stata ddml estimate, mname(m1) spec(mse) rep(md) notable replay noconstant: mse md}     [min-mse]     [min-mse]  6763.292 (1128.673)

{txt}Median over 5 min-mse resamples
y-E[y|X]{col 11}= {res}y-md_net_tfa_mse{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-md_e401_mse 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6763.292{col 26}{space 2} 1128.673{col 37}{space 1}    5.99{col 46}{space 3}0.000{col 54}{space 4} 4551.134{col 67}{space 3}  8975.45
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 6874.5621 6410.0474 6696.4688 6763.2920 6934.0591 7568.9434
{txt}

{pstd}To estimate all four specifications, we use the {cmd:allcombos} option:{p_end}

{input}. ddml estimate, mname(m1) robust allcombos
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}m1_Y1_reg m1_Y2_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}m1_D1_reg m1_D2_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{res} {stata ddml estimate, mname(m1) spec(1) rep(1) notable replay:  1  1}     m1_Y1_reg     m1_D1_reg  5397.208 (1130.776)
 {stata ddml estimate, mname(m1) spec(2) rep(1) notable replay:  2  1}     m1_Y1_reg m1_D2_pysta~d  6651.343  (892.371)
*{stata ddml estimate, mname(m1) spec(3) rep(1) notable replay:  3  1} m1_Y2_pysta~d     m1_D1_reg  6934.059 (1115.680)
 {stata ddml estimate, mname(m1) spec(4) rep(1) notable replay:  4  1} m1_Y2_pysta~d m1_D2_pysta~d  6948.286  (773.032)
 {stata ddml estimate, mname(m1) spec(1) rep(2) notable replay:  1  2}     m1_Y1_reg     m1_D1_reg  4941.948 (1075.687)
 {stata ddml estimate, mname(m1) spec(2) rep(2) notable replay:  2  2}     m1_Y1_reg m1_D2_pysta~d  6429.783  (920.446)
*{stata ddml estimate, mname(m1) spec(3) rep(2) notable replay:  3  2} m1_Y2_pysta~d     m1_D1_reg  7568.943  (961.984)
 {stata ddml estimate, mname(m1) spec(4) rep(2) notable replay:  4  2} m1_Y2_pysta~d m1_D2_pysta~d  7049.313  (843.588)
 {stata ddml estimate, mname(m1) spec(1) rep(3) notable replay:  1  3}     m1_Y1_reg     m1_D1_reg  5054.250 (1082.173)
 {stata ddml estimate, mname(m1) spec(2) rep(3) notable replay:  2  3}     m1_Y1_reg m1_D2_pysta~d  6201.805  (873.064)
*{stata ddml estimate, mname(m1) spec(3) rep(3) notable replay:  3  3} m1_Y2_pysta~d     m1_D1_reg  6763.292  (938.991)
 {stata ddml estimate, mname(m1) spec(4) rep(3) notable replay:  4  3} m1_Y2_pysta~d m1_D2_pysta~d  6282.347  (769.125)
 {stata ddml estimate, mname(m1) spec(1) rep(4) notable replay:  1  4}     m1_Y1_reg     m1_D1_reg  4496.728 (1113.339)
 {stata ddml estimate, mname(m1) spec(2) rep(4) notable replay:  2  4}     m1_Y1_reg m1_D2_pysta~d  6305.684  (919.015)
*{stata ddml estimate, mname(m1) spec(3) rep(4) notable replay:  3  4} m1_Y2_pysta~d     m1_D1_reg  6696.469 (1001.911)
 {stata ddml estimate, mname(m1) spec(4) rep(4) notable replay:  4  4} m1_Y2_pysta~d m1_D2_pysta~d  6914.925  (874.286)
 {stata ddml estimate, mname(m1) spec(1) rep(5) notable replay:  1  5}     m1_Y1_reg     m1_D1_reg  5264.462 (1097.929)
 {stata ddml estimate, mname(m1) spec(2) rep(5) notable replay:  2  5}     m1_Y1_reg m1_D2_pysta~d  6231.522  (929.780)
*{stata ddml estimate, mname(m1) spec(3) rep(5) notable replay:  3  5} m1_Y2_pysta~d     m1_D1_reg  6410.047 (1113.142)
 {stata ddml estimate, mname(m1) spec(4) rep(5) notable replay:  4  5} m1_Y2_pysta~d m1_D2_pysta~d  6310.288  (813.804)
*{txt} = minimum MSE specification for that resample.

Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(1) rep(mn) notable replay noconstant:   1 mn}     {res}m1_Y1_reg     m1_D1_reg  5030.919 (1136.789)
{stata ddml estimate, mname(m1) spec(1) rep(md) notable replay noconstant:   1 md}     m1_Y1_reg     m1_D1_reg  5054.250 (1117.872)
{stata ddml estimate, mname(m1) spec(2) rep(mn) notable replay noconstant:   2 mn}     m1_Y1_reg m1_D2_pysta~d  6364.027  (921.100)
{stata ddml estimate, mname(m1) spec(2) rep(md) notable replay noconstant:   2 md}     m1_Y1_reg m1_D2_pysta~d  6305.684  (928.774)
{stata ddml estimate, mname(m1) spec(3) rep(mn) notable replay noconstant:   3 mn} m1_Y2_pysta~d     m1_D1_reg  6874.562 (1080.461)
{stata ddml estimate, mname(m1) spec(3) rep(md) notable replay noconstant:   3 md} m1_Y2_pysta~d     m1_D1_reg  6763.292 (1128.673)
{stata ddml estimate, mname(m1) spec(4) rep(mn) notable replay noconstant:   4 mn} m1_Y2_pysta~d m1_D2_pysta~d  6701.032  (878.130)
{stata ddml estimate, mname(m1) spec(4) rep(md) notable replay noconstant:   4 md} m1_Y2_pysta~d m1_D2_pysta~d  6914.925  (874.286)
{stata ddml estimate, mname(m1) spec(mse) rep(mn) notable replay noconstant: mse mn}     [min-mse]     [min-mse]  6874.562 (1080.461)
{stata ddml estimate, mname(m1) spec(mse) rep(md) notable replay noconstant: mse md}     [min-mse]     [min-mse]  6763.292 (1128.673)

{txt}Median over 5 min-mse resamples
y-E[y|X]{col 11}= {res}y-md_net_tfa_mse{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-md_e401_mse 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6763.292{col 26}{space 2} 1128.673{col 37}{space 1}    5.99{col 46}{space 3}0.000{col 54}{space 4} 4551.134{col 67}{space 3}  8975.45
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 6874.5621 6410.0474 6696.4688 6763.2920 6934.0591 7568.9434
{txt}

{pstd}After having estimated all specifications, we can retrieve 
specific results. Here we use the specification relying on OLS for both
estimating both E[Y|X] and E[D|X], from the 4th cross-fit split ({opt rep(4))}.
(Note: Working interactively, the simplest way to do this
is to click on the hyperlink in the summary table in the {opt ddml estimate} output above.)
The {opt notable} option suppresses the summary table:{p_end}

{input}. ddml estimate, mname(m1) spec(1) rep(4) replay notable
{res}
{txt}DDML model, specification 1 (sample=4)
y-E[y|X]{col 11}= {res}y-m1_Y1_reg_4{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-m1_D1_reg_4 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 4496.728{col 26}{space 2} 1113.339{col 37}{space 1}    4.04{col 46}{space 3}0.000{col 54}{space 4} 2314.623{col 67}{space 3} 6678.834
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-41.08484{col 26}{space 2} 399.6619{col 37}{space 1}   -0.10{col 46}{space 3}0.918{col 54}{space 4}-824.4078{col 67}{space 3} 742.2381
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}

{pstd}You could manually retrieve the same point estimate by 
cacluating the orthogonalized versions of {opt net_tfa} and {opt e401}
from the 4th cross-fit estimation and then using {help regress}.
Recall that we used the {opt prefix} option with {help ddml init},
so the variable names start with "m1".{p_end}

{input}. cap drop Yresid
{txt}
{input}. cap drop Dresid
{txt}
{input}. gen double Yresid = $Y - m1_Y1_reg_4
{txt}
{input}. gen double Dresid = $D - m1_D1_reg_4
{txt}
{input}. regress Yresid Dresid, robust

{txt}Linear regression                               Number of obs     = {res}     9,915
                                                {txt}F(1, 9913)        =  {res}    16.31
                                                {txt}Prob > F          = {res}    0.0001
                                                {txt}R-squared         = {res}    0.0026
                                                {txt}Root MSE          =    {res}  39790

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2} 4496.728{col 26}{space 2} 1113.339{col 37}{space 1}    4.04{col 46}{space 3}0.000{col 54}{space 4} 2314.357{col 67}{space 3}   6679.1
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-41.08484{col 26}{space 2} 399.6619{col 37}{space 1}   -0.10{col 46}{space 3}0.918{col 54}{space 4}-824.5035{col 67}{space 3} 742.3338
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}{txt}

{pstd}You can also compare the estimated conditional expectations graphically:{p_end}

{input}. twoway (scatter $Y m1_Y2_pystacked_4) 
{res}{txt}

{pstd}To describe the ddml model setup or results in detail,
you can use {cmd: ddml describe} with the relevant option ({opt sample}, {opt learners}, {opt crossfit}, {opt estimates}),
or just describe them all with the {opt all} option:{p_end}

{input}. ddml describe, mname(m1) all
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=5
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}m1_Y1_reg m1_Y2_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}m1_D1_reg m1_D2_pystacked
{txt}Specifications:{col 25}{res}4 possible specs * 5 crossfit splits = 20

{txt}ID:{col 25}{res}m1_id
{txt}Full sample indic.:{col 25}{res}m1_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m1_fid_1    m1_fid_2    m1_fid_3    m1_fid_4    m1_fid_5  
{txt}Fold sample indic.:{col 25}{res}m1_sample_1 m1_sample_2 m1_sample_3 m1_sample_4 m1_sample_5 
{txt}Estimation N:{col 25}    {res}9915        9915        9915        9915        9915    

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}m1_Y1_reg
{col 15}est cmd: reg net_tfa tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}m1_Y2_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}m1_D1_reg
{col 15}est cmd: reg e401 tw age inc fsize educ db marr twoearn pira hown
{col 2}Learner:{col 15}m1_D2_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown, type(reg) method(rf)

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}

{txt}Median over 5 min-mse resamples
y-E[y|X]{col 11}= {res}y-md_net_tfa_mse{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-md_e401_mse 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6763.292{col 26}{space 2} 1128.673{col 37}{space 1}    5.99{col 46}{space 3}0.000{col 54}{space 4} 4551.134{col 67}{space 3}  8975.45
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 6874.5621 6410.0474 6696.4688 6763.2920 6934.0591 7568.9434
{txt}

{pstd}If there is a previously-estimated {opt ddml} model called "m0",
we can load it using {opt ddml estimate} with the {opt mname(m0)} and {opt replay} options and compare.{p_end}

{input}. ddml estimate, mname(m0) replay
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}{res}  Y1_pystacked  D1_pystacked  7451.662  (937.660)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7451.662  (937.660)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  Y1_pystacked  D1_pystacked  7159.673  (887.218)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7159.673  (887.218)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}{res}  Y1_pystacked  D1_pystacked  7305.668  (923.048)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7305.668  (923.048)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  Y1_pystacked  D1_pystacked  7305.668  (924.390)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7305.668  (924.390)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7305.668{col 26}{space 2} 924.3896{col 37}{space 1}    7.90{col 46}{space 3}0.000{col 54}{space 4} 5493.898{col 67}{space 3} 9117.438
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7305.6677 7159.6733 7159.6733 7305.6677 7451.6621 7451.6621
{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:16:21

Help file: ddml_example_partial_pystacked_multitreat.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:16:21
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear model - Multiple treatments with {help pystacked}}

{pstd}We can also run the partially-linear model with multiple treatments. 
In this simple example, we estimate the effect of both 401k elligibility 
{cmd:e401} and education {cmd:educ}. 
Note that we remove {cmd:educ} from the set of controls.
We again use {help pystacked} as the single learner provided to {opt ddml};
the two base learners, OLS and random forest, are provided via {help pystacked}.
We use the simplified syntax supported by {help pystacked}.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D1 e401
{txt}
{input}. global D2 educ
{txt}
{input}. global X tw age inc fsize db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}

{pstd}Initialize the model.{p_end}

{input}. ddml init partial, kfolds(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}Add learners. Note that we add learners with both {cmd:$D1} and
{cmd:$D2} as the dependent variable.{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) methods(ols rf)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D1 $X, type(reg) methods(ols rf)
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D2 $X, type(reg) methods(ols rf)
{res}{txt}Learner D2_pystacked added successfully.
{txt}

{pstd}Cross-fitting.{p_end}

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: educ
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}

{pstd}Estimation.{p_end}

{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (2):{col 25}{res}e401 educ
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked
{txt}{col 2}educ learners:{col 25}{res}D2_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6575.235 (1011.846)  D2_pystacked   -13.817  (180.738)

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D1-D1_pystacked_1 D2-D2_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 6575.235{col 26}{space 2} 1011.846{col 37}{space 1}    6.50{col 46}{space 3}0.000{col 54}{space 4} 4592.054{col 67}{space 3} 8558.416
{txt}{space 8}educ {c |}{col 14}{res}{space 2}-13.81744{col 26}{space 2}  180.738{col 37}{space 1}   -0.08{col 46}{space 3}0.939{col 54}{space 4}-368.0574{col 67}{space 3} 340.4225
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-225.6904{col 26}{space 2} 357.6214{col 37}{space 1}   -0.63{col 46}{space 3}0.528{col 54}{space 4}-926.6154{col 67}{space 3} 475.2347
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Because we have used {help pystacked} as the single {opt ddml} learner,
we can access the saved {opt pystacked} information.
Here we use the {opt pystacked} option to get the stacking weights and MSEs by cross-fit fold:{p_end}

{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for D1_pystacked (e401)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  .72587155  .71142712
{txt} rf {res}         2          1  .27412845  .28857288
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}         learner  mean_weight        rep_1
ols {res}           1    .71864934    .71864934
{txt} rf {res}           2    .28135066    .28135066
{reset}
{res}pystacked MSEs for D1_pystacked (e401)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1   .2050931  .19752967
{txt} rf {res}         2          1  .21760044  .20899576
{reset}
{res}mean stacking MSEs across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}       learner   mean_MSE      rep_1
ols {res}         1  .20131139  .20131139
{txt} rf {res}         2   .2132981   .2132981
{reset}
{res}pystacked weights for D2_pystacked (educ)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  .56766281  .62100559
{txt} rf {res}         2          1  .43233719  .37899441
{reset}
{res}mean stacking weights across folds/resamples for D2_pystacked (educ)
{res}final stacking estimator: nnls1
{txt}         learner  mean_weight        rep_1
ols {res}           1     .5943342     .5943342
{txt} rf {res}           2     .4056658     .4056658
{reset}
{res}pystacked MSEs for D2_pystacked (educ)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  6.1283809  5.9179008
{txt} rf {res}         2          1  6.2683575  6.1781066
{reset}
{res}mean stacking MSEs across folds/resamples for D2_pystacked (educ)
{res}final stacking estimator: nnls1
{txt}       learner   mean_MSE      rep_1
ols {res}         1  6.0231408  6.0231408
{txt} rf {res}         2  6.2232321  6.2232321
{reset}
{res}pystacked weights for Y1_pystacked (net_tfa)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  .52681726   .2326513
{txt} rf {res}         2          1  .47318274   .7673487
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}         learner  mean_weight        rep_1
ols {res}           1    .37973428    .37973428
{txt} rf {res}           2    .62026572    .62026572
{reset}
{res}pystacked MSEs for Y1_pystacked (net_tfa)
{txt}       learner   resample     fold_1     fold_2
ols {res}         1          1  1.524e+09  1.558e+09
{txt} rf {res}         2          1  1.553e+09  1.224e+09
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}       learner   mean_MSE      rep_1
ols {res}         1  1.541e+09  1.541e+09
{txt} rf {res}         2  1.388e+09  1.388e+09
{reset}{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:18:10

Help file: ddml_example_interactive_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:18:10
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Interactive model - Basic example with {help pystacked}}{p_end}

{pstd}We need to estimate the conditional expectations of E[Y|X,D=0], E[Y|X,D=1] and E[D|X].
The first two conditional expectations are added jointly.
We use 5 cross-fit folds and 2 resamplings
(more resamplings would be advisable; we use 2 in this example so the code runs faster).
We specify two supervised learners: linear regression and gradient boosted
trees, stacked using {help pystacked}.
We use {help pystacked}'s 2nd syntax and stack using the single-best learner
(rather than the default constrained least squares).
Note that we use gradient boosted regression trees for E[Y|X,D],
but gradient boosted classification trees for E[D|X].{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
{txt}
{input}. global Y bweight
{txt}
{input}. global D mbsmoke
{txt}
{input}. global X prenatal1 mmarried fbaby mage medu
{txt}
{input}. set seed 42
{txt}
{input}. ddml init interactive, kfolds(5) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X,D]: pystacked $Y $X || method(ols) || method(gradboost) || , type(reg) finalest(singlebest)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X || method(logit) || method(gradboost) || , type(class) finalest(singlebest)
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}

{pstd}{opt ddml estimate} reports the ATE (average treatment effect) by default:{p_end}

{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -207.548   (32.276)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -212.145   (29.030)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -209.846   (30.612)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -209.846   (30.782)

{txt}Median over 2 stacking resamples (ATE)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-209.8464{col 26}{space 2} 30.78171{col 37}{space 1}   -6.82{col 46}{space 3}0.000{col 54}{space 4}-270.1774{col 67}{space 3}-149.5154
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}singlebest
Warning{txt}: 2 resamples had propensity scores trimmed to lower limit .01.

Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -209.8464 -212.1452 -212.1452 -209.8464 -207.5476 -207.5476
{txt}

{pstd}Request the ATET (average treatment effect on the treated) instead:{p_end}

{input}. ddml estimate, atet
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATET):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -234.766   (24.667)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -231.387   (25.228)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -233.077   (25.000)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -233.077   (25.006)

{txt}Median over 2 stacking resamples (ATET)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-233.0769{col 26}{space 2} 25.00582{col 37}{space 1}   -9.32{col 46}{space 3}0.000{col 54}{space 4}-282.0874{col 67}{space 3}-184.0664
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}singlebest
Warning{txt}: 2 resamples had propensity scores trimmed to lower limit .01.

Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -233.0769 -234.7664 -234.7664 -233.0769 -231.3873 -231.3873
{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:20:56

Help file: ddml_example_interactive_pystacked_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:20:56
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Interactive model - Detailed example with {help pystacked}}{p_end}

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
{txt}
{input}. global Y bweight
{txt}
{input}. global D mbsmoke
{txt}
{input}. global X prenatal1 mmarried fbaby mage medu
{txt}
{input}. set seed 42
{txt}

{pstd}We use 5 folds and 5 resamplings; that is, 
we estimate the model 5 times using randomly chosen folds.{p_end}

{input}. ddml init interactive, kfolds(5) reps(5)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}We need to estimate the conditional expectations of E[Y|X,D=0], 
E[Y|X,D=1] and E[D|X]. The first two conditional expectations 
are added jointly.{p_end} 
{pstd}We consider two supervised learners: linear regression and gradient boosted
trees, stacked using {helpb pystacked}.
Note that we use gradient boosted regression trees for E[Y|X,D], but
gradient boosted classification trees for E[D|X].{p_end}

{input}. ddml E[Y|X,D]: pystacked $Y $X, type(reg) methods(ols gradboost)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X, type(class) methods(logit gradboost)
{res}{txt}Learner D1_pystacked added successfully.
{txt}

{pstd}Cross-fitting and short-stacking:{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}

{pstd}In the final estimation step, we can estimate
the average treatment effect (the default),
the average treatment effect on the treated ({opt atet}),
or the average treatment effect on the untreated ({opt ateu}).{p_end}

{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.583   (26.027)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]  -216.277   (26.756)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.967   (25.586)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]          [ss]  -218.975   (25.913)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -227.103   (26.256)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]          [ss]  -225.686   (26.477)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -221.207   (25.830)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]          [ss]  -221.029   (26.590)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -224.497   (25.840)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]          [ss]  -222.705   (26.775)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -222.672   (26.045)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}  [shortstack]          [ss]          [ss]  -220.934   (26.685)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -221.207   (26.049)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  [shortstack]          [ss]          [ss]  -221.029   (26.828)

{txt}Shortstack DDML model (median over 5 resamples) (ATE)
E[y|X,D=0]{col 14}= {res}Y_bweight_ss0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y_bweight_ss1
{txt}E[D|X]{col 14}= {res}D_mbsmoke_ss
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-221.0291{col 26}{space 2}  26.8275{col 37}{space 1}   -8.24{col 46}{space 3}0.000{col 54}{space 4}  -273.61{col 67}{space 3}-168.4481
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -220.9344 -225.6861 -222.7047 -221.0291 -218.9749 -216.2772
{txt}
{input}. ddml estimate, atet
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATET):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -228.281   (23.768)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]  -230.567   (23.983)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -226.403   (24.073)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]          [ss]  -227.182   (24.275)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -235.118   (23.866)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]          [ss]  -235.587   (23.948)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -233.333   (23.664)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]          [ss]  -235.966   (23.885)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -230.264   (23.649)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]          [ss]  -231.205   (23.924)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -230.680   (24.010)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}  [shortstack]          [ss]          [ss]  -232.101   (24.222)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -230.264   (23.862)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  [shortstack]          [ss]          [ss]  -231.205   (24.346)

{txt}Shortstack DDML model (median over 5 resamples) (ATET)
E[y|X,D=0]{col 14}= {res}Y_bweight_ss0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y_bweight_ss1
{txt}E[D|X]{col 14}= {res}D_mbsmoke_ss
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-231.2049{col 26}{space 2} 24.34589{col 37}{space 1}   -9.50{col 46}{space 3}0.000{col 54}{space 4} -278.922{col 67}{space 3}-183.4878
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -232.1014 -235.9659 -235.5873 -231.2049 -230.5669 -227.1821
{txt}
{input}. ddml estimate, ateu
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATEU):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -217.251   (28.232)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]  -212.719   (29.192)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.203   (27.646)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]          [ss]  -216.588   (28.080)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -225.630   (28.379)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]          [ss]  -223.817   (28.658)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -218.507   (27.799)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]          [ss]  -217.692   (28.808)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -223.173   (27.779)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]          [ss]  -220.725   (29.005)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.753   (28.132)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay:  ss mn}  [shortstack]          [ss]          [ss]  -218.308   (28.977)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.203   (28.061)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay:  ss md}  [shortstack]          [ss]          [ss]  -217.692   (29.163)

{txt}Shortstack DDML model (median over 5 resamples) (ATEU)
E[y|X,D=0]{col 14}= {res}Y_bweight_ss0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y_bweight_ss1
{txt}E[D|X]{col 14}= {res}D_mbsmoke_ss
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-217.6923{col 26}{space 2} 29.16286{col 37}{space 1}   -7.46{col 46}{space 3}0.000{col 54}{space 4}-274.8504{col 67}{space 3}-160.5341
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -218.3081 -223.8169 -220.7247 -217.6923 -216.5880 -212.7186
{txt}

{pstd}Recall that we have specified 5 resampling iterations ({opt reps(5)})
By default, the median over short-stacked resampling iterations is shown.
At the bottom, a table of summary statistics over resampling iterations is shown. 
To display the mean over standard stacking results, i.e.,
the results where the weights derive from {helpb pystacked} and vary by cross-fit fold,
we use {opt ddml estimate, replay} with {opt spec(st)} and {opt rep(mn)}.{p_end}

{input}. ddml estimate, spec(st) rep(mn) notable replay
{res}
{txt}Mean over 5 stacking resamples (ATEU)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-220.7528{col 26}{space 2}  28.1325{col 37}{space 1}   -7.85{col 46}{space 3}0.000{col 54}{space 4}-275.8914{col 67}{space 3}-165.6141
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -220.7528 -225.6302 -223.1726 -219.2034 -218.5068 -217.2508
{txt}

{pstd}Generate an overlap plot using {opt ddml overlap}:{p_end}

{input}. ddml overlap
{res}{txt}

{pstd}Report the standard stacking and short-stacking weights:{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for Y1_pystacked (bweight)
{res}final stacking estimator: nnls1
{txt}               learner        D=0/1  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1            0    .96570242     .9999956    .96016968    .97196735    .95501857    .94136089
{txt}gradboost {res}           2            0    .03429267    3.982e-11    .03983032    .02802434    .04496957    .05863911
{txt}      ols {res}           1            1    .94773816    .95897886    .97302404    .94535865    .92548652    .93584273
{txt}gradboost {res}           2            1    .05226184    .04102114    .02697596    .05464135    .07451348    .06415727
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (mbsmoke)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
    logit {res}           1    .26469509    .27914461    .25411088    .25036705    .25768503    .28216788
{txt}gradboost {res}           2    .73530491    .72085539    .74588912    .74963295    .74231497    .71783212
{reset}{res}{txt}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for bweight
{res}final stacking estimator: nnls1
{txt}               learner        D=0/1  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1            0    .98382895            1            1    .99892026     .9202245            1
{txt}gradboost {res}           2            0    .01617105            0            0    .00107974     .0797755    4.591e-17
{txt}      ols {res}           1            1    .89125977    .84721895    .85802465    .91334299    .95738422    .88032805
{txt}gradboost {res}           2            1    .10874023    .15278105    .14197535    .08665701    .04261578    .11967195
{reset}
{res}short-stacked weights across resamples for mbsmoke
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
    logit {res}           1    .18611935     .1780141    .20142045    .21745899     .1598537     .1738495
{txt}gradboost {res}           2    .81388065     .8219859    .79857955    .78254101     .8401463     .8261505
{reset}{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:27:50

Help file: ddml_example_partialiv_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:27:50
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear IV model - Basic example with {help pystacked}} 

{pstd}The model has three conditional expectations: E[Y|X], E[D|X] and E[Z|X].
For each reduced form equation, we use {help pystacked}'s default learners: 
OLS, cross-validated lasso, and gradient boosting.
Since the data set is very small, we consider 30 cross-fitting folds.
NB: The model specification and results will be stored on a Mata object
with the default name "m0".{p_end}

{input}. use https://statalasso.github.io/dta/AJR.dta, clear
{txt}
{input}. global Y logpgp95
{txt}
{input}. global D avexpr
{txt}
{input}. global Z logem4
{txt}
{input}. global X lat_abst edes1975 avelf temp* humid* steplow-oilres
{txt}
{input}. set seed 42
{txt}
{input}. ddml init iv, kfolds(30)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml E[Z|X]: pystacked $Z $X
{res}{txt}Learner Z1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: logpgp95
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: avexpr
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[Z|X]: logem4
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}iv, crossfit folds k=30, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}logpgp95
{txt}{col 2}logpgp95 learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}avexpr
{txt}{col 2}avexpr learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}logem4
{txt}{col 2}logem4 learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked     2.376    (2.826)  Z1_pystacked

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z1_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2}  2.37577{col 26}{space 2} 2.826037{col 37}{space 1}    0.84{col 46}{space 3}0.401{col 54}{space 4}-3.163161{col 67}{space 3} 7.914701
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .1790394{col 26}{space 2} .5070894{col 37}{space 1}    0.35{col 46}{space 3}0.724{col 54}{space 4}-.8148375{col 67}{space 3} 1.172916
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Replicate the {opt ddml estimate} results for the 1st cross-fit estimation (resample 1) by hand,
using the estimated conditional expectations generated by {opt ddml} and {help pystacked};
"_1" means resample 1.
Compare using {opt ddml estimate, replay}.{p_end}

{input}. cap drop Yresid
{txt}
{input}. cap drop Dresid
{txt}
{input}. cap drop Zresid
{txt}
{input}. gen double Yresid = $Y - Y1_pystacked_1
{txt}
{input}. gen double Dresid = $D - D1_pystacked_1
{txt}
{input}. gen double Zresid = $Z - Z1_pystacked_1
{txt}
{input}. ivreg Yresid (Dresid=Zresid)

{txt}Instrumental variables (2SLS) regression

      Source {c |}       SS           df       MS      Number of obs   ={res}        64
{txt}{hline 13}{c +}{hline 34}   F(1, 62)        = {res}     0.71
{txt}       Model {c |} {res}-701.578378         1 -701.578378   {txt}Prob > F        ={res}    0.4038
{txt}    Residual {c |} {res} 738.231487        62  11.9069595   {txt}R-squared       ={res}         .
{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}         .
{txt}       Total {c |} {res} 36.6531083        63  .581795369   {txt}Root MSE        =   {res} 3.4506

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}      Yresid{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dresid {c |}{col 14}{res}{space 2}  2.37577{col 26}{space 2} 2.826037{col 37}{space 1}    0.84{col 46}{space 3}0.404{col 54}{space 4}-3.273398{col 67}{space 3} 8.024938
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .1790394{col 26}{space 2} .5070894{col 37}{space 1}    0.35{col 46}{space 3}0.725{col 54}{space 4}-.8346178{col 67}{space 3} 1.192697
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{p 0 15 38}Instrumented:{space 2}Dresid{p_end}
{p 0 15 38}Instruments:{space 3}Zresid{p_end}
{hline 78}
{txt}
{input}. ddml estimate, mname(m0) spec(st) rep(1) notable replay
{res}
{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z1_pystacked_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2}  2.37577{col 26}{space 2} 2.826037{col 37}{space 1}    0.84{col 46}{space 3}0.401{col 54}{space 4}-3.163161{col 67}{space 3} 7.914701
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .1790394{col 26}{space 2} .5070894{col 37}{space 1}    0.35{col 46}{space 3}0.724{col 54}{space 4}-.8148375{col 67}{space 3} 1.172916
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:32:56

Help file: ddml_example_partialiv_anylearner_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:32:56
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear IV model - Basic example with various learners} 

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. use https://statalasso.github.io/dta/AJR.dta, clear
{txt}
{input}. global Y logpgp95
{txt}
{input}. global D avexpr
{txt}
{input}. global Z logem4
{txt}
{input}. global X lat_abst edes1975 avelf temp* humid* steplow-oilres
{txt}
{input}. set seed 42
{txt}

{pstd}Preparation: we load the data, define global macros and set the seed. Since the
data set is very small, we consider 30 cross-fitting folds.{p_end}

{input}. ddml init iv, kfolds(30)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}The partially linear IV model has three conditional expectations: 
E[Y|X], E[D|X] and E[Z|X]. For each reduced form equation, we use two learners:
OLS and random forest.
To illustrate how {opt ddml} works with other packages,
instead of a single call to {opt pystacked} specifying two base learners
we specify Stata's {help regress} and {help rforest} by Zou and Schonlau as the two learners.
We need to add the option {opt vtype(none)} for {help rforest} to 
work with {cmd:ddml} since {help rforest}'s {cmd:predict} command doesn't
support variable types.{p_end}

{input}. ddml E[Y|X]: reg $Y $X
{res}{txt}Learner Y1_reg added successfully.
{txt}
{input}. ddml E[Y|X], vtype(none): rforest $Y $X, type(reg)
{res}{txt}Learner Y2_rforest added successfully.
{txt}
{input}. ddml E[D|X]: reg $D $X
{res}{txt}Learner D1_reg added successfully.
{txt}
{input}. ddml E[D|X], vtype(none): rforest $D $X, type(reg)
{res}{txt}Learner D2_rforest added successfully.
{txt}
{input}. ddml E[Z|X]: reg $Z $X
{res}{txt}Learner Z1_reg added successfully.
{txt}
{input}. ddml E[Z|X], vtype(none): rforest $Z $X, type(reg)
{res}{txt}Learner Z2_rforest added successfully.
{txt}

{pstd}Cross-fitting and estimation; report all combinations of estimated conditional expectations.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: logpgp95
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: avexpr
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[Z|X]: logem4
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust allcombos
{res}

{txt}Model:{col 25}{res}iv, crossfit folds k=30, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}logpgp95
{txt}{col 2}logpgp95 learners:{col 25}{res}Y1_reg Y2_rforest
{txt}D equations (1):{col 25}{res}avexpr
{txt}{col 2}avexpr learners:{col 25}{res}D1_reg D2_rforest
{txt}Z equations (1):{col 25}{res}logem4
{txt}{col 2}logem4 learners:{col 25}{res}Z1_reg Z2_rforest

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      Z learner
{res} {stata ddml estimate, mname(m0) spec(1) rep(1) notable replay:  1  1}        Y1_reg        D1_reg     0.378    (0.125)        Z1_reg
 {stata ddml estimate, mname(m0) spec(2) rep(1) notable replay:  2  1}        Y1_reg        D1_reg    -0.187    (1.573)    Z2_rforest
 {stata ddml estimate, mname(m0) spec(3) rep(1) notable replay:  3  1}        Y1_reg    D2_rforest     2.413    (3.594)        Z1_reg
 {stata ddml estimate, mname(m0) spec(4) rep(1) notable replay:  4  1}        Y1_reg    D2_rforest     0.083    (0.475)    Z2_rforest
 {stata ddml estimate, mname(m0) spec(5) rep(1) notable replay:  5  1}    Y2_rforest        D1_reg     0.123    (0.207)        Z1_reg
 {stata ddml estimate, mname(m0) spec(6) rep(1) notable replay:  6  1}    Y2_rforest        D1_reg    -1.749    (4.690)    Z2_rforest
 {stata ddml estimate, mname(m0) spec(7) rep(1) notable replay:  7  1}    Y2_rforest    D2_rforest     0.783    (0.504)        Z1_reg
*{stata ddml estimate, mname(m0) spec(8) rep(1) notable replay:  8  1}    Y2_rforest    D2_rforest     0.772    (0.207)    Z2_rforest
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]     0.716    (0.196)          [ss]
*{txt} = minimum MSE specification for that resample.

{res}{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_logpgp95_ss_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D_avexpr_ss_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z_logem4_ss_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2} .7158509{col 26}{space 2} .1958379{col 37}{space 1}    3.66{col 46}{space 3}0.000{col 54}{space 4} .3320156{col 67}{space 3} 1.099686
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0308504{col 26}{space 2} .0914997{col 37}{space 1}   -0.34{col 46}{space 3}0.736{col 54}{space 4}-.2101864{col 67}{space 3} .1484857
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}
	
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:33:14

Help file: ddml_example_flexiv_anylearner_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:33:14
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Flexible partially-linear IV model - Basic example with {help pystacked}}

{pstd}First load the data, define global macros, set the seed and initialize the model.
We add learners for E[Y|X] in the usual way.
We illustrate with single {help pystacked} estimations,
but the procedure applies to all learners.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/BLP.dta, clear
{txt}
{input}. global Y share
{txt}
{input}. global D price
{txt}
{input}. global X hpwt air mpd space
{txt}
{input}. global Z sum*
{txt}
{input}. set seed 42
{txt}
{input}. ddml init fiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}Adding learners for E[Y|X] is the same as for other {opt ddml} linear models:{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}

{pstd}Adding learners for E[D|Z,X] and E[D|X] in the {opt fiv} model is different
from how it's done in the {opt partialiv} model.
The reason for this is that the estimation of E[D|X]
depends on the estimation of E[D|X,Z].{p_end}

{pstd}When adding learners for E[D|Z,X],
we need to provide a name for each learners using {opt learner(name)}.
Here we use the name "Dhat_pys".{p_end}

{input}. ddml E[D|Z,X], learner(Dhat_pys): pystacked $D $X $Z, type(reg)
{res}{txt}Learner Dhat_pys added successfully.
{txt}

{pstd}When adding learners for E[D|X], we explicitly refer to the name of the learner from 
the previous step (here, "Dhat_pys").
We also provide the name of the treatment variable ({cmd:vname($D)}),
and we use the placeholder {cmd:{D}} in place of the dependent variable.{p_end}

{input}. ddml E[D|X], learner(Dhat_pys) vname($D): pystacked {D} $X, type(reg)
{res}{txt}Learner Dhat_pys_h added successfully.
{txt}

{pstd}The crossfit and estimation commands with the {opt fiv} model are standard.{p_end}

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}Dhat_pys

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked      Dhat_pys    -0.098    (0.008)    Dhat_pys_h

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-Dhat_pys_1 
{txt}E[D^|X]{col 11}= {res}Dhat_pys_h_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0079847{col 37}{space 1}  -12.26{col 46}{space 3}0.000{col 54}{space 4} -.113534{col 67}{space 3}-.0822344
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215635{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390072{col 67}{space 3} .0455204
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:34:09

Help file: ddml_example_flexiv_anylearner_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:34:09
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Flexible partially-linear IV model - Detailed example with {help pystacked}}

{pstd}Here will illustrate how to do standard- and short-stacking with the flexible IV model.{p_end}

{pstd}Note: Support for {help pystacked} integration is relatively limited for the flexible IV model.
In particular, short-stacking requires that individual learners appear in separate {help pystacked} commands,
pooled stacking is not available, and re-stacking with {opt ddml estimate} is also not available.{p_end}

{pstd}First we illustrate how to do standard stacking with {help pystacked}.
To start, we load the data, define global macros, set the seed and initialize the model.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/BLP.dta, clear
{txt}
{input}. global Y share
{txt}
{input}. global D price
{txt}
{input}. global X hpwt air mpd space
{txt}
{input}. global Z sum*
{txt}
{input}. set seed 42
{txt}
{input}. ddml init fiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}Adding learners for E[Y|X] is the same as for other {opt ddml} linear models:{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}

{pstd}Adding learners for E[D|Z,X] and E[D|X] in the {opt fiv} model is different
from how it's done in the {opt partialiv} model.
The reason for this is that the estimation of E[D|X]
depends on the estimation of E[D|X,Z].{p_end}

{pstd}When adding learners for E[D|Z,X],
we need to provide a name for each learners using {opt learner(name)}.
Here we use the name "Dhat_pys".{p_end}

{input}. ddml E[D|Z,X], learner(Dhat_pys): pystacked $D $X $Z, type(reg)
{res}{txt}Learner Dhat_pys added successfully.
{txt}

{pstd}When adding learners for E[D|X], we explicitly refer to the name of the learner from 
the previous step (here, "Dhat_pys").
We also provide the name of the treatment variable ({cmd:vname($D)}),
and we use the placeholder {cmd:{D}} in place of the dependent variable.{p_end}

{input}. ddml E[D|X], learner(Dhat_pys) vname($D): pystacked {D} $X, type(reg)
{res}{txt}Learner Dhat_pys_h added successfully.
{txt}

{pstd}The crossfit and estimation commands with the {opt fiv} model are standard.{p_end}

{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}Dhat_pys

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked      Dhat_pys    -0.098    (0.008)    Dhat_pys_h

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-Dhat_pys_1 
{txt}E[D^|X]{col 11}= {res}Dhat_pys_h_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0075085{col 37}{space 1}  -13.04{col 46}{space 3}0.000{col 54}{space 4}-.1126006{col 67}{space 3}-.0831678
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215627{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390055{col 67}{space 3} .0455187
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}The stacking weights and other results from {help pystacked} are available via {help ddml extract}.
Note this is only the case if {help pystacked} is the single learner in each equation.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for Dhat_pys (price)
{res}final stacking estimator: nnls1
{txt}               learner        h=0/1  mean_weight        rep_1
      ols {res}           1            0    .00029361    .00029361
{txt}  lassocv {res}           2            0    3.869e-16    3.869e-16
{txt}gradboost {res}           3            0    .99970639    .99970639
{txt}      ols {res}           1            1            0            0
{txt}  lassocv {res}           2            1            0            0
{txt}gradboost {res}           3            1            1            1
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1
      ols {res}           1    .01072127    .01072127
{txt}  lassocv {res}           2    .00089782    .00089782
{txt}gradboost {res}           3    .98838092    .98838092
{reset}{res}{txt}
{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for Dhat_pys (price)
{txt}             learner          h   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          0          1  .00146806          0          0          0          0
{txt}  lassocv {res}         2          0          1  2.899e-17          0          0  1.905e-15          0
{txt}gradboost {res}         3          0          1  .99853194          1          1          1          1
{txt}      ols {res}         1          1          1          0          0          0          0          0
{txt}  lassocv {res}         2          1          1          0          0          0          0          0
{txt}gradboost {res}         3          1          1          1          1          1          1          1
{reset}
{res}mean stacking weights across folds/resamples for Dhat_pys (price)
{res}final stacking estimator: nnls1
{txt}               learner        h=0/1  mean_weight        rep_1
      ols {res}           1            0    .00029361    .00029361
{txt}  lassocv {res}           2            0    3.869e-16    3.869e-16
{txt}gradboost {res}           3            0    .99970639    .99970639
{txt}      ols {res}           1            1            0            0
{txt}  lassocv {res}           2            1            0            0
{txt}gradboost {res}           3            1            1            1
{reset}
{res}pystacked MSEs for Dhat_pys (price)
{txt}             learner          h   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          0          1  29.117492  28.750566  28.599294  27.609091  27.984089
{txt}  lassocv {res}         2          0          1  29.105272  28.733296  28.611895  27.596867  27.974163
{txt}gradboost {res}         3          0          1  12.489515  11.066737    11.8996  11.454903  11.792511
{txt}      ols {res}         1          1          1  22.708623  21.869205  22.138751  21.559765  22.334953
{txt}  lassocv {res}         2          1          1  22.708698  21.869208   22.13965  21.560209  22.335081
{txt}gradboost {res}         3          1          1  8.5356607  7.7975507  8.9779883  7.6268412   8.967218
{reset}
{res}mean stacking MSEs across folds/resamples for Dhat_pys (price)
{res}final stacking estimator: nnls1
{txt}             learner      h=0/1   mean_MSE      rep_1
      ols {res}         1          0  28.412106  28.412106
{txt}  lassocv {res}         2          0  28.404299  28.404299
{txt}gradboost {res}         3          0  11.740653  11.740653
{txt}      ols {res}         1          1  22.122259  22.122259
{txt}  lassocv {res}         2          1  22.122569  22.122569
{txt}gradboost {res}         3          1  8.3810518  8.3810518
{reset}
{res}pystacked weights for Y1_pystacked (share)
{txt}             learner   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          1          0  9.888e-17  9.565e-19  .04108882  .01251751
{txt}  lassocv {res}         2          1  1.388e-17  2.429e-17  6.072e-17          0  .00448908
{txt}gradboost {res}         3          1          1          1          1  .95891118  .98299341
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1
      ols {res}           1    .01072127    .01072127
{txt}  lassocv {res}           2    .00089782    .00089782
{txt}gradboost {res}           3    .98838092    .98838092
{reset}
{res}pystacked MSEs for Y1_pystacked (share)
{txt}             learner   resample     fold_1     fold_2     fold_3     fold_4     fold_5
      ols {res}         1          1   1.410348  1.4521883  1.4141429  1.4309885  1.4682377
{txt}  lassocv {res}         2          1  1.4103449  1.4520901  1.4140542  1.4310193  1.4680032
{txt}gradboost {res}         3          1  1.1465506  1.2157637  1.1898038  1.2044167  1.2344672
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}             learner   mean_MSE      rep_1
      ols {res}         1  1.4351811  1.4351811
{txt}  lassocv {res}         2  1.4351023  1.4351023
{txt}gradboost {res}         3  1.1982004  1.1982004
{reset}{res}{txt}

{pstd}To replicate what {cmd:ddml} does in the background:{p_end}

{input}. cap drop Ytilde
{txt}
{input}. cap drop Dtilde
{txt}
{input}. cap drop Ztilde
{txt}
{input}. gen double Ytilde = $Y - Y1_pystacked_1
{txt}
{input}. gen Dtilde = $D - Dhat_pys_h_1
{txt}
{input}. gen Zopt = Dhat_pys_1 - Dhat_pys_h_1
{txt}
{input}. ivreg Ytilde (Dtilde=Zopt), robust

{txt}Instrumental variables (2SLS) regression        Number of obs     = {res}     2,217
                                                {txt}F(1, 2215)        =  {res}   169.95
                                                {txt}Prob > F          = {res}    0.0000
                                                {txt}R-squared         = {res}    0.1175
                                                {txt}Root MSE          =    {res} 1.0152

{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}      Ytilde{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      t{col 46}   P>|t|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}Dtilde {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0075085{col 37}{space 1}  -13.04{col 46}{space 3}0.000{col 54}{space 4}-.1126087{col 67}{space 3}-.0831598
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215627{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390286{col 67}{space 3} .0455418
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{p 0 15 38}Instrumented:{space 2}Dtilde{p_end}
{p 0 15 38}Instruments:{space 3}Zopt{p_end}
{hline 78}
{txt}

{pstd}Next we illustrate how to do short-stacking with the flexible IV model.
We again use {help pystacked}, but the procedure applies to any set of learners.
Here we use the same learners as in the standard stacking estimation with {help pystacked} above,
in order to facilitate direct comparison of the two sets of results.
We begin by re-initializing the model.{p_end}

{input}. set seed 42
{txt}
{input}. ddml init fiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}We add learners for E[Y|X] in the usual way,
but we need to specify each {help pystacked} learner in a separate equation.{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) m(ols)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) m(lassocv)
{res}{txt}Learner Y2_pystacked added successfully.
{txt}
{input}. ddml E[Y|X]: pystacked $Y $X, type(reg) m(gradboost)
{res}{txt}Learner Y3_pystacked added successfully.
{txt}

{pstd}
As above, when adding learners for E[D|Z,X],
we need to provide a name for each learner using {opt learner(name)}.{p_end}

{input}. ddml E[D|Z,X], learner(Dhat_ols): pystacked $D $X $Z, type(reg) m(ols)
{res}{txt}Learner Dhat_ols added successfully.
{txt}
{input}. ddml E[D|Z,X], learner(Dhat_lassocv): pystacked $D $X $Z, type(reg) m(lassocv)
{res}{txt}Learner Dhat_lassocv added successfully.
{txt}
{input}. ddml E[D|Z,X], learner(Dhat_gradboost): pystacked $D $X $Z, type(reg) m(gradboost)
{res}{txt}Learner Dhat_gradboost added successfully.
{txt}

{pstd}Again as above, when adding learners for E[D|X],
we explicitly refer to the learner from the previous step,
the name of the treatment variable ({cmd:vname($D)}),
and the placeholder {cmd:{D}} in place of the dependent variable.{p_end}

{input}. ddml E[D|X], learner(Dhat_ols) vname($D): pystacked {D} $X, type(reg) m(ols)
{res}{txt}Learner Dhat_ols_h added successfully.
{txt}
{input}. ddml E[D|X], learner(Dhat_lassocv) vname($D): pystacked {D} $X, type(reg) m(lassocv)
{res}{txt}Learner Dhat_lassocv_h added successfully.
{txt}
{input}. ddml E[D|X], learner(Dhat_gradboost) vname($D): pystacked {D} $X, type(reg) m(gradboost)
{res}{txt}Learner Dhat_gradboost_h added successfully.
{txt}
 
{pstd}Short-stacking is requested when cross-fitting.
Short-stacking weights can be examined using {help ddml extract}.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting{res}{txt}...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked Y2_pystacked Y3_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}Dhat_ols Dhat_lassocv Dhat_gradboost

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(mse) rep(1) notable replay: mse  1}{res}  Y3_pystacked Dhat_gradbo~t    -0.098    (0.008) Dhat_gradbo~h
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]    -0.097    (0.007)          [ss]
{txt}mse = minimum MSE specification for that resample.

{res}{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_share_ss_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-D_price_ss_1 
{txt}E[D^|X]{col 11}= {res}D_price_h_ss_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2} -.097427{col 26}{space 2} .0074744{col 37}{space 1}  -13.03{col 46}{space 3}0.000{col 54}{space 4}-.1120765{col 67}{space 3}-.0827775
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0034453{col 26}{space 2} .0215529{col 37}{space 1}    0.16{col 46}{space 3}0.873{col 54}{space 4}-.0387976{col 67}{space 3} .0456882
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for price
{res}final stacking estimator: nnls1
{txt}                  learner        h=0/1  mean_weight        rep_1
    Dhat_ols {res}           1            0            0            0
{txt}Dhat_lassocv {res}           2            0            0            0
{txt}Dhat_gradb~t {res}           3            0            1            1
{txt}  Dhat_ols_h {res}           1            1            0            0
{txt}Dhat_lasso~h {res}           2            1            0            0
{txt}Dhat_gradb~h {res}           3            1            1            1
{reset}
{res}short-stacked weights across resamples for share
{res}final stacking estimator: nnls1
{txt}                  learner  mean_weight        rep_1
Y1_pystacked {res}           1            0            0
{txt}Y2_pystacked {res}           2            0            0
{txt}Y3_pystacked {res}           3            1            1
{reset}{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:35:47

Help file: ddml_example_interactiveiv_pystacked_basic.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:35:47
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 3august2023}{...}
{smcl}
{pstd}{ul:Interactive IV model (LATE) - Basic example with {help pystacked}}

{pstd}We use {help pystacked} with two base learners for each reduced form equation.{p_end}

{input}. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta, clear
{txt}
{input}. global Y earnings
{txt}
{input}. global D training
{txt}
{input}. global Z assignmt
{txt}
{input}. global X sex age married black hispanic
{txt}

{pstd}Drop observations where treatment=1 even though assignment=0.
(Up to the user how to handle such observations;
{opt ddml} can handle these cases,
and we drop them here only to illustrate how this is reflected in the stacking weights.){p_end}

{input}. tab $D $Z

{txt}Enrollment {c |}     Assignment to
        in {c |}       Training
  Training {c |}         0          1 {c |}     Total
{hline 11}{c +}{hline 22}{c +}{hline 10}
         0 {c |}{res}     3,663      2,683 {txt}{c |}{res}     6,346 
{txt}         1 {c |}{res}        54      4,804 {txt}{c |}{res}     4,858 
{txt}{hline 11}{c +}{hline 22}{c +}{hline 10}
     Total {c |}{res}     3,717      7,487 {txt}{c |}{res}    11,204 
{txt}
{input}. drop if $D==1 & $Z==0
{txt}(54 observations deleted)
{txt}

{pstd}Set the seed, initialize, cross-fit and estimate:{p_end}

{input}. set seed 42
{txt}
{input}. ddml init interactiveiv
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X,Z]: pystacked $Y c.($X)# #c($X), type(reg) m(ols lassocv)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X,Z]: pystacked $D c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml E[Z|X]: pystacked $Z c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner Z1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  D1_pystacked  1735.381  (501.153)  Z1_pystacked

{txt}Stacking DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y1_pystacked0_1{txt}{col 52}Number of obs   ={col 70}{res}    11150
{txt}E[y|X,Z=1]{col 14}= {res}Y1_pystacked1_1
{txt}E[D|X,Z=0]{col 14}= {res}D1_pystacked0_1
{txt}E[D|X,Z=1]{col 14}= {res}D1_pystacked1_1
{txt}E[Z|X]{col 14}= {res}Z1_pystacked_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1735.381{col 26}{space 2} 501.1529{col 37}{space 1}    3.46{col 46}{space 3}0.001{col 54}{space 4} 753.1392{col 67}{space 3} 2717.622
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Report the stacking weights.
Note that the weights for the non-existent case (treatment=1, assignment=0) are missing.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for Z1_pystacked (assignmt)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
  logit {res}           1    .21337055    .21337055
{txt}lassocv {res}           2    .78662945    .78662945
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (earnings)
{res}final stacking estimator: nnls1
{txt}             learner        Z=0/1  mean_weight        rep_1
    ols {res}           1            0    .86435554    .86435554
{txt}lassocv {res}           2            0    .13564446    .13564446
{txt}    ols {res}           1            1     .9345463     .9345463
{txt}lassocv {res}           2            1     .0654537     .0654537
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (training)
{res}final stacking estimator: nnls1
{txt}             learner        Z=0/1  mean_weight        rep_1
  logit {res}           1            0            0            0
{txt}lassocv {res}           2            0            0            0
{txt}  logit {res}           1            1    .93657404    .93657404
{txt}lassocv {res}           2            1    .06342596    .06342596
{reset}{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:39:30

Help file: ddml_example_interactiveiv_pystacked_detailed.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:39:30
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Interactive IV model (LATE) - Detailed example with {help pystacked}}

{pstd}Preparation: we load the data, define global macros and set the seed.{p_end}

{input}. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta, clear
{txt}
{input}. global Y earnings
{txt}
{input}. global D training
{txt}
{input}. global Z assignmt
{txt}
{input}. global X sex age married black hispanic
{txt}
{input}. set seed 42
{txt}

{pstd}We initialize the model.{p_end}

{input}. ddml init interactiveiv, kfolds(5)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}We use {helpb pystacked} with two base learners for each reduced form equation.
Note that E[Y|X,Z] is a regression problem,
whereas E[D|X,Z] and E[Z|X] are classification problems.{p_end}

{input}. ddml E[Y|X,Z]: pystacked $Y c.($X)# #c($X), type(reg) m(ols lassocv)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X,Z]: pystacked $D c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml E[Z|X]: pystacked $Z c.($X)# #c($X), type(class) m(logit lassocv)
{res}{txt}Learner Z1_pystacked added successfully.
{txt}

{pstd}Cross-fitting and estimation, with short-stacking implemented via {opt ddml}.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}note: treatment (training) = 1 in 54 cases when assignment (assignmt) = 0
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  D1_pystacked  1817.232  (512.772)  Z1_pystacked
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]          [ss]          [ss]  1818.117  (513.944)          [ss]

{txt}Shortstack DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y_earnings_ss0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y_earnings_ss1_1
{txt}E[D|X,Z=0]{col 14}= {res}D_training_ss0_1
{txt}E[D|X,Z=1]{col 14}= {res}D_training_ss1_1
{txt}E[Z|X]{col 14}= {res}Z_assignmt_ss_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1818.117{col 26}{space 2} 513.9437{col 37}{space 1}    3.54{col 46}{space 3}0.000{col 54}{space 4}  810.806{col 67}{space 3} 2825.428
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Compare the short-stacking estimation above with standard (within-cross-fit-fold) stacking:{p_end}

{input}. ddml estimate, spec(st) rep(1) replay notable
{res}
{txt}Stacking DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y1_pystacked0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y1_pystacked1_1
{txt}E[D|X,Z=0]{col 14}= {res}D1_pystacked0_1
{txt}E[D|X,Z=1]{col 14}= {res}D1_pystacked1_1
{txt}E[Z|X]{col 14}= {res}Z1_pystacked_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1817.232{col 26}{space 2} 512.7721{col 37}{space 1}    3.54{col 46}{space 3}0.000{col 54}{space 4} 812.2173{col 67}{space 3} 2822.247
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Short-stacking is typically considerably faster than standard stacking.
We can estimate using short-stacking only by specifying the {opt nostd} option when cross-fitting.
We re-set the seed for comparability.{p_end}

{input}. set seed 42
{txt}
{input}. ddml crossfit, shortstack nostdstack
{res}{txt}note: treatment (training) = 1 in 54 cases when assignment (assignmt) = 0
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 2 3 4 5 ...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]          [ss]          [ss]  1814.245  (513.279)          [ss]

{txt}Shortstack DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y_earnings_ss0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y_earnings_ss1_1
{txt}E[D|X,Z=0]{col 14}= {res}D_training_ss0_1
{txt}E[D|X,Z=1]{col 14}= {res}D_training_ss1_1
{txt}E[Z|X]{col 14}= {res}Z_assignmt_ss_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1814.245{col 26}{space 2} 513.2794{col 37}{space 1}    3.53{col 46}{space 3}0.000{col 54}{space 4} 808.2361{col 67}{space 3} 2820.254
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}

{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:50:16

Help file: ddml_example_extract.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:50:16
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 31july2023}{...}
{smcl}
{pstd}{ul:ddml extract utility: Extracting stored information from ddml associative arrays}

{pstd}The examples below use the partially-linear model
and stacking regression using {helpb pystacked}.
We also request short-stacking.
The model name is the default name "m0".
For simplicity we use {helpb pystacked}'s default learners and settings.
{p_end}

{pstd}Preparation and estimation:{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(3) reps(5)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X]: pystacked net_tfa $X, type(reg)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked e401 $X, type(reg)
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=3, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  7971.516 (1157.199)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7467.899 (1059.748)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7103.917  (916.936)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7378.277  (895.972)
{stata ddml estimate, mname(m0) spec(st) rep(3) notable replay:  st  3}  Y1_pystacked  D1_pystacked  7271.315  (928.559)
{stata ddml estimate, mname(m0) spec(ss) rep(3) notable replay:  ss  3}  [shortstack]          [ss]  7302.977  (907.828)
{stata ddml estimate, mname(m0) spec(st) rep(4) notable replay:  st  4}  Y1_pystacked  D1_pystacked  6887.581  (916.298)
{stata ddml estimate, mname(m0) spec(ss) rep(4) notable replay:  ss  4}  [shortstack]          [ss]  6923.917  (913.388)
{stata ddml estimate, mname(m0) spec(st) rep(5) notable replay:  st  5}  Y1_pystacked  D1_pystacked  6901.912  (896.746)
{stata ddml estimate, mname(m0) spec(ss) rep(5) notable replay:  ss  5}  [shortstack]          [ss]  6985.731  (882.863)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7227.248 (1000.026)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7211.760  (949.927)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7103.917  (941.490)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7302.977  (938.132)

{txt}Shortstack DDML model (median over 5 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7302.977{col 26}{space 2}  938.132{col 37}{space 1}    7.78{col 46}{space 3}0.000{col 54}{space 4} 5464.272{col 67}{space 3} 9141.682
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7211.7602 6923.9165 6985.7310 7302.9771 7378.2773 7467.8989
{txt}

{pstd}{ul:{opt show(something)} option examples}{p_end}

{pstd}{opt show} option examples: report standard (pystacked) and short-stacked weights.
Standard stacking weights displayed here are mean weights across cross-fit folds.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .08153887    .05608768     .0840624    .03251847    .14207861    .09294721
{txt}  lassocv {res}           2    .16367892     .1983422    .17484295    .21455488    .11080118     .1198534
{txt}gradboost {res}           3     .7547822    .74557012    .74109465    .75292665    .74712021     .7871994
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .28747183    .18398986    .36148227     .1103495    .41252374    .36901379
{txt}  lassocv {res}           2    .09613986    .05278333    .13207421    .29583822    1.063e-16    3.567e-06
{txt}gradboost {res}           3    .61858407    .76322682    .51839357    .59381228    .58650496    .63098273
{reset}{res}{txt}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .03049847    .15249237            0            0    2.846e-19    2.168e-19
{txt}  lassocv {res}           2    .20329907    .05653283    .23140523     .2290732    .27932792    .22015614
{txt}gradboost {res}           3    .76620246    .79097479    .76859477     .7709268    .72067208    .77984386
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .16952276    .62414185    1.588e-17            0    .22347198    6.647e-11
{txt}  lassocv {res}           2    .16130065            0    .19359176    .21773024    .15214415    .24303708
{txt}gradboost {res}           3    .66917659    .37585815    .80640824    .78226976    .62438388    .75696292
{reset}{res}{txt}

{pstd}The {opt show} option leaves results in r(.) macros.{p_end}

{input}. mat list r(Y_net_tfa_ss)
{res}
{txt}r(Y_net_tfa_ss)[3,7]
               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .16952276    .62414185    1.588e-17            0    .22347198    6.647e-11
{txt}  lassocv {res}           2    .16130065            0    .19359176    .21773024    .15214415    .24303708
{txt}gradboost {res}           3    .66917659    .37585815    .80640824    .78226976    .62438388    .75696292
{reset}{txt}
{input}. mat list r(D_e401_ss)
{res}
{txt}r(D_e401_ss)[3,7]
               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .03049847    .15249237            0            0    2.846e-19    2.168e-19
{txt}  lassocv {res}           2    .20329907    .05653283    .23140523     .2290732    .27932792    .22015614
{txt}gradboost {res}           3    .76620246    .79097479    .76859477     .7709268    .72067208    .77984386
{reset}{txt}

{pstd}{opt show} option examples: examine the learner weights and MSEs by fold reported by {cmd:pystacked}.{p_end}

{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for D1_pystacked (e401)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  .16826304          0          0
{txt}  lassocv {res}         2          1  .13109924  .23961713  .22431024
{txt}gradboost {res}         3          1  .70063771  .76038287  .77568976
{txt}      ols {res}         1          2          0  .24979577  .00239144
{txt}  lassocv {res}         2          2  .26607389          0  .25845497
{txt}gradboost {res}         3          2  .73392611  .75020423  .73915359
{txt}      ols {res}         1          3  .09755541          0  1.084e-18
{txt}  lassocv {res}         2          3  .12368253  .24396537  .27601674
{txt}gradboost {res}         3          3  .77876206  .75603463  .72398326
{txt}      ols {res}         1          4   .1894134  .14721477  .08960765
{txt}  lassocv {res}         2          4  .05381122   .1454022  .13319012
{txt}gradboost {res}         3          4  .75677539  .70738303  .77720222
{txt}      ols {res}         1          5  5.421e-20  .27884163          0
{txt}  lassocv {res}         2          5  .15552757          0  .20403262
{txt}gradboost {res}         3          5  .84447243  .72115837  .79596738
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .08153887    .05608768     .0840624    .03251847    .14207861    .09294721
{txt}  lassocv {res}           2    .16367892     .1983422    .17484295    .21455488    .11080118     .1198534
{txt}gradboost {res}           3     .7547822    .74557012    .74109465    .75292665    .74712021     .7871994
{reset}
{res}pystacked MSEs for D1_pystacked (e401)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  .20351577  .20225882  .19754608
{txt}  lassocv {res}         2          1   .2035348  .20225473    .197507
{txt}gradboost {res}         3          1  .19956581  .19769108  .19215809
{txt}      ols {res}         1          2  .20186788   .2013563  .19981196
{txt}  lassocv {res}         2          2  .20183337  .20137622  .19984606
{txt}gradboost {res}         3          2  .19713729   .1970131  .19555222
{txt}      ols {res}         1          3  .19656056  .20380581  .20229808
{txt}  lassocv {res}         2          3  .19657887  .20370893  .20223549
{txt}gradboost {res}         3          3  .19126091  .19870774   .1983283
{txt}      ols {res}         1          4   .2026485  .20058303   .1998553
{txt}  lassocv {res}         2          4  .20270242  .20057994  .19985482
{txt}gradboost {res}         3          4  .19747921  .19697907  .19476448
{txt}      ols {res}         1          5  .20091221  .19935736  .20305163
{txt}  lassocv {res}         2          5  .20089484  .19935905  .20298434
{txt}gradboost {res}         3          5  .19439272  .19568025   .1972188
{reset}
{res}mean stacking MSEs across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner   mean_MSE      rep_1      rep_2      rep_3      rep_4      rep_5
      ols {res}         1  .20102862  .20110689  .20101204  .20088815  .20102894  .20110707
{txt}  lassocv {res}         2  .20101672  .20109884  .20101855   .2008411  .20104573  .20107941
{txt}gradboost {res}         3  .19626194  .19647166  .19656754  .19609898  .19640759  .19576392
{reset}
{res}pystacked weights for Y1_pystacked (net_tfa)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  .27812564  1.058e-12  .27384393
{txt}  lassocv {res}         2          1          0  .15834998          0
{txt}gradboost {res}         3          1  .72187436  .84165002  .72615607
{txt}      ols {res}         1          2  .48876223          0  .59568458
{txt}  lassocv {res}         2          2  1.308e-17  .39622264          0
{txt}gradboost {res}         3          2  .51123777  .63962752  .40431542
{txt}      ols {res}         1          3  .33104848  4.487e-16  3.292e-08
{txt}  lassocv {res}         2          3  5.876e-14   .1875602  .69995446
{txt}gradboost {res}         3          3  .66895152   .8124398  .30004551
{txt}      ols {res}         1          4  .43531108  .39610026  .40615988
{txt}  lassocv {res}         2          4  3.182e-16  7.860e-19          0
{txt}gradboost {res}         3          4  .56468892  .60389974  .59092621
{txt}      ols {res}         1          5  .41850968   .4982584  .19027328
{txt}  lassocv {res}         2          5  1.305e-11          0   .0000107
{txt}gradboost {res}         3          5  .58149032  .50174186  .80971602
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2        rep_3        rep_4        rep_5
      ols {res}           1    .28747183    .18398986    .36148227     .1103495    .41252374    .36901379
{txt}  lassocv {res}           2    .09613986    .05278333    .13207421    .29583822    1.063e-16    3.567e-06
{txt}gradboost {res}           3    .61858407    .76322682    .51839357    .59381228    .58650496    .63098273
{reset}
{res}pystacked MSEs for Y1_pystacked (net_tfa)
{txt}             learner   resample     fold_1     fold_2     fold_3
      ols {res}         1          1  1.626e+09  1.495e+09  1.520e+09
{txt}  lassocv {res}         2          1  1.627e+09  1.495e+09  1.519e+09
{txt}gradboost {res}         3          1  1.385e+09  1.098e+09  1.272e+09
{txt}      ols {res}         1          2  1.623e+09  1.522e+09  1.673e+09
{txt}  lassocv {res}         2          2  1.623e+09  1.519e+09  1.674e+09
{txt}gradboost {res}         3          2  1.611e+09  1.378e+09  1.817e+09
{txt}      ols {res}         1          3  1.551e+09  1.824e+09  1.447e+09
{txt}  lassocv {res}         2          3  1.553e+09  1.823e+09  1.445e+09
{txt}gradboost {res}         3          3  1.339e+09  1.390e+09  1.653e+09
{txt}      ols {res}         1          4  1.758e+09  1.304e+09  1.610e+09
{txt}  lassocv {res}         2          4  1.759e+09  1.304e+09  1.612e+09
{txt}gradboost {res}         3          4  1.689e+09  1.203e+09  1.468e+09
{txt}      ols {res}         1          5  1.448e+09  1.652e+09  1.633e+09
{txt}  lassocv {res}         2          5  1.448e+09  1.654e+09  1.634e+09
{txt}gradboost {res}         3          5  1.346e+09  1.649e+09  1.278e+09
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner   mean_MSE      rep_1      rep_2      rep_3      rep_4      rep_5
      ols {res}         1  1.579e+09  1.547e+09  1.606e+09  1.608e+09  1.557e+09  1.578e+09
{txt}  lassocv {res}         2  1.579e+09  1.547e+09  1.605e+09  1.607e+09  1.558e+09  1.579e+09
{txt}gradboost {res}         3  1.438e+09  1.251e+09  1.602e+09  1.461e+09  1.453e+09  1.424e+09
{reset}{res}{txt}

{pstd}{ul:List keys examples}{p_end}

{pstd}List keys of associative arrays used in model m0.
Associative array m0.eqnAA is an "equation AA" and has one key,
which is is the name of the variable for which conditional expectations are estimated.
Associative array m0.estAA is an "estimation AA" and has two keys.
The objects stored on this AA are either estimation results,
AAs that have sets of estimation results, or objects with information about the estimations.{p_end}

{input}. ddml extract, keys
{res}{txt}AA keys for m0.eqnAA:
             1
    {c TLC}{hline 11}{c TRC}
  1 {c |}  {res}   e401{txt}  {c |}
  2 {c |}  {res}net_tfa{txt}  {c |}
    {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA:
         1    2
     {c TLC}{hline 11}{c TRC}
   1 {c |}  {res}ss    1{txt}  {c |}
   2 {c |}  {res}ss    2{txt}  {c |}
   3 {c |}  {res}ss    3{txt}  {c |}
   4 {c |}  {res}ss    4{txt}  {c |}
   5 {c |}  {res}ss    5{txt}  {c |}
   6 {c |}  {res}ss   md{txt}  {c |}
   7 {c |}  {res}ss   mn{txt}  {c |}
   8 {c |}  {res}st    1{txt}  {c |}
   9 {c |}  {res}st    2{txt}  {c |}
  10 {c |}  {res}st    3{txt}  {c |}
  11 {c |}  {res}st    4{txt}  {c |}
  12 {c |}  {res}st    5{txt}  {c |}
  13 {c |}  {res}st   md{txt}  {c |}
  14 {c |}  {res}st   mn{txt}  {c |}
     {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=1:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=2:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=3:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=4:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=5:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=md:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                  d_md                    local{txt}  {c |}
  10 {c |}  {res}                depvar                     post{txt}  {c |}
  11 {c |}  {res}                  dh_m                    local{txt}  {c |}
  12 {c |}  {res}                dnames                    local{txt}  {c |}
  13 {c |}  {res}                 title                    local{txt}  {c |}
  14 {c |}  {res}                   vce                    local{txt}  {c |}
  15 {c |}  {res}               vcetype                    local{txt}  {c |}
  16 {c |}  {res}                     y                    local{txt}  {c |}
  17 {c |}  {res}                   y_m                    local{txt}  {c |}
  18 {c |}  {res}                  y_md                    local{txt}  {c |}
  19 {c |}  {res}                 yname                    local{txt}  {c |}
  20 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=mn:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                  d_mn                    local{txt}  {c |}
  10 {c |}  {res}                depvar                     post{txt}  {c |}
  11 {c |}  {res}                  dh_m                    local{txt}  {c |}
  12 {c |}  {res}                dnames                    local{txt}  {c |}
  13 {c |}  {res}                 title                    local{txt}  {c |}
  14 {c |}  {res}                   vce                    local{txt}  {c |}
  15 {c |}  {res}               vcetype                    local{txt}  {c |}
  16 {c |}  {res}                     y                    local{txt}  {c |}
  17 {c |}  {res}                   y_m                    local{txt}  {c |}
  18 {c |}  {res}                  y_mn                    local{txt}  {c |}
  19 {c |}  {res}                 yname                    local{txt}  {c |}
  20 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=1:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=2:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=3:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=4:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=5:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=md:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                        d_md                          local{txt}  {c |}
  10 {c |}  {res}                      depvar                           post{txt}  {c |}
  11 {c |}  {res}                        dh_m                          local{txt}  {c |}
  12 {c |}  {res}                      dnames                          local{txt}  {c |}
  13 {c |}  {res}                       title                          local{txt}  {c |}
  14 {c |}  {res}                         vce                          local{txt}  {c |}
  15 {c |}  {res}                     vcetype                          local{txt}  {c |}
  16 {c |}  {res}                           y                          local{txt}  {c |}
  17 {c |}  {res}                         y_m                          local{txt}  {c |}
  18 {c |}  {res}                        y_md                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=mn:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                        d_mn                          local{txt}  {c |}
  10 {c |}  {res}                      depvar                           post{txt}  {c |}
  11 {c |}  {res}                        dh_m                          local{txt}  {c |}
  12 {c |}  {res}                      dnames                          local{txt}  {c |}
  13 {c |}  {res}                       title                          local{txt}  {c |}
  14 {c |}  {res}                         vce                          local{txt}  {c |}
  15 {c |}  {res}                     vcetype                          local{txt}  {c |}
  16 {c |}  {res}                           y                          local{txt}  {c |}
  17 {c |}  {res}                         y_m                          local{txt}  {c |}
  18 {c |}  {res}                        y_mn                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{res}{txt}

{pstd}List keys relating to equation for D variable, e401.
Keys for two associative arrays are reported.
Associative array e401.lrnAA is a "learner AA" and has two keys; it stores e.g. an estimation specification.
Associative array e401.resAA is a "results AA" and has three keys; it stores e.g. estimation results.{p_end}

{input}. ddml extract, keys vname(e401)
{res}{txt}AA keys for eqn e401.lrnAA:
                      1                 2
     {c TLC}{hline 37}{c TRC}
   1 {c |}  {res}   D1_pystacked               cmd{txt}  {c |}
   2 {c |}  {res}   D1_pystacked          est_main{txt}  {c |}
   3 {c |}  {res}   D1_pystacked       est_options{txt}  {c |}
   4 {c |}  {res}   D1_pystacked           estring{txt}  {c |}
   5 {c |}  {res}   D1_pystacked           predopt{txt}  {c |}
   6 {c |}  {res}   D1_pystacked    stack_base_est{txt}  {c |}
   7 {c |}  {res}   D1_pystacked   stack_final_est{txt}  {c |}
   8 {c |}  {res}   D1_pystacked        stack_type{txt}  {c |}
   9 {c |}  {res}   D1_pystacked             vtype{txt}  {c |}
  10 {c |}  {res}      D_e401_ss      ss_final_est{txt}  {c |}
  11 {c |}  {res}      D_e401_ss    stack_base_est{txt}  {c |}
  12 {c |}  {res}      D_e401_ss        stack_type{txt}  {c |}
  13 {c |}  {res}            opt                 1{txt}  {c |}
  14 {c |}  {res}            opt                 2{txt}  {c |}
  15 {c |}  {res}            opt                 3{txt}  {c |}
  16 {c |}  {res}            opt                 4{txt}  {c |}
  17 {c |}  {res}            opt                 5{txt}  {c |}
     {c BLC}{hline 37}{c BRC}
{txt}AA keys for eqn e401.resAA:
                    1               2               3
     {c TLC}{hline 49}{c TRC}
   1 {c |}  {res} D1_pystacked             MSE               1{txt}  {c |}
   2 {c |}  {res} D1_pystacked             MSE               2{txt}  {c |}
   3 {c |}  {res} D1_pystacked             MSE               3{txt}  {c |}
   4 {c |}  {res} D1_pystacked             MSE               4{txt}  {c |}
   5 {c |}  {res} D1_pystacked             MSE               5{txt}  {c |}
   6 {c |}  {res} D1_pystacked       MSE_folds               1{txt}  {c |}
   7 {c |}  {res} D1_pystacked       MSE_folds               2{txt}  {c |}
   8 {c |}  {res} D1_pystacked       MSE_folds               3{txt}  {c |}
   9 {c |}  {res} D1_pystacked       MSE_folds               4{txt}  {c |}
  10 {c |}  {res} D1_pystacked       MSE_folds               5{txt}  {c |}
  11 {c |}  {res} D1_pystacked               N               1{txt}  {c |}
  12 {c |}  {res} D1_pystacked               N               2{txt}  {c |}
  13 {c |}  {res} D1_pystacked               N               3{txt}  {c |}
  14 {c |}  {res} D1_pystacked               N               4{txt}  {c |}
  15 {c |}  {res} D1_pystacked               N               5{txt}  {c |}
  16 {c |}  {res} D1_pystacked         N_folds               1{txt}  {c |}
  17 {c |}  {res} D1_pystacked         N_folds               2{txt}  {c |}
  18 {c |}  {res} D1_pystacked         N_folds               3{txt}  {c |}
  19 {c |}  {res} D1_pystacked         N_folds               4{txt}  {c |}
  20 {c |}  {res} D1_pystacked         N_folds               5{txt}  {c |}
  21 {c |}  {res} D1_pystacked      stack_MSEs               1{txt}  {c |}
  22 {c |}  {res} D1_pystacked      stack_MSEs               2{txt}  {c |}
  23 {c |}  {res} D1_pystacked      stack_MSEs               3{txt}  {c |}
  24 {c |}  {res} D1_pystacked      stack_MSEs               4{txt}  {c |}
  25 {c |}  {res} D1_pystacked      stack_MSEs               5{txt}  {c |}
  26 {c |}  {res} D1_pystacked   stack_weights               1{txt}  {c |}
  27 {c |}  {res} D1_pystacked   stack_weights               2{txt}  {c |}
  28 {c |}  {res} D1_pystacked   stack_weights               3{txt}  {c |}
  29 {c |}  {res} D1_pystacked   stack_weights               4{txt}  {c |}
  30 {c |}  {res} D1_pystacked   stack_weights               5{txt}  {c |}
  31 {c |}  {res} D1_pystacked   y_stacking_cv               1{txt}  {c |}
  32 {c |}  {res} D1_pystacked   y_stacking_cv               2{txt}  {c |}
  33 {c |}  {res} D1_pystacked   y_stacking_cv               3{txt}  {c |}
  34 {c |}  {res} D1_pystacked   y_stacking_cv               4{txt}  {c |}
  35 {c |}  {res} D1_pystacked   y_stacking_cv               5{txt}  {c |}
  36 {c |}  {res}    D_e401_ss             MSE               1{txt}  {c |}
  37 {c |}  {res}    D_e401_ss             MSE               2{txt}  {c |}
  38 {c |}  {res}    D_e401_ss             MSE               3{txt}  {c |}
  39 {c |}  {res}    D_e401_ss             MSE               4{txt}  {c |}
  40 {c |}  {res}    D_e401_ss             MSE               5{txt}  {c |}
  41 {c |}  {res}    D_e401_ss       MSE_folds               1{txt}  {c |}
  42 {c |}  {res}    D_e401_ss       MSE_folds               2{txt}  {c |}
  43 {c |}  {res}    D_e401_ss       MSE_folds               3{txt}  {c |}
  44 {c |}  {res}    D_e401_ss       MSE_folds               4{txt}  {c |}
  45 {c |}  {res}    D_e401_ss       MSE_folds               5{txt}  {c |}
  46 {c |}  {res}    D_e401_ss               N               1{txt}  {c |}
  47 {c |}  {res}    D_e401_ss               N               2{txt}  {c |}
  48 {c |}  {res}    D_e401_ss               N               3{txt}  {c |}
  49 {c |}  {res}    D_e401_ss               N               4{txt}  {c |}
  50 {c |}  {res}    D_e401_ss               N               5{txt}  {c |}
  51 {c |}  {res}    D_e401_ss         N_folds               1{txt}  {c |}
  52 {c |}  {res}    D_e401_ss         N_folds               2{txt}  {c |}
  53 {c |}  {res}    D_e401_ss         N_folds               3{txt}  {c |}
  54 {c |}  {res}    D_e401_ss         N_folds               4{txt}  {c |}
  55 {c |}  {res}    D_e401_ss         N_folds               5{txt}  {c |}
  56 {c |}  {res}    D_e401_ss      ss_weights               1{txt}  {c |}
  57 {c |}  {res}    D_e401_ss      ss_weights               2{txt}  {c |}
  58 {c |}  {res}    D_e401_ss      ss_weights               3{txt}  {c |}
  59 {c |}  {res}    D_e401_ss      ss_weights               4{txt}  {c |}
  60 {c |}  {res}    D_e401_ss      ss_weights               5{txt}  {c |}
     {c BLC}{hline 49}{c BRC}
{res}{txt}

{pstd}{ul:Working with model estimation results}{p_end}

{pstd}Extract the estimated beta for the short-stack specification ("ss"), resample 2.
Provide the keys for the AA with the results for the specification and resampling,
and the subkeys for this AA to obtain the posted beta.{p_end}

{input}. ddml extract, key1(ss) key2(2) subkey1(b) subkey2(post)
{res}       {txt}           1              2
    {c TLC}{hline 31}{c TRC}
  1 {c |}  {res} 7378.277121   -263.4154308{txt}  {c |}
    {c BLC}{hline 31}{c BRC}
{txt}

{pstd}As above, but store as a Mata object "bmat".
This is done by providing this name after "ddml extract".{p_end}

{input}. ddml extract bmat, key1(ss) key2(2) subkey1(b) subkey2(post)
{res}{txt}
{input}. mata: bmat
{res}       {txt}           1              2
    {c TLC}{hline 31}{c TRC}
  1 {c |}  {res} 7378.277121   -263.4154308{txt}  {c |}
    {c BLC}{hline 31}{c BRC}
{txt}

{pstd}By default, the object is saved as a Mata object.
To save as a Stata macro r(bmat), use the {opt Stata} option:{p_end}

{input}. ddml extract bmat, key1(ss) key2(2) subkey1(b) subkey2(post) stata
{res}{txt}
{input}. mat list r(bmat)
{res}
{txt}r(bmat)[1,2]
            c1          c2
r1 {res}  7378.2771  -263.41543
{reset}{txt}

{pstd}More examples of the above, relating to specification ss and
various resamples or the mean/median across resamples.
{input}. ddml extract, keys
{res}{txt}AA keys for m0.eqnAA:
             1
    {c TLC}{hline 11}{c TRC}
  1 {c |}  {res}   e401{txt}  {c |}
  2 {c |}  {res}net_tfa{txt}  {c |}
    {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA:
         1    2
     {c TLC}{hline 11}{c TRC}
   1 {c |}  {res}ss    1{txt}  {c |}
   2 {c |}  {res}ss    2{txt}  {c |}
   3 {c |}  {res}ss    3{txt}  {c |}
   4 {c |}  {res}ss    4{txt}  {c |}
   5 {c |}  {res}ss    5{txt}  {c |}
   6 {c |}  {res}ss   md{txt}  {c |}
   7 {c |}  {res}ss   mn{txt}  {c |}
   8 {c |}  {res}st    1{txt}  {c |}
   9 {c |}  {res}st    2{txt}  {c |}
  10 {c |}  {res}st    3{txt}  {c |}
  11 {c |}  {res}st    4{txt}  {c |}
  12 {c |}  {res}st    5{txt}  {c |}
  13 {c |}  {res}st   md{txt}  {c |}
  14 {c |}  {res}st   mn{txt}  {c |}
     {c BLC}{hline 11}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=1:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=2:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=3:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=4:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=5:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
   3 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
   4 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
   5 {c |}  {res}                     N                     post{txt}  {c |}
   6 {c |}  {res}                     V                     post{txt}  {c |}
   7 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   8 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   9 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  10 {c |}  {res}                     b                     post{txt}  {c |}
  11 {c |}  {res}                     d                    local{txt}  {c |}
  12 {c |}  {res}                   d_m                    local{txt}  {c |}
  13 {c |}  {res}                depvar                     post{txt}  {c |}
  14 {c |}  {res}                dnames                    local{txt}  {c |}
  15 {c |}  {res}                 title                    local{txt}  {c |}
  16 {c |}  {res}                   vce                    local{txt}  {c |}
  17 {c |}  {res}               vcetype                    local{txt}  {c |}
  18 {c |}  {res}                     y                    local{txt}  {c |}
  19 {c |}  {res}                   y_m                    local{txt}  {c |}
  20 {c |}  {res}                 yname                    local{txt}  {c |}
  21 {c |}  {res}                znames                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=md:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                  d_md                    local{txt}  {c |}
  10 {c |}  {res}                depvar                     post{txt}  {c |}
  11 {c |}  {res}                  dh_m                    local{txt}  {c |}
  12 {c |}  {res}                dnames                    local{txt}  {c |}
  13 {c |}  {res}                 title                    local{txt}  {c |}
  14 {c |}  {res}                   vce                    local{txt}  {c |}
  15 {c |}  {res}               vcetype                    local{txt}  {c |}
  16 {c |}  {res}                     y                    local{txt}  {c |}
  17 {c |}  {res}                   y_m                    local{txt}  {c |}
  18 {c |}  {res}                  y_md                    local{txt}  {c |}
  19 {c |}  {res}                 yname                    local{txt}  {c |}
  20 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=ss and key 2=mn:
                             1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   2 {c |}  {res}                     N                     post{txt}  {c |}
   3 {c |}  {res}                     V                     post{txt}  {c |}
   4 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   5 {c |}  {res}                     b                     post{txt}  {c |}
   6 {c |}  {res}           b_resamples                   matrix{txt}  {c |}
   7 {c |}  {res}                     d                    local{txt}  {c |}
   8 {c |}  {res}                   d_m                    local{txt}  {c |}
   9 {c |}  {res}                  d_mn                    local{txt}  {c |}
  10 {c |}  {res}                depvar                     post{txt}  {c |}
  11 {c |}  {res}                  dh_m                    local{txt}  {c |}
  12 {c |}  {res}                dnames                    local{txt}  {c |}
  13 {c |}  {res}                 title                    local{txt}  {c |}
  14 {c |}  {res}                   vce                    local{txt}  {c |}
  15 {c |}  {res}               vcetype                    local{txt}  {c |}
  16 {c |}  {res}                     y                    local{txt}  {c |}
  17 {c |}  {res}                   y_m                    local{txt}  {c |}
  18 {c |}  {res}                  y_mn                    local{txt}  {c |}
  19 {c |}  {res}                 yname                    local{txt}  {c |}
  20 {c |}  {res}                   z_m                    local{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=1:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=2:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=3:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=4:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=5:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}            D1_pystacked_mse                         scalar{txt}  {c |}
   2 {c |}  {res}      D1_pystacked_mse_folds                         matrix{txt}  {c |}
   3 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   4 {c |}  {res}                           N                           post{txt}  {c |}
   5 {c |}  {res}                           V                           post{txt}  {c |}
   6 {c |}  {res}            Y1_pystacked_mse                         scalar{txt}  {c |}
   7 {c |}  {res}      Y1_pystacked_mse_folds                         matrix{txt}  {c |}
   8 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   9 {c |}  {res}                           b                           post{txt}  {c |}
  10 {c |}  {res}                           d                          local{txt}  {c |}
  11 {c |}  {res}                         d_m                          local{txt}  {c |}
  12 {c |}  {res}                      depvar                           post{txt}  {c |}
  13 {c |}  {res}                      dnames                          local{txt}  {c |}
  14 {c |}  {res}                       title                          local{txt}  {c |}
  15 {c |}  {res}                         vce                          local{txt}  {c |}
  16 {c |}  {res}                     vcetype                          local{txt}  {c |}
  17 {c |}  {res}                           y                          local{txt}  {c |}
  18 {c |}  {res}                         y_m                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                      znames                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=md:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                        d_md                          local{txt}  {c |}
  10 {c |}  {res}                      depvar                           post{txt}  {c |}
  11 {c |}  {res}                        dh_m                          local{txt}  {c |}
  12 {c |}  {res}                      dnames                          local{txt}  {c |}
  13 {c |}  {res}                       title                          local{txt}  {c |}
  14 {c |}  {res}                         vce                          local{txt}  {c |}
  15 {c |}  {res}                     vcetype                          local{txt}  {c |}
  16 {c |}  {res}                           y                          local{txt}  {c |}
  17 {c |}  {res}                         y_m                          local{txt}  {c |}
  18 {c |}  {res}                        y_md                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{txt}AA keys for m0.estAA, key 1=st and key 2=mn:
                                   1                              2
     {c TLC}{hline 63}{c TRC}
   1 {c |}  {res}D1_pystacked_stack_final_est                          local{txt}  {c |}
   2 {c |}  {res}                           N                           post{txt}  {c |}
   3 {c |}  {res}                           V                           post{txt}  {c |}
   4 {c |}  {res}Y1_pystacked_stack_final_est                          local{txt}  {c |}
   5 {c |}  {res}                           b                           post{txt}  {c |}
   6 {c |}  {res}                 b_resamples                         matrix{txt}  {c |}
   7 {c |}  {res}                           d                          local{txt}  {c |}
   8 {c |}  {res}                         d_m                          local{txt}  {c |}
   9 {c |}  {res}                        d_mn                          local{txt}  {c |}
  10 {c |}  {res}                      depvar                           post{txt}  {c |}
  11 {c |}  {res}                        dh_m                          local{txt}  {c |}
  12 {c |}  {res}                      dnames                          local{txt}  {c |}
  13 {c |}  {res}                       title                          local{txt}  {c |}
  14 {c |}  {res}                         vce                          local{txt}  {c |}
  15 {c |}  {res}                     vcetype                          local{txt}  {c |}
  16 {c |}  {res}                           y                          local{txt}  {c |}
  17 {c |}  {res}                         y_m                          local{txt}  {c |}
  18 {c |}  {res}                        y_mn                          local{txt}  {c |}
  19 {c |}  {res}                       yname                          local{txt}  {c |}
  20 {c |}  {res}                         z_m                          local{txt}  {c |}
     {c BLC}{hline 63}{c BRC}
{res}{txt}

{input}. ddml extract, key1(ss) key2(1) subkey1(D_e401_ss_mse) subkey2(scalar)
{res}  .1958363362
{txt}
{input}. ddml extract, key1(ss) key2(2) subkey1(D_e401_ss_mse_folds) subkey2(matrix)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1957355901   .1941540463   .1985244675{txt}  {c |}
    {c BLC}{hline 43}{c BRC}
{txt}
{input}. ddml extract, key1(ss) key2(mn) subkey1(V) subkey2(post)
{res}  902361.1559
{txt}
{input}. ddml extract, key1(ss) key2(md) subkey1(title) subkey2(local)
{res}  Shortstack DDML model (median over 5 resamples)
{txt}

{pstd}{ul:Working with equation estimation results}{p_end}

{pstd}Display information stored on learner AA e401.lrnAA
about the specification of conditional expectations for variable e401.{p_end}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(est_main)
{res}  pystacked e401 tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(stack_base_est)
{res}  ols lassocv gradboost
{txt}

{pstd}Display information stored on results AA e401.resAA
about the estimation results for resamplings 1 and 2.{p_end}

{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(MSE_folds) key3(1)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1915497943   .1933662438   .2026450476{txt}  {c |}
    {c BLC}{hline 43}{c BRC}
{txt}
{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(MSE_folds) key3(2)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1956606296   .1941944697   .1985518793{txt}  {c |}
    {c BLC}{hline 43}{c BRC}
{txt}
{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(stack_weights) key3(1)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}.1682630405             0             0{txt}  {c |}
  2 {c |}  {res}.1310992449   .2396171276   .2243102368{txt}  {c |}
  3 {c |}  {res}.7006377146   .7603828724   .7756897632{txt}  {c |}
    {c BLC}{hline 43}{c BRC}
{txt}
{input}. ddml extract, vname(e401) key1(D1_pystacked) key2(stack_weights) key3(2)
{res}       {txt}          1             2             3
    {c TLC}{hline 43}{c TRC}
  1 {c |}  {res}          0   .2497957652   .0023914381{txt}  {c |}
  2 {c |}  {res}.2660738854             0   .2584549675{txt}  {c |}
  3 {c |}  {res}.7339261146   .7502042348   .7391535944{txt}  {c |}
    {c BLC}{hline 43}{c BRC}
{txt}

{pstd}{ul:Working directly with an equation associative array}{p_end}

{pstd}Extract the associative AA for the estimation of conditional expectations for variable e401.
Store it as a Mata object called AA_e401.
Note: the {cmd:crossfit} command returns an equation associative array,
so this step is unnecessary when using this command.{p_end}

{input}. ddml extract AA_e401, vname(e401)
{res}{txt}
{input}. mata: AA_e401
{res}  0x34c22ec0
{txt}

{pstd}Examples of working with this equation associative array.
Note that the {opt ename} option must be used.{p_end}

{input}. ddml extract, ename(AA_e401) key1(D1_pystacked) key2(MSE) key3(1)
{res}  .1958536952
{txt}
{input}. ddml extract, ename(AA_e401) key1(D1_pystacked) key2(MSE) key3(2)
{res}  .1961356595
{txt}

{pstd}{ul:Using Mata's associative array commands}{p_end}

{pstd}If preferred, Mata's associative array commands can be used directly.
Note that all keys are strings.{p_end}

{input}. mata: m0.estAA.keys()
{res}        {txt} 1    2
     {c TLC}{hline 11}{c TRC}
   1 {c |}  {res}ss    2{txt}  {c |}
   2 {c |}  {res}st    2{txt}  {c |}
   3 {c |}  {res}ss    3{txt}  {c |}
   4 {c |}  {res}st    3{txt}  {c |}
   5 {c |}  {res}st    4{txt}  {c |}
   6 {c |}  {res}st   md{txt}  {c |}
   7 {c |}  {res}st   mn{txt}  {c |}
   8 {c |}  {res}ss    1{txt}  {c |}
   9 {c |}  {res}st    5{txt}  {c |}
  10 {c |}  {res}ss    4{txt}  {c |}
  11 {c |}  {res}ss   md{txt}  {c |}
  12 {c |}  {res}st    1{txt}  {c |}
  13 {c |}  {res}ss   mn{txt}  {c |}
  14 {c |}  {res}ss    5{txt}  {c |}
     {c BLC}{hline 11}{c BRC}
{txt}
{input}. mata: AA_e1_r2 = (m0.estAA).get(("ss","2"))
{res}{txt}
{input}. mata: AA_e1_r2.keys()
{res}        {txt}                     1                        2
     {c TLC}{hline 51}{c TRC}
   1 {c |}  {res}                znames                    local{txt}  {c |}
   2 {c |}  {res}                dnames                    local{txt}  {c |}
   3 {c |}  {res}                 title                    local{txt}  {c |}
   4 {c |}  {res}                depvar                     post{txt}  {c |}
   5 {c |}  {res}      Y_net_tfa_ss_mse                   scalar{txt}  {c |}
   6 {c |}  {res}   D_e401_ss_final_est                    local{txt}  {c |}
   7 {c |}  {res}                   vce                    local{txt}  {c |}
   8 {c |}  {res}Y_net_tfa_ss_final_est                    local{txt}  {c |}
   9 {c |}  {res}                     V                     post{txt}  {c |}
  10 {c |}  {res}                   y_m                    local{txt}  {c |}
  11 {c |}  {res}                 yname                    local{txt}  {c |}
  12 {c |}  {res}                     N                     post{txt}  {c |}
  13 {c |}  {res}                     b                     post{txt}  {c |}
  14 {c |}  {res}               vcetype                    local{txt}  {c |}
  15 {c |}  {res}                     y                    local{txt}  {c |}
  16 {c |}  {res}Y_net_tfa_ss_mse_folds                   matrix{txt}  {c |}
  17 {c |}  {res}            D_e401_ssw                   matrix{txt}  {c |}
  18 {c |}  {res}                   d_m                    local{txt}  {c |}
  19 {c |}  {res}                     d                    local{txt}  {c |}
  20 {c |}  {res}         D_e401_ss_mse                   scalar{txt}  {c |}
  21 {c |}  {res}   D_e401_ss_mse_folds                   matrix{txt}  {c |}
     {c BLC}{hline 51}{c BRC}
{txt}
{input}. mata: AA_e1_r2.get(("b","post"))
{res}       {txt}           1              2
    {c TLC}{hline 31}{c TRC}
  1 {c |}  {res} 7378.277121   -263.4154308{txt}  {c |}
    {c BLC}{hline 31}{c BRC}
{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:54:31

Help file: ddml_example_stacking.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:54:31
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Partially-linear model with {help pystacked} and stacking}:{p_end}

{pstd}Preparation: load the data, define global macros, set the seed and initialize the model.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}

{pstd}Add supervised machine learners for estimating conditional expectations.
For simplicity, we use {help pystacked}'s default learners:
OLS, cross-validated lasso, and gradient boosting.{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.
{txt}

{pstd} Cross-fitting and estimation:
The learners are iteratively fitted on the training data to obtain the estimated conditional expectations,
and then the causal coefficient of interest is estimated along with heteroskedastic-consistent SEs.
Note that the initial stacking is specified at the {help ddml crossfit:cross-fitting} stage.
In addition to the standard stacking done by {helpb pystacked},
also request short-stacking and pooled-stacking to be done by {opt ddml}.{p_end}

{input}. ddml crossfit, shortstack poolstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking{res}{txt}...completed pooled-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (998.890)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7074.289  (966.832)
{stata ddml estimate, mname(m0) spec(ps) rep(1) notable replay:  ps  1}   [poolstack]          [ps]  6840.628  (977.354)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (964.328)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7433.262  (898.604)
{stata ddml estimate, mname(m0) spec(ps) rep(2) notable replay:  ps  2}   [poolstack]          [ps]  7013.319  (910.084)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494 (1046.569)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7253.775  (948.082)
{stata ddml estimate, mname(m0) spec(ps) rep(mn) notable replay noconstant:  ps mn}   [poolstack]          [ps]  6926.973  (945.891)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7017.494 (1047.070)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7253.775  (950.443)
{stata ddml estimate, mname(m0) spec(ps) rep(md) notable replay noconstant:  ps md}   [poolstack]          [ps]  6926.973  (948.257)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7253.775{col 26}{space 2} 950.4432{col 37}{space 1}    7.63{col 46}{space 3}0.000{col 54}{space 4} 5390.941{col 67}{space 3}  9116.61
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7253.7754 7074.2886 7074.2886 7253.7754 7433.2622 7433.2622
{txt}

{pstd}Examine the standard ({cmd:pystacked}) stacking weights as well as
the {opt ddml} short-stacking and pooled-stacking weights.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .05613789    .05836149    .05391429
{txt}  lassocv {res}           2    .27554279    .24816003    .30292554
{txt}gradboost {res}           3    .66831932    .69347848    .64316016
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .57321109    .55513919    .59128299
{txt}  lassocv {res}           2    1.006e-08            0    2.011e-08
{txt}gradboost {res}           3    .42700058    .44528417    .40871699
{reset}{res}{txt}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .25052052    .23042397    .27061706
{txt}  lassocv {res}           2    .00153817    .00307633            0
{txt}gradboost {res}           3    .74794132     .7664997    .72938294
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1     .2246767    .21142516    .23792824
{txt}  lassocv {res}           2    .02898811    2.917e-06    .05797331
{txt}gradboost {res}           3    .74633519    .78857192    .70409845
{reset}{res}{txt}
{input}. ddml extract, show(psweights)
{res}
{res}pool-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .00823385    2.819e-18     .0164677
{txt}  lassocv {res}           2     .3228386    .30599574    .33968146
{txt}gradboost {res}           3    .66892755    .69400426    .64385084
{reset}
{res}pool-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1        rep_2
      ols {res}           1    .54463296    .58045718    .50880875
{txt}  lassocv {res}           2            0            0            0
{txt}gradboost {res}           3    .45536704    .41954282    .49119125
{reset}{res}{txt}

{pstd} Re-stack without cross-fitting, using the single-best learner
instead of the default constrained nonlinear least squares.
We do this using the {help ddml estimate} command.
Since no stacking method is specified,
restacking will be done for all three methods.{p_end}

{input}. ddml estimate, robust finalest(singlebest)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6455.251 (1001.440)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7124.950  (957.277)
{stata ddml estimate, mname(m0) spec(ps) rep(1) notable replay:  ps  1}   [poolstack]          [ps]  7074.448 (1008.427)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7877.428  (996.891)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7806.394  (926.937)
{stata ddml estimate, mname(m0) spec(ps) rep(2) notable replay:  ps  2}   [poolstack]          [ps]  6496.931  (997.313)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7166.339 (1226.365)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7465.672 (1001.535)
{stata ddml estimate, mname(m0) spec(ps) rep(mn) notable replay noconstant:  ps mn}   [poolstack]          [ps]  6785.690 (1043.574)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7166.339 (1226.371)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7465.672 (1001.942)
{stata ddml estimate, mname(m0) spec(ps) rep(md) notable replay noconstant:  ps md}   [poolstack]          [ps]  6785.690 (1043.629)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7465.672{col 26}{space 2} 1001.942{col 37}{space 1}    7.45{col 46}{space 3}0.000{col 54}{space 4} 5501.903{col 67}{space 3} 9429.442
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}singlebest

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7465.6721 7124.9502 7124.9502 7465.6721 7806.3940 7806.3940
{txt}

{pstd} As above, but request short-stacking only at the cross-fitting stage.
Note the speed improvement.{p_end}

{input}. ddml crossfit, shortstack nostdstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 2 ...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]  7073.928  (967.615)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7406.747  (896.114)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  {res}[shortstack]          [ss]  7240.337  (944.666)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7240.337  (947.281)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7240.337{col 26}{space 2} 947.2813{col 37}{space 1}    7.64{col 46}{space 3}0.000{col 54}{space 4}   5383.7{col 67}{space 3} 9096.975
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7240.3374 7073.9282 7073.9282 7240.3374 7406.7466 7406.7466
{txt}

{pstd} Re-stack the above without cross-fitting, using OLS as the final estimator.
Use the option {opt shortstack} since only these results are re-stacked.{p_end}

{input}. ddml estimate, robust shortstack finalest(ols)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]  7046.829  (966.256)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7424.263  (897.706)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  {res}[shortstack]          [ss]  7235.546  (949.141)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7235.546  (951.513)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7235.546{col 26}{space 2} 951.5133{col 37}{space 1}    7.60{col 46}{space 3}0.000{col 54}{space 4} 5370.614{col 67}{space 3} 9100.478
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}ols

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7235.5459 7046.8291 7046.8291 7235.5459 7424.2627 7424.2627
{txt}
{input}. ddml estimate, robust shortstack finalest(ols)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  {res}[shortstack]          [ss]  7046.829  (966.256)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7424.263  (897.706)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  {res}[shortstack]          [ss]  7235.546  (949.141)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7235.546  (951.513)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7235.546{col 26}{space 2} 951.5133{col 37}{space 1}    7.60{col 46}{space 3}0.000{col 54}{space 4} 5370.614{col 67}{space 3} 9100.478
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}ols

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7235.5459 7046.8291 7046.8291 7235.5459 7424.2627 7424.2627
{txt}

{pstd}{ul:Extended example with specified {help pystacked} learners and settings}:{p_end}

{pstd}Same example as above, but specify the base learners explicitly.
We again make use of {help pystacked} integration,
so there is a single call to {help pystacked} for each conditional expectation.
The first learner in the stacked ensemble is OLS.
We also use cross-validated lasso, ridge and two random forests with different settings.
The settings are stored in macros for readability.{p_end}

{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. global rflow max_features(5) min_samples_leaf(1) max_samples(.7)
{txt}
{input}. global rfhigh max_features(5) min_samples_leaf(10) max_samples(.7)
{txt}
{input}. ddml E[Y|X]: pystacked $Y $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X || method(ols) || method(lassocv) || method(ridgecv) || method(rf) opt($rflow) || method(rf) opt($rfhigh), type(reg)
{res}{txt}Learner D1_pystacked added successfully.
{txt}

{pstd}Note: Options before ":" and after the first comma refer to {cmd:ddml}. 
Options that come after the final comma refer to the estimation command. 
Make sure to not confuse the two types of options.{p_end}

{pstd}The learners are iteratively fitted on the training data.
In addition to the standard stacking done by {helpb pystacked},
also request short-stacking to be done by {opt ddml}.
Finally, estimate the coefficients of interest.{p_end}

{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate, robust
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  7294.554 (1005.548)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7046.814  (979.169)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7114.501 (1033.362)
{stata ddml estimate, mname(m0) spec(ss) rep(2) notable replay:  ss  2}  [shortstack]          [ss]  7234.312  (972.221)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7204.528 (1023.142)
{stata ddml estimate, mname(m0) spec(ss) rep(mn) notable replay noconstant:  ss mn}  [shortstack]          [ss]  7140.563  (980.171)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7204.528 (1023.517)
{stata ddml estimate, mname(m0) spec(ss) rep(md) notable replay noconstant:  ss md}  [shortstack]          [ss]  7140.563  (980.195)

{txt}Shortstack DDML model (median over 2 resamples)
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7140.563{col 26}{space 2} 980.1951{col 37}{space 1}    7.28{col 46}{space 3}0.000{col 54}{space 4} 5219.416{col 67}{space 3}  9061.71
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7140.5632 7046.8140 7046.8140 7140.5632 7234.3125 7234.3125
{txt}

{pstd}Examine the standard ({cmd:pystacked}) stacking weights as well as the {opt ddml} short-stacking weights.{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    4.018e-20            0    8.036e-20
{txt}lassocv {res}           2    .22993114    .16362312    .29623916
{txt}ridgecv {res}           3    .11694608    .21786462    .01602755
{txt}     rf {res}           4    .01560619            0    .03121238
{txt}     rf {res}           5    .63751658    .61851226    .65652091
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    .24179897    .05679108    .42680686
{txt}lassocv {res}           2    .02574689    .05149378            0
{txt}ridgecv {res}           3            0            0            0
{txt}     rf {res}           4     .6974316    .94665083    .44821237
{txt}     rf {res}           5    .08557162            0    .17114324
{reset}{res}{txt}
{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for e401
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1    1.952e-17            0    3.903e-17
{txt}lassocv {res}           2    .12439376    .24878753            0
{txt}ridgecv {res}           3    .16345225            0    .32690449
{txt}     rf {res}           4    2.404e-17    6.397e-18    4.169e-17
{txt}     rf {res}           5    .71215399    .75121247    .67309551
{reset}
{res}short-stacked weights across resamples for net_tfa
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1        rep_2
    ols {res}           1     .0644898            0     .1289796
{txt}lassocv {res}           2            0            0            0
{txt}ridgecv {res}           3    .09095584    .18191168            0
{txt}     rf {res}           4    .84455436    .81808832     .8710204
{txt}     rf {res}           5            0            0            0
{reset}{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:56:39

Help file: ddml_example_describe.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:56:39
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:ddml describe utility - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros, set the seed and initialize the model.
Use 2-fold cross-fitting with two repetitions (resamples)
Use {help pystacked}'s default learners as the supervised learners.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(2) reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6653.485  (826.611)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  D1_pystacked  7381.502  (856.397)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay noconstant:  st mn}{res}  Y1_pystacked  D1_pystacked  7017.494  (916.573)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay noconstant:  st md}  Y1_pystacked  D1_pystacked  7017.494  (916.980)

{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020
{txt}

{pstd}Default of {opt ddml describe} is to report a brief summary.{p_end}

{input}. ddml describe
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked
{txt}

{pstd}Options: report details of the total and cross-fit samples,
learners (including the estimation strings),
cross-fit results,
and estimation results.{p_end}

{input}. ddml describe, sample
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}ID:{col 25}{res}m0_id
{txt}Full sample indic.:{col 25}{res}m0_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m0_fid_1    m0_fid_2  
{txt}Fold sample indic.:{col 25}{res}m0_sample_1 m0_sample_2 
{txt}Estimation N:{col 25}    {res}9915        9915    
{txt}
{input}. ddml describe, learners
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. ddml describe, crossfit
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}net_tfa{col 12}Y1_pysta~d{col 26} 1{col 34} 1.3e+09   1.4e+09   1.2e+09
{col 12}Y1_pysta~d{col 26} 2{col 34} 1.4e+09   1.3e+09   1.6e+09
e401{col 12}D1_pysta~d{col 26} 1{col 34}    0.20      0.19      0.20
{col 12}D1_pysta~d{col 26} 2{col 34}    0.20      0.20      0.20
{txt}
{input}. ddml describe, estimates
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked


{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020
{txt}

{pstd}The {opt all} option is equivalent to specifying all 4 options.{p_end}

{input}. ddml describe, all
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked
{txt}Specifications:{col 25}{res}1 possible specs * 2 crossfit splits = 2

{txt}ID:{col 25}{res}m0_id
{txt}Full sample indic.:{col 25}{res}m0_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m0_fid_1    m0_fid_2  
{txt}Fold sample indic.:{col 25}{res}m0_sample_1 m0_sample_2 
{txt}Estimation N:{col 25}    {res}9915        9915    

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}net_tfa{col 12}Y1_pysta~d{col 26} 1{col 34} 1.3e+09   1.4e+09   1.2e+09
{col 12}Y1_pysta~d{col 26} 2{col 34} 1.4e+09   1.3e+09   1.6e+09
e401{col 12}D1_pysta~d{col 26} 1{col 34}    0.20      0.19      0.20
{col 12}D1_pysta~d{col 26} 2{col 34}    0.20      0.20      0.20


{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020
{txt}
{input}. ddml describe, sample learners crossfit estimates
{res}
{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}ID:{col 25}{res}m0_id
{txt}Full sample indic.:{col 25}{res}m0_sample (N=9915)
{txt}Fold ID:{col 25}  {res}m0_fid_1    m0_fid_2  
{txt}Fold sample indic.:{col 25}{res}m0_sample_1 m0_sample_2 
{txt}Estimation N:{col 25}    {res}9915        9915    

{txt}Y learners (detail):
{res}{col 2}Learner:{col 15}Y1_pystacked
{col 15}est cmd: pystacked net_tfa tw age inc fsize educ db marr twoearn pira hown
{txt}D learners (detail):
{res}{col 2}Learner:{col 15}D1_pystacked
{col 15}est cmd: pystacked e401 tw age inc fsize educ db marr twoearn pira hown

{txt}Crossfit results (detail):
{res}{txt}{col 38}All{col 45}By fold:
Cond. exp.{col 13}Learner{col 26}rep{col 38}MSE        1         2 
{res}net_tfa{col 12}Y1_pysta~d{col 26} 1{col 34} 1.3e+09   1.4e+09   1.2e+09
{col 12}Y1_pysta~d{col 26} 2{col 34} 1.4e+09   1.3e+09   1.6e+09
e401{col 12}D1_pysta~d{col 26} 1{col 34}    0.20      0.19      0.20
{col 12}D1_pysta~d{col 26} 2{col 34}    0.20      0.20      0.20


{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020
{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:57:21

Help file: ddml_example_export.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:57:21
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:ddml export utility - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros, set the seed and initialize the model.
Use 2-fold cross-fitting with two repetitions (resamples)
Use {help pystacked}'s default learners as the supervised learners.
We explicitly name the model to be estimated as m_sip1991;
this is the name of the Mata global containing the model details.
The default behavior of {opt ddml} is to prefix the created sample and fold indicators,
but we specify the {opt prefix} option with {help ddml init}
so that all created variables including the estimated conditional expectations are prefixed.
{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}
{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(2) reps(2) mname(m_sip1991) prefix
{res}{txt}
{input}. ddml E[Y|X], mname(m_sip1991): pystacked $Y $X
{res}{txt}Learner m_sip1991_Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X], mname(m_sip1991): pystacked $D $X
{res}{txt}Learner m_sip1991_D1_pystacked added successfully.
{txt}
{input}. ddml crossfit, mname(m_sip1991)
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate, mname(m_sip1991)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=2
{txt}Mata global (mname):{col 25}{res}m_sip1991
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}m_sip1991_Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}m_sip1991_D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m_sip1991) spec(st) rep(1) notable replay:  st  1}{res} m_sip1991_Y~d m_sip1991_D~d  6653.485  (826.611)
{stata ddml estimate, mname(m_sip1991) spec(st) rep(2) notable replay:  st  2} m_sip1991_Y~d m_sip1991_D~d  7381.502  (856.397)

{txt}Mean/med    Y learner     D learner         b        SE 
{stata ddml estimate, mname(m_sip1991) spec(st) rep(mn) notable replay noconstant:  st mn}{res} m_sip1991_Y~d m_sip1991_D~d  7017.494  (916.573)
{stata ddml estimate, mname(m_sip1991) spec(st) rep(md) notable replay noconstant:  st md} m_sip1991_Y~d m_sip1991_D~d  7017.494  (916.980)

{txt}Median over 2 stacking resamples
y-E[y|X]{col 11}= {res}y-m_sip1991_Y1_pystacked{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-m_sip1991_D1_pystacked 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7017.494{col 26}{space 2} 916.9804{col 37}{space 1}    7.65{col 46}{space 3}0.000{col 54}{space 4} 5220.245{col 67}{space 3} 8814.742
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
        e401{col 15}{res} 7017.4937 6653.4854 6653.4854 7017.4937 7381.5020 7381.5020
{txt}

{pstd}It will often be a good idea to include an ID variable that identifies the observation number.
This dataset doesn't include an ID variable, so we create one.{p_end}

{input}. gen long m_sip1991_id = _n
{txt}

{pstd}To include the ID variable with everything else, we use the {opt addvars(.)} option.
The data will be exported to a CSV file called "m_ddml_sip1991.csv".{p_end}

{input}. ddml export using m_ddml_sip1991.csv, mname(m_sip1991) replace addvars(m_sip1991_id)
{res}{txt}file m_ddml_sip1991.csv saved
{txt}

{pstd}Lists of saved {opt ddml} estimated conditional expectations with and without resample numbers,
saved in r(.) macros:{p_end}

{input}. di "`r(vreplist)'"
m_sip1991_Y1_pystacked_1 m_sip1991_Y1_pystacked_2 m_sip1991_Y1_pystacked_L1_1 m_sip1991_Y1_pystacked_L1_2 m_sip1991_Y1_pystacked_L2_1 m_sip1991_Y1_pystacked_L2_2 m_sip1991_Y1_pystacked_L3_1 m_sip1991_Y1_pystacked_L3_2 m_sip1991_D1_pystacked_1 m_sip1991_D1_pystacked_2 m_sip1991_D1_pystacked_L1_1 m_sip1991_D1_pystacked_L1_2 m_sip1991_D1_pystacked_L2_1 m_sip1991_D1_pystacked_L2_2 m_sip1991_D1_pystacked_L3_1 m_sip1991_D1_pystacked_L3_2
{txt}
{input}. di "`r(vlist)'"
m_sip1991_Y1_pystacked m_sip1991_Y1_pystacked_L1 m_sip1991_Y1_pystacked_L2 m_sip1991_Y1_pystacked_L3 m_sip1991_D1_pystacked m_sip1991_D1_pystacked_L1 m_sip1991_D1_pystacked_L2 m_sip1991_D1_pystacked_L3
{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:58:00

Help file: ddml_example_overlap.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:58:00
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:ddml overlap utility - Overlap plots with interactive models (ATE etc.)}{p_end}

{pstd}We use the default of 5 cross-fit folds
and specify 2 resamplings with 2 supervised learners:
linear regression and gradient boosted trees, stacked using {help pystacked}.
Note that we use gradient boosted regression trees for E[Y|X,D],
but gradient boosted classification trees for E[D|X].{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
{txt}
{input}. global Y bweight
{txt}
{input}. global D mbsmoke
{txt}
{input}. global X prenatal1 mmarried fbaby mage medu
{txt}
{input}. set seed 42
{txt}
{input}. ddml init interactive, reps(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X,D]: pystacked $Y $X || method(ols) || method(gradboost) || , type(reg)
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X || method(logit) || method(gradboost) || , type(class)
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=2
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.297   (25.985)
{stata ddml estimate, mname(m0) spec(st) rep(2) notable replay:  st  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -220.083   (25.665)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(mn) notable replay:  st mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.690   (25.826)
{stata ddml estimate, mname(m0) spec(st) rep(md) notable replay:  st md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -219.690   (25.828)

{txt}Median over 2 stacking resamples (ATE)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-219.6899{col 26}{space 2} 25.82837{col 37}{space 1}   -8.51{col 46}{space 3}0.000{col 54}{space 4}-270.3125{col 67}{space 3}-169.0672
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}Summary over 2 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -219.6899 -220.0827 -220.0827 -219.6899 -219.2971 -219.2971
{txt}

{pstd}Default behavior of {opt ddml overlap} is to use all cross-fit resamples
and plot the stacked (ensemble) learner generated by {help pystacked}:{p_end}

{input}. ddml overlap
{res}{txt}

{pstd}Use just resample 1:{p_end}

{input}. ddml overlap, replist(1)
{res}{txt}

{pstd}Overlap plots for the predicted values of
the separate logit (#1) and gradboost (#2) learners:{p_end}

{input}. ddml overlap, pslist(D1_pystacked_L1 D1_pystacked_L2)
{res}{txt}

{pstd}Save the overlap plot using the default triangle kernel,
generate an overlap plot using the Epanechnikov, kernal,
and combine the two into a single graph:{p_end}

{input}. ddml overlap, name(triangle, replace) title(Propensity score - triangle kernel)
{res}{txt}
{input}. ddml overlap, kernel(epanechnikov) name(epanechnikov, replace) title(Propensity score - epanechnikov kernel)
{res}{txt}
{input}. graph combine triangle epanechnikov
{res}{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 11:59:16

Help file: ddml_example_fcluster.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 11:59:16
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{smcl}
{pstd}{ul:Cluster sampling with cross-fit folds - Basic example with {help pystacked}}{p_end}

{pstd}Load the data, define global macros and set the seed.{p_end}

{input}. webuse nlsw88, clear
{txt}(NLSW, 1988 extract)
{txt}
{input}. gen lwage = ln(wage)
{txt}
{input}. global Y lwage
{txt}
{input}. global D union
{txt}
{input}. global X age-c_city hours-tenure
{txt}
{input}. set seed 42
{txt}

{pstd}Initialize the model.
The {opt fcluster(industry)} ("fold-cluster") option tells {opt ddml}
to ensure that clusters (here, identified by the variable {opt industry})
are not split across cross-fit folds, i.e., each cluster appears in only one cross-fit fold.
Here we specify 2 cross-fit folds,
so all observations for each cluster will appear in either fold 1 or in fold 2.
NB: This example is somewhat artificial, because there are only 12 clusters (industries).{p_end}

{input}. ddml init partial, kfolds(2) fcluster(industry)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. tab industry m0_fid_1

                      {txt}{c |}   Fold ID (randomly
                      {c |}   generated) rep 1
             industry {c |}         1          2 {c |}     Total
{hline 22}{c +}{hline 22}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}        17          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          4 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}        29          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0        367 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0         90 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}       333          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0        192 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0         86 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}        97          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}        17          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0        824 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}       176          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 22}{c +}{hline 10}
                Total {c |}{res}       669      1,563 {txt}{c |}{res}     2,232 
{txt}

{pstd}Since there are 12 clusters defined by {opt industry},
we could achieve the same cross-fit split either by specifying {opt fcluster(industry)},
or by using {opt fcluster(industry)} as the fold identifier and specifying {opt foldvar(industry)}.
(NB: The split is the same but the fold numbering is different.){p_end}

{input}. ddml init partial, foldvar(industry)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
note - fold variable missing for some observations
these observations will be excluded from the estimation sample
{txt}
{input}. tab industry m0_fid_1

                      {txt}{c |}                             (based on industry)
             industry {c |}         1          2          3          4          5          6          7 {c |}     Total
{hline 22}{c +}{hline 77}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}        17          0          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          4          0          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0         29          0          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0        367          0          0          0 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0          0          0          0         90          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0          0        333          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0          0          0          0          0          0        192 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 77}{c +}{hline 10}
                Total {c |}{res}        17          4         29        367         90        333        192 {txt}{c |}{res}     2,232 


                      {txt}{c |}                  (based on industry)
             industry {c |}         8          9         10         11         12 {c |}     Total
{hline 22}{c +}{hline 55}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}        86          0          0          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0         97          0          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0          0         17          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0        824          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0        176 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 55}{c +}{hline 10}
                Total {c |}{res}        86         97         17        824        176 {txt}{c |}{res}     2,232 
{txt}

{input}. ddml init partial, kfolds(12) fcluster(industry)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. tab industry m0_fid_1

                      {txt}{c |}                      Fold ID (randomly generated) rep 1
             industry {c |}         1          2          3          4          5          6          7 {c |}     Total
{hline 22}{c +}{hline 77}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          0          4          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0          0         29          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0          0          0          0        367 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}       192          0          0          0          0          0          0 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0          0          0          0         97          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0         17          0          0          0          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0          0          0          0          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0          0        176          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 77}{c +}{hline 10}
                Total {c |}{res}       192         17          4         29         97        176        367 {txt}{c |}{res}     2,232 


                      {txt}{c |}           Fold ID (randomly generated) rep 1
             industry {c |}         8          9         10         11         12 {c |}     Total
{hline 22}{c +}{hline 55}{c +}{hline 10}
Ag/Forestry/Fisheries {c |}{res}         0         17          0          0          0 {txt}{c |}{res}        17 
{txt}               Mining {c |}{res}         0          0          0          0          0 {txt}{c |}{res}         4 
{txt}         Construction {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        29 
{txt}        Manufacturing {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       367 
{txt}Transport/Comm/Utilit {c |}{res}        90          0          0          0          0 {txt}{c |}{res}        90 
{txt}Wholesale/Retail Trad {c |}{res}         0          0          0          0        333 {txt}{c |}{res}       333 
{txt}Finance/Ins/Real Esta {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       192 
{txt}  Business/Repair Svc {c |}{res}         0          0         86          0          0 {txt}{c |}{res}        86 
{txt}    Personal Services {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        97 
{txt}Entertainment/Rec Svc {c |}{res}         0          0          0          0          0 {txt}{c |}{res}        17 
{txt}Professional Services {c |}{res}         0          0          0        824          0 {txt}{c |}{res}       824 
{txt}Public Administration {c |}{res}         0          0          0          0          0 {txt}{c |}{res}       176 
{txt}{hline 22}{c +}{hline 55}{c +}{hline 10}
                Total {c |}{res}        90         17         86        824        333 {txt}{c |}{res}     2,232 
{txt}

{pstd}Estimation is standard,
but to obtain cluster-robust SEs the covariance estimator
needs to be requested with {opt ddml estimate}:{p_end}

{input}. ddml E[Y|X]: pystacked $Y $X
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit
{res}{txt}Cross-fitting E[y|X] equation: lwage
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: union
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. ddml estimate, cluster(industry)
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=12, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{col 25}Folds respect clustering by industry
{txt}Dependent variable (Y):{col 25}{res}lwage
{txt}{col 2}lwage learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}union
{txt}{col 2}union learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked     0.098    (0.057)

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     1852
{txt}D-E[D|X]{col 11}= {res}D-D1_pystacked_1 
{txt}{ralign 78:(Std. Err. adjusted for {res:12} clusters in industry)}
{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}       lwage{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}union {c |}{col 14}{res}{space 2} .0983255{col 26}{space 2} .0566405{col 37}{space 1}    1.74{col 46}{space 3}0.083{col 54}{space 4}-.0126879{col 67}{space 3} .2093388
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0256319{col 26}{space 2} .0473131{col 37}{space 1}   -0.54{col 46}{space 3}0.588{col 54}{space 4}-.1183639{col 67}{space 3} .0671001
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 12:00:32

Help file: qddml.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 12:00:32
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 8aug2023}{...}
{viewerjumpto "Syntax" "qddml##syntax"}{...}
{viewerjumpto "Options" "qddml##options"}{...}
{viewerjumpto "Models" "qddml##models"}{...}
{viewerjumpto "Compatibility" "qddml##compatibility"}{...}
{viewerjumpto "Examples" "qddml##examples"}{...}
{viewerjumpto "Installation" "qddml##installation"}{...}
{viewerjumpto "References" "qddml##references"}{...}
{viewerjumpto "Authors" "qddml##authors"}{...}
{vieweralsosee "ddml main page" "ddml"}{...}
{vieweralsosee "Other" "qddml##also_see"}{...}
{hline}
{cmd:help qddml}{right: v1.4.1}
{hline}

{title:ddml, qddml - Stata package for Double Debiased Machine Learning}

{pstd}
{help ddml} implements algorithms for causal inference aided by supervised
machine learning as proposed in 
{it:Double/debiased machine learning for treatment and structural parameters}
(Econometrics Journal, 2018). Five different models are supported, allowing for 
binary or continuous treatment variables and endogeneity, high-dimensional 
controls and/or instrumental variables. 
{help ddml} supports a variety of different ML programs, including
but not limited to {help pystacked} and {help lassopack}. 

{pstd}
{opt qddml} is a wrapper program for {help ddml}. It provides a convenient 
one-line syntax with almost the full flexibility of {help ddml}.
The main restriction of {cmd:qddml} is that it only allows to be used 
with one machine learning program at the time, while {help ddml} 
allow for multiple learners per reduced form equation.

{pstd}
{opt qddml} uses stacking regression implemented via {help pystacked}
as the default machine learning program.
{opt qddml} has various options specific to {help pystacked}; see below.

{pstd}
Since {opt qddml} uses {help pystacked} by default, 
it requires Stata 16 or higher, Python 3.x and at least scikit-learn 0.24.
See {help python:this help file},
{browse "https://blog.stata.com/2020/08/18/stata-python-integration-part-1-setting-up-stata-to-use-python/":this Stata blog entry}
and 
{browse "https://www.youtube.com/watch?v=4WxMAGNhcuE":this Youtube video}
for how to set up Python on your system.
In short, install Python 3.x (we recommend Anaconda) 
and set the appropriate Python path using {cmd:python set exec}.

{pstd}
Please check the {help qddml##examples:examples} provided at the end of this help file.


{marker syntax}{...}
{title:Syntax}

{pstd}When used with {help pystacked}:{p_end}

{p 8 14 2}
{cmd:qddml}
{it:depvar} {it:regressors} [{cmd:(}{it:hd_controls}{cmd:)}]
{cmd:(}{it:endog}{cmd:=}{it:instruments}{cmd:)}
[{cmd:if} {it:exp}] [{cmd:in} {it:range}]
{opt model(name)}
{bind:[ {cmd:,}}
{opt pystacked(string)}
{opt pystacked_y(string)}
{opt pystacked_d(string)}
{opt pystacked_z(string)}
{opt shortstack}
{opt stdstack}
{opt poolstack}
{opt finalest(name)}
{opt mname(string)}
{bind:... ]}

{pstd}When used with other learners:{p_end}

{p 8 14 2}
{cmd:qddml}
{it:depvar} {it:regressors} [{cmd:(}{it:hd_controls}{cmd:)}]
{cmd:(}{it:endog}{cmd:=}{it:instruments}{cmd:)}
[{cmd:if} {it:exp}] [{cmd:in} {it:range}]
{opt model(name)}
{bind:[ {cmd:,}}
{opt cmd(string)}
{opt cmdopt(string)}
{opt shortstack}
{opt finalest(name)}
{opt mname(string)}
{bind:... ]}

{marker options}{...}
{title:Options}

{synoptset 20}{...}
{synopthdr:General}
{synoptline}
{synopt:{opt model(name)}}
the model to be estimated; allows for {it:partial}, {it:interactive},
{it:iv}, {it:fiv}, {it:late}. See {help ddml##models:here} for an overview.
{p_end}
{synopt:{opt mname(string)}}
name of the DDML model. Allows to run multiple DDML
models simultaneously. Defaults to {it:m0}.
{p_end}
{synopt:{opt kfolds(integer)}}
number of cross-fitting folds. The default is 5.
{p_end}
{synopt:{opt fcluster(varname)}}
cluster identifiers for cluster randomization of random folds.
{p_end}
{synopt:{opt foldvar(varname)}}
integer variable with user-specified cross-fitting folds.
{p_end}
{synopt:{opt reps(integer)}}
number of re-sampling iterations, i.e., how often the cross-fitting procedure is
repeated on randomly generated folds. 
{p_end}
{synopt:{cmdab:r:obust}}
report SEs that are robust to the
presence of arbitrary heteroskedasticity.
{p_end}
{synopt:{opt vce(type)}}
select variance-covariance estimator, see {help regress##vcetype:here}
{p_end}
{synopt:{opt cluster(varname)}}
select cluster-robust variance-covariance estimator.
{p_end}

{synoptset 20}{...}
{synopthdr:Stacking}
{synoptline}
{synopt:{opt shortstack}} asks for short-stacking to be used.
Short-stacking combines the cross-fitted predicted values
to obtain a weighted average of several base learners.
The default behavior of {opt qddml} is to report short-stacked results;
the {opt shortstack} option is used when the user wants to report
more than one type of stacking results.
{p_end}
{synopt:{opt stdstack}} (requires {help pystacked}) requests results based on standard stacking.
Stacking is done k times when cross-fitting.
Note that the final estimator for combining the base learner predicted values
is set via the options provided directly to {help pystacked};
the {help pystacked} default is constrained non-negative least squares.
Standard stacking is available only in combination with {help pystacked}.
{p_end}
{synopt:{opt poolstack}} (requires {help pystacked}) is an alternative to standard stacking.
Pooled stacking combines the out-of-sample predicted values of the {help pystacked}
using a single final estimation and set of weights.
Pooled stacking is available only in conjunction with {help pystacked}.
{p_end}
{synopt:{opt finalest(name)}}
specifies the final (ensemble) estimator used to combine
the base learner predicted values.
The default is constrained non-negative least squares;
for alternatives, see the choices of final estimator available in {help pystacked}.
{opt finalest(name)} controls the final estimator used for all types of stacking.
NB: in the unlikely event you want to change the stacking final estimators separately,
prefix "finalest" with either "std", "ss" or "ps".
{p_end}

{pstd}
For more on stacking, see {help ddml stacking:help ddml stacking}.
Note: some of the stacking options available via {help pystacked} integration
are not available for the flexible IV model.
In particular, pooled stacking is not available,
and standard stacking and short-stacking need to be done separately.
See the {help qddml##fivexample:example} below
for how to stack and short-stack when using the flexible IV model.{p_end}

{synoptset 20}{...}
{synopthdr:Learners - pystacked}
{synoptline}
{synopt:{opt pystacked(string)}}
{help pystacked} options;
applies to all estimated conditional expectations. 
If no options are specified, {help pystacked}'s defaults are used.
{p_end}
{synopt:{opt pystacked_y(string)}}
{help pystacked} options specific to the estimation of the conditional expectations of the outcome {it:Y}. 
{p_end}
{synopt:{opt pystacked_d(string)}}
{help pystacked} options specific to the estimation of the conditional expectations of the treatment variable(s) {it:D}.
{p_end}
{synopt:{opt pystacked_z(string)}}
{help pystacked} options specific to the estimation of the conditional expectations of instrumental variable(s) {it:Z}. 
{p_end}

{synoptset 20}{...}
{synopthdr:Learners - other}
{synoptline}
{synopt:{opt cmd(string)}}
ML program used for estimating conditional expectations. 
Defaults to {help pystacked}. 
See {help ddml##compatibility:here} for 
other supported programs.
{p_end}
{synopt:{opt ycmd(string)}}
ML program used for estimating the conditional expectations of the outcome {it:Y}. 
Defaults to {opt cmd(string)}. 
{p_end}
{synopt:{opt dcmd(string)}}
ML program used for estimating the conditional expectations of the treatment variable(s) {it:D}. 
Defaults to {opt cmd(string)}. 
{p_end}
{synopt:{opt zcmd(string)}}
ML program used for estimating conditional expectations of instrumental variable(s) {it:Z}. 
Defaults to {opt cmd(string)}. 
{p_end}
{synopt:{opt *cmdopt(string)}}
options that are passed on to ML program. 
The asterisk {cmd:*} can be replaced with either nothing 
(setting the default for all reduced form equations), 
{cmd:y} (setting the default for the conditional expectation of {it:Y}), 
{cmd:d} (setting the default for {it:D})
or {cmd:z} (setting the default for {it:Z}).
{p_end}
{synopt:{opt *vtype(string)}}
variable type of the variable to be created. Defaults to {it:double}. 
{it:none} can be used to leave the type field blank 
(this is required when using {help ddml} with {help rforest}.)
The asterisk {cmd:*} can be replaced with either nothing 
(setting the default for all reduced form equations), 
{cmd:y} (setting the default for the conditional expectation of {it:Y}), 
{cmd:d} (setting the default for {it:D})
or {cmd:z} (setting the default for {it:Z}).
{p_end}
{synopt:{opt *predopt(string)}}
{cmd:predict} option to be used to get predicted values. 
Typical values could be {opt xb} or {opt pr}. Default is 
blank. The asterisk {cmd:*} can be replaced with either nothing 
(setting the default for all reduced form equations), 
{cmd:y} (setting the default for the conditional expectation of {it:Y}), 
{cmd:d} (setting the default for {it:D})
or {cmd:z} (setting the default for {it:Z}).
{p_end}

{synoptset 20}{...}
{synopthdr:Output}
{synoptline}
{synopt:{opt verb:ose}}
show detailed output
{p_end}
{synopt:{opt vverb:ose}}
show even more output
{p_end}


{marker models}{...}
{title:Models}

{pstd} 
See {help ddml##help:here}.


{marker compatibility}{...}
{title:Compatible programs}

{pstd} 
See {help ddml##compatibility:here}.


{marker examples}{...}
{title:Examples}

{pstd}Below we demonstrate the use of {cmd:qddml} for each of the 5 models supported. 
Note that estimation models are chosen for demonstration purposes only and 
may be kept simple to allow you to run the code quickly.

{pstd}The last example below illustrates the equivalence of {help ddml} and {opt qddml},
i.e., the sequence of {help ddml} commands executed internally by {opt qddml}.

{pstd}{ul:Partially-linear model} 

{pstd}Preparation: we load the data and define global macros.{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/sipp1991.dta, clear
{txt}
{input}. global Y net_tfa
{txt}
{input}. global D e401
{txt}
{input}. global X tw age inc fsize educ db marr twoearn pira hown
{txt}

{pstd}The options {cmd:model(partial)} selects the partially-linear model
and {cmd:kfolds(2)} selects two cross-fitting folds.
We use the options {cmd:cmd()} and {cmd:cmdopt()} to select
random forest and cross-validated lasso for estimating the conditional expectations.{p_end}

{pstd}Note that we set the number of random folds to 2, so that 
the model runs quickly. The default is {opt kfolds(5)}. We recommend 
to consider at least 5-10 folds and even more if your sample size is small.{p_end}

{pstd}Note also that we recommend to re-run the model multiple time on 
different random folds; see options {opt reps(integer)}.{p_end}

{input}. qddml $Y $D ($X), kfolds(2) model(partial) cmd(pystacked) cmdopt(type(reg) method(rf lassocv))
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}Learner Y1_pystacked added successfully.
{res}{txt}Learner D1_pystacked added successfully.
{res}{txt}Cross-fitting E[y|X] equation: net_tfa
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: e401
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}net_tfa
{txt}{col 2}net_tfa learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}e401
{txt}{col 2}e401 learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked  6654.955  (772.859)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]  7047.612  (759.915)

{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_net_tfa_ss_1{txt}{col 52}Number of obs   ={col 70}{res}     9915
{txt}D-E[D|X]{col 11}= {res}D-D_e401_ss_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}     net_tfa{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 8}e401 {c |}{col 14}{res}{space 2} 7047.612{col 26}{space 2} 759.9146{col 37}{space 1}    9.27{col 46}{space 3}0.000{col 54}{space 4} 5558.207{col 67}{space 3} 8537.017
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} -640.347{col 26}{space 2} 339.0844{col 37}{space 1}   -1.89{col 46}{space 3}0.059{col 54}{space 4} -1304.94{col 67}{space 3} 24.24623
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Postestimation options for {help ddml} also work after {opt qddml}.
Here we request display of the {help pystacked} stacking weights and MSEs.{p_end}

{input}. ddml extract, show(pystacked)
{res}
{res}pystacked weights for D1_pystacked (e401)
{txt}           learner   resample     fold_1     fold_2
     rf {res}         1          1  .32558284  .33949796
{txt}lassocv {res}         2          1  .67441716  .66050204
{reset}
{res}mean stacking weights across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
     rf {res}           1     .3325404     .3325404
{txt}lassocv {res}           2     .6674596     .6674596
{reset}
{res}pystacked MSEs for D1_pystacked (e401)
{txt}           learner   resample     fold_1     fold_2
     rf {res}         1          1  .21141083  .20838311
{txt}lassocv {res}         2          1  .20264705   .2003294
{reset}
{res}mean stacking MSEs across folds/resamples for D1_pystacked (e401)
{res}final stacking estimator: nnls1
{txt}           learner   mean_MSE      rep_1
     rf {res}         1  .20989697  .20989697
{txt}lassocv {res}         2  .20148823  .20148823
{reset}
{res}pystacked weights for Y1_pystacked (net_tfa)
{txt}           learner   resample     fold_1     fold_2
     rf {res}         1          1  .62522887  .61889155
{txt}lassocv {res}         2          1  .37477113  .38110845
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
     rf {res}           1    .62206021    .62206021
{txt}lassocv {res}           2    .37793979    .37793979
{reset}
{res}pystacked MSEs for Y1_pystacked (net_tfa)
{txt}           learner   resample     fold_1     fold_2
     rf {res}         1          1  1.376e+09  1.586e+09
{txt}lassocv {res}         2          1  1.514e+09  1.695e+09
{reset}
{res}mean stacking MSEs across folds/resamples for Y1_pystacked (net_tfa)
{res}final stacking estimator: nnls1
{txt}           learner   mean_MSE      rep_1
     rf {res}         1  1.481e+09  1.481e+09
{txt}lassocv {res}         2  1.605e+09  1.605e+09
{reset}{res}{txt}

{pstd}{ul:Partially-linear IV model} 

{pstd}Preparation: we load the data and define global macros.{p_end}

{input}. use https://statalasso.github.io/dta/AJR.dta, clear
{txt}
{input}. global Y logpgp95
{txt}
{input}. global D avexpr
{txt}
{input}. global Z logem4
{txt}
{input}. global X lat_abst edes1975 avelf temp* humid* steplow-oilres
{txt}

{pstd}Since the data set is very small, we consider 30 cross-fitting folds.{p_end} 
{pstd}We need to add the option {opt vtype(none)} for {help rforest} to 
work with {help ddml} since {help rforests}'s {cmd:predict} command doesn't
support variable types.{p_end}

{input}. set seed 42
{txt}
{input}. qddml $Y ($X) ($D=$Z), kfolds(30) model(iv) cmd(rforest) cmdopt(type(reg)) vtype(none) robust
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}Learner Y1_rforest added successfully.
{res}{txt}Learner D1_rforest added successfully.
{res}{txt}Learner Z1_rforest added successfully.
{res}{txt}shortstack  requested but must have multiple learners in all equations; option ignored
{res}{txt}Cross-fitting E[y|X] equation: logpgp95
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: avexpr
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[Z|X]: logem4
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}6 {res}{txt}7 {res}{txt}8 {res}{txt}9 {res}{txt}10 {res}{txt}11 {res}{txt}12 {res}{txt}13 {res}{txt}14 {res}{txt}15 {res}{txt}16 {res}{txt}17 {res}{txt}18 {res}{txt}19 {res}{txt}20 {res}{txt}21 {res}{txt}22 {res}{txt}23 {res}{txt}24 {res}{txt}25 {res}{txt}26 {res}{txt}27 {res}{txt}28 {res}{txt}29 {res}{txt}30 {res}{txt}...completed cross-fitting
{res}

{txt}Model:{col 25}{res}iv, crossfit folds k=30, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}logpgp95
{txt}{col 2}logpgp95 learners:{col 25}{res}Y1_rforest
{txt}D equations (1):{col 25}{res}avexpr
{txt}{col 2}avexpr learners:{col 25}{res}D1_rforest
{txt}Z equations (1):{col 25}{res}logem4
{txt}{col 2}logem4 learners:{col 25}{res}Z1_rforest

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(1) rep(1) notable replay:   1  1}{res}    Y1_rforest    D1_rforest     0.772    (0.207)    Z1_rforest

{txt}DDML model
y-E[y|X]{col 11}= {res}y-Y1_rforest_1{txt}{col 52}Number of obs   ={col 70}{res}       64
{txt}D-E[D|X]{col 11}= {res}D-D1_rforest_1 
{txt}Z-E[Z|X]{col 11}= {res}Z-Z1_rforest_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    logpgp95{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 6}avexpr {c |}{col 14}{res}{space 2} .7723141{col 26}{space 2} .2068282{col 37}{space 1}    3.73{col 46}{space 3}0.000{col 54}{space 4} .3669382{col 67}{space 3}  1.17769
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0119092{col 26}{space 2}  .100929{col 37}{space 1}   -0.12{col 46}{space 3}0.906{col 54}{space 4}-.2097263{col 67}{space 3} .1859079
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}

{pstd}{ul:Interactive model--ATE and ATET estimation} 

{pstd}Preparation: we load the data and define global macros.{p_end}

{input}. webuse cattaneo2, clear
{txt}(Excerpt from Cattaneo (2010) Journal of Econometrics 155: 138-154)
{txt}
{input}. global Y bweight
{txt}
{input}. global D mbsmoke
{txt}
{input}. global X mage prenatal1 mmarried fbaby mage medu
{txt}

{pstd}
Note that we use gradient boosted regression trees for E[Y|X,D] (see {opt ycmdopt()}),
but gradient boosted classification trees for E[D|X] (see {opt dcmdopt()}).{p_end}

{input}. set seed 42
{txt}
{input}. qddml $Y $D ($X), kfolds(5) reps(5) model(interactive) cmd(pystacked) ycmdopt(type(reg) method(gradboost)) dcmdopt(type(class) method(gradboost))
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}Learner Y1_pystacked added successfully.
{res}{txt}Learner D1_pystacked added successfully.
{res}{txt}shortstack  requested but must have multiple learners in all equations; option ignored
{res}{txt}Cross-fitting E[y|X,D] equation: bweight
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X] equation: mbsmoke
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATE):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(1) rep(1) notable replay:   1  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -195.812   (30.885)
{stata ddml estimate, mname(m0) spec(1) rep(2) notable replay:   1  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -199.401   (32.442)
{stata ddml estimate, mname(m0) spec(1) rep(3) notable replay:   1  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -227.291   (32.605)
{stata ddml estimate, mname(m0) spec(1) rep(4) notable replay:   1  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -234.604   (33.826)
{stata ddml estimate, mname(m0) spec(1) rep(5) notable replay:   1  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -215.839   (31.833)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(1) rep(mn) notable replay:   1 mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -214.589   (35.381)
{stata ddml estimate, mname(m0) spec(1) rep(md) notable replay:   1 md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -215.839   (36.369)

{txt}Median over 5 resamples (ATE)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-215.8387{col 26}{space 2} 36.36916{col 37}{space 1}   -5.93{col 46}{space 3}0.000{col 54}{space 4}-287.1209{col 67}{space 3}-144.5565
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}Warning{txt}: 5 resamples had propensity scores trimmed to lower limit .01.

Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -214.5893 -234.6039 -227.2912 -215.8387 -199.4008 -195.8117
{txt}

{pstd}{cmd:qddml} reports the ATE effect by default. The option {cmd:atet}
returns the ATET estimate.{p_end}

{pstd}If we want retrieve the ATET estimate after estimation, 
we can simply use {ddml estimate}.{p_end}

{input}. ddml estimate, atet
{res}

{txt}Model:{col 25}{res}interactive, crossfit folds k=5, resamples r=5
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}bweight
{txt}{col 2}bweight learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}mbsmoke
{txt}{col 2}mbsmoke learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results (ATET):
spec  r  Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(1) rep(1) notable replay:   1  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -228.707   (25.699)
{stata ddml estimate, mname(m0) spec(1) rep(2) notable replay:   1  2}  Y1_pystacked  Y1_pystacked  D1_pystacked  -229.323   (25.031)
{stata ddml estimate, mname(m0) spec(1) rep(3) notable replay:   1  3}  Y1_pystacked  Y1_pystacked  D1_pystacked  -231.423   (27.400)
{stata ddml estimate, mname(m0) spec(1) rep(4) notable replay:   1  4}  Y1_pystacked  Y1_pystacked  D1_pystacked  -243.639   (24.590)
{stata ddml estimate, mname(m0) spec(1) rep(5) notable replay:   1  5}  Y1_pystacked  Y1_pystacked  D1_pystacked  -237.354   (24.847)

{txt}Mean/med Y(0) learner  Y(1) learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(1) rep(mn) notable replay:   1 mn}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  -234.089   (26.101)
{stata ddml estimate, mname(m0) spec(1) rep(md) notable replay:   1 md}  Y1_pystacked  Y1_pystacked  D1_pystacked  -231.423   (25.842)

{txt}Median over 5 resamples (ATET)
E[y|X,D=0]{col 14}= {res}Y1_pystacked0{txt}{col 52}Number of obs   ={col 70}{res}     4642
{txt}E[y|X,D=1]{col 14}= {res}Y1_pystacked1
{txt}E[D|X]{col 14}= {res}D1_pystacked
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}     bweight{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 5}mbsmoke {c |}{col 14}{res}{space 2}-231.4228{col 26}{space 2} 25.84174{col 37}{space 1}   -8.96{col 46}{space 3}0.000{col 54}{space 4}-282.0716{col 67}{space 3}-180.7739
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}Warning{txt}: 5 resamples had propensity scores trimmed to lower limit .01.

Summary over 5 resamples:
       D eqn      mean       min       p25       p50       p75       max
     mbsmoke{col 15}{res} -234.0891 -243.6388 -237.3540 -231.4228 -229.3230 -228.7068
{txt}

{pstd}{ul:Interactive IV model--LATE estimation} 

{pstd}Preparation: we load the data, define global macros and then estimate.{p_end}

{input}. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta,clear
{txt}
{input}. global Y earnings
{txt}
{input}. global D training
{txt}
{input}. global Z assignmt
{txt}
{input}. global X sex age married black hispanic
{txt}
{input}. set seed 42
{txt}
{input}. qddml $Y (c.($X)# #c($X)) ($D=$Z), kfolds(5) model(interactiveiv) cmd(pystacked) ycmdopt(type(reg) m(lassocv)) dcmdopt(type(class) m(lassocv)) zcmdopt(type(class) m(lassocv))
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}Learner Y1_pystacked added successfully.
{res}{txt}Learner D1_pystacked added successfully.
{res}{txt}Learner Z1_pystacked added successfully.
{res}{txt}note: treatment (training) = 1 in 54 cases when assignment (assignmt) = 0
{res}{txt}shortstack  requested but must have multiple learners in all equations; option ignored
{res}{txt}Cross-fitting E[y|X,Z] equation: earnings
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] equation: training
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[Z|X]: assignmt
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}

{txt}Model:{col 25}{res}interactiveiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}earnings
{txt}{col 2}earnings learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}training
{txt}{col 2}training learners:{col 25}{res}D1_pystacked
{txt}Z equations (1):{col 25}{res}assignmt
{txt}{col 2}assignmt learners:{col 25}{res}Z1_pystacked

{txt}DDML estimation results (LATE):
spec  r  Y(0) learner  Y(1) learner  D(0) learner  D(1) learner         b        SE      Z learner
{stata ddml estimate, mname(m0) spec(1) rep(1) notable replay:   1  1}{res}  Y1_pystacked  Y1_pystacked  D1_pystacked  D1_pystacked  1824.216  (514.244)  Z1_pystacked

{txt}DDML model (LATE)
E[y|X,Z=0]{col 14}= {res}Y1_pystacked0_1{txt}{col 52}Number of obs   ={col 70}{res}    11204
{txt}E[y|X,Z=1]{col 14}= {res}Y1_pystacked1_1
{txt}E[D|X,Z=0]{col 14}= {res}D1_pystacked0_1
{txt}E[D|X,Z=1]{col 14}= {res}D1_pystacked1_1
{txt}E[Z|X]{col 14}= {res}Z1_pystacked_1
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 14}{c |}{col 26}    Robust
{col 1}    earnings{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 4}training {c |}{col 14}{res}{space 2} 1824.216{col 26}{space 2} 514.2438{col 37}{space 1}    3.55{col 46}{space 3}0.000{col 54}{space 4} 816.3162{col 67}{space 3} 2832.115
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}
{txt}

{marker fivexample}{...}
{pstd}{ul:Flexible partially-linear IV model} 

{pstd}Preparation: we load the data and define global macros.
We use {help pystacked}'s default learners.
By default, {opt qddml} will short-stack;
internally, {opt qddml} extracts the list of {help pystacked} learners
and adds them to the model one-by-one:{p_end}

{input}. use https://github.com/aahrens1/ddml/raw/master/data/BLP.dta, clear
{txt}
{input}. global Y share
{txt}
{input}. global D price
{txt}
{input}. global X hpwt air mpd space
{txt}
{input}. global Z sum*
{txt}

{pstd}The syntax is the same as in the partially-linear IV model, 
but we now estimate the optimal instrument flexibly.{p_end}

{input}. set seed 42
{txt}
{input}. qddml $Y ($X) ($D=$Z), model(fiv)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
Y learner 1:
{txt}Learner Y1_ols added successfully.
Y learner 2:
{res}{txt}Learner Y2_lassocv added successfully.
Y learner 3:
{res}{txt}Learner Y3_gradboost added successfully.
D learner 1:
{res}{txt}Learner D1_ols added successfully.
D learner 2:
{res}{txt}Learner D2_lassocv added successfully.
D learner 3:
{res}{txt}Learner D3_gradboost added successfully.
D learner 1:
{res}{txt}Learner D1_ols_h added successfully.
D learner 2:
{res}{txt}Learner D2_lassocv_h added successfully.
D learner 3:
{res}{txt}Learner D3_gradboost_h added successfully.
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting{res}{txt}...completed short-stacking
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_ols Y2_lassocv Y3_gradboost
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}D1_ols D2_lassocv D3_gradboost

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(mse) rep(1) notable replay: mse  1}{res}  Y3_gradboost  D3_gradboost    -0.098    (0.008) D3_gradboos~h
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]    -0.097    (0.008)          [ss]
{txt}mse = minimum MSE specification for that resample.

{res}{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_share_ss_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-D_price_ss_1 
{txt}E[D^|X]{col 11}= {res}D_price_h_ss_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2} -.097427{col 26}{space 2} .0079921{col 37}{space 1}  -12.19{col 46}{space 3}0.000{col 54}{space 4}-.1130912{col 67}{space 3}-.0817628
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0034453{col 26}{space 2} .0215531{col 37}{space 1}    0.16{col 46}{space 3}0.873{col 54}{space 4} -.038798{col 67}{space 3} .0456885
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Report the short-stack weights:{p_end}

{input}. ddml extract, show(ssweights)
{res}
{res}short-stacked weights across resamples for price
{res}final stacking estimator: nnls1
{txt}                  learner        h=0/1  mean_weight        rep_1
      D1_ols {res}           1            0            0            0
{txt}  D2_lassocv {res}           2            0            0            0
{txt}D3_gradboost {res}           3            0            1            1
{txt}    D1_ols_h {res}           1            1            0            0
{txt}D2_lassocv_h {res}           2            1            0            0
{txt}D3_gradboo~h {res}           3            1            1            1
{reset}
{res}short-stacked weights across resamples for share
{res}final stacking estimator: nnls1
{txt}                  learner  mean_weight        rep_1
      Y1_ols {res}           1            0            0
{txt}  Y2_lassocv {res}           2            0            0
{txt}Y3_gradboost {res}           3            1            1
{reset}{res}{txt}

{pstd}To get {opt qddml} to use standard stacking via {help pystacked},
bypass its {help pystacked} integration by specifying {help pystacked} as a standard estimation command
with the {opt cmd} and {opt cmdopt(.)} options:{p_end}

{input}. set seed 42
{txt}
{input}. qddml $Y ($X) ($D=$Z), model(fiv) cmd(pystacked) cmdopt(type(reg))
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}Learner Y1_pystacked added successfully.
{res}{txt}Learner D1_pystacked added successfully.
{res}{txt}Learner D1_pystacked_h added successfully.
{res}{txt}shortstack requested but fiv model does not support pystacked integration
to short-stack with fiv model, must have multiple learners in all equations; option ignored
{res}{txt}Cross-fitting E[y|X,Z] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}{txt}Cross-fitting E[D|X,Z] and E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}4 {res}{txt}5 {res}{txt}...completed cross-fitting
{res}

{txt}Model:{col 25}{res}fiv, crossfit folds k=5, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE     DH learner
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked    -0.098    (0.008) D1_pystacke~h

{txt}Stacking DDML model
y-E[y|X]{col 11}= {res}y-Y1_pystacked_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}E[D|X,Z]{col 11}= {res}D-D1_pystacked_1 
{txt}E[D^|X]{col 11}= {res}D1_pystacked_h_1
{txt}Orthogonalized D = D - E[D^|X]; optimal IV = E[D|X,Z] - E[D^|X].
{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0978842{col 26}{space 2} .0079847{col 37}{space 1}  -12.26{col 46}{space 3}0.000{col 54}{space 4} -.113534{col 67}{space 3}-.0822344
{txt}{space 7}_cons {c |}{col 14}{res}{space 2} .0032566{col 26}{space 2} .0215635{col 37}{space 1}    0.15{col 46}{space 3}0.880{col 54}{space 4}-.0390072{col 67}{space 3} .0455204
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Report the standard stacking weights:{p_end}

{input}. ddml extract, show(stweights)
{res}
{res}mean stacking weights across folds/resamples for D1_pystacked (price)
{res}final stacking estimator: nnls1
{txt}               learner        h=0/1  mean_weight        rep_1
      ols {res}           1            0    .00029361    .00029361
{txt}  lassocv {res}           2            0    3.869e-16    3.869e-16
{txt}gradboost {res}           3            0    .99970639    .99970639
{txt}      ols {res}           1            1            0            0
{txt}  lassocv {res}           2            1            0            0
{txt}gradboost {res}           3            1            1            1
{reset}
{res}mean stacking weights across folds/resamples for Y1_pystacked (share)
{res}final stacking estimator: nnls1
{txt}               learner  mean_weight        rep_1
      ols {res}           1    .01072127    .01072127
{txt}  lassocv {res}           2    .00089782    .00089782
{txt}gradboost {res}           3    .98838092    .98838092
{reset}{res}{txt}

{pstd}{ul:Equivalence of ddml and qddml} 

{pstd}Here we illustrate how to replicate the output of {opt qddml} using separate {help ddml} commands.
Note that to guarantee exact replication, we need to set Stata's random-number seed.
Also note that {help ddml} with {help pystacked} will (unlike {opt qddml})
by default cross-fit using standard stacking,
so we specifiy that the {opt qddml} estimation should report both standard stacking and short-stacking.
The replication works because "under the hood"
{opt qddml} follows the same {help ddml} steps as we specify here,
and with no intermediate calculations that would affect Stata's random number seed.{p_end}

{pstd}We specify 5 base learners: OLS, cross-validated lasso and ridge, and two random forests.
We will use the same specification for both conditional expectations E[Y|X] and E[D|X].{p_end}

{input}. global rflow max_features(4) min_samples_leaf(1) max_samples(.7)
{txt}
{input}. global rfhigh max_features(4) min_samples_leaf(10) max_samples(.7)
{txt}
{input}. global psoptions method(ols lassocv ridgecv rf rf) cmdopt4($rflow) cmdopt5($rfhigh) type(reg)
{txt}

{pstd}Estimation using {opt ddml}.{p_end}

{input}. set seed 42
{txt}
{input}. ddml init partial, kfolds(2)
{res}warning - model m0 already exists
all existing model results and variables will
be dropped and model m0 will be re-initialized
{txt}
{input}. ddml E[Y|X]: pystacked $Y $X, $psoptions
{res}{txt}Learner Y1_pystacked added successfully.
{txt}
{input}. ddml E[D|X]: pystacked $D $X, $psoptions
{res}{txt}Learner D1_pystacked added successfully.
{txt}
{input}. ddml crossfit, shortstack
{res}{txt}Cross-fitting E[y|X] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}
{input}. ddml estimate
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=1
{txt}Mata global (mname):{col 25}{res}m0
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m0) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked    -0.078    (0.005)
{stata ddml estimate, mname(m0) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]    -0.075    (0.005)

{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_share_ss_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}D-E[D|X]{col 11}= {res}D-D_price_ss_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0752506{col 26}{space 2} .0052847{col 37}{space 1}  -14.24{col 46}{space 3}0.000{col 54}{space 4}-.0856085{col 67}{space 3}-.0648927
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0005764{col 26}{space 2} .0213419{col 37}{space 1}   -0.03{col 46}{space 3}0.978{col 54}{space 4}-.0424057{col 67}{space 3}  .041253
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}Estimation using {opt qddml}.{p_end}

{input}. set seed 42
{txt}
{input}. qddml $Y $D ($X), mname(m1) model(partial) kfolds(2) shortstack stdstack pystacked($psoptions)
{res}warning - model m1 already exists
all existing model results and variables will
be dropped and model m1 will be re-initialized
{txt}Learner Y1_pystacked added successfully.
{res}{txt}Learner D1_pystacked added successfully.
{res}{txt}Cross-fitting E[y|X] equation: share
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}{txt}Cross-fitting E[D|X] equation: price
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}...completed cross-fitting...completed short-stacking
{res}

{txt}Model:{col 25}{res}partial, crossfit folds k=2, resamples r=1
{txt}Mata global (mname):{col 25}{res}m1
{txt}Dependent variable (Y):{col 25}{res}share
{txt}{col 2}share learners:{col 25}{res}Y1_pystacked
{txt}D equations (1):{col 25}{res}price
{txt}{col 2}price learners:{col 25}{res}D1_pystacked

{txt}DDML estimation results:
spec  r     Y learner     D learner         b        SE 
{stata ddml estimate, mname(m1) spec(st) rep(1) notable replay:  st  1}{res}  Y1_pystacked  D1_pystacked    -0.078    (0.005)
{stata ddml estimate, mname(m1) spec(ss) rep(1) notable replay:  ss  1}  [shortstack]          [ss]    -0.075    (0.005)

{txt}Shortstack DDML model
y-E[y|X]{col 11}= {res}y-Y_share_ss_1{txt}{col 52}Number of obs   ={col 70}{res}     2217
{txt}D-E[D|X]{col 11}= {res}D-D_price_ss_1 
{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1}       share{col 14}{c |}      Coef.{col 26}   Std. Err.{col 38}      z{col 46}   P>|z|{col 54}     [95% Con{col 67}f. Interval]
{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 7}price {c |}{col 14}{res}{space 2}-.0752506{col 26}{space 2} .0052847{col 37}{space 1}  -14.24{col 46}{space 3}0.000{col 54}{space 4}-.0856085{col 67}{space 3}-.0648927
{txt}{space 7}_cons {c |}{col 14}{res}{space 2}-.0005764{col 26}{space 2} .0213419{col 37}{space 1}   -0.03{col 46}{space 3}0.978{col 54}{space 4}-.0424057{col 67}{space 3}  .041253
{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
Stacking final estimator: {res}nnls1

{txt}

{pstd}The same {help ddml} tools can be used after {help ddml} or {opt qddml}.
The model estimated by {help ddml} has the default name m0;
the model estimated by {opt qddml} has the name m1.
For example:{p_end}

{input}. ddml extract, mname(m0) show(ssweights)
{res}
{res}short-stacked weights across resamples for price
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
    ols {res}           1            0            0
{txt}lassocv {res}           2            0            0
{txt}ridgecv {res}           3            0            0
{txt}     rf {res}           4            1            1
{txt}     rf {res}           5            0            0
{reset}
{res}short-stacked weights across resamples for share
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
    ols {res}           1    .03038145    .03038145
{txt}lassocv {res}           2    1.015e-16    1.015e-16
{txt}ridgecv {res}           3    .01640807    .01640807
{txt}     rf {res}           4    .95321048    .95321048
{txt}     rf {res}           5            0            0
{reset}{res}{txt}
{input}. ddml extract, mname(m1) show(ssweights)
{res}
{res}short-stacked weights across resamples for price
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
    ols {res}           1            0            0
{txt}lassocv {res}           2            0            0
{txt}ridgecv {res}           3            0            0
{txt}     rf {res}           4            1            1
{txt}     rf {res}           5            0            0
{reset}
{res}short-stacked weights across resamples for share
{res}final stacking estimator: nnls1
{txt}             learner  mean_weight        rep_1
    ols {res}           1    .03038145    .03038145
{txt}lassocv {res}           2    1.015e-16    1.015e-16
{txt}ridgecv {res}           3    .01640807    .01640807
{txt}     rf {res}           4    .95321048    .95321048
{txt}     rf {res}           5            0            0
{reset}{res}{txt}


{smcl}
INCLUDE help ddml_install_ref_auth
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 8 Aug 2023, 12:06:30

Help file: crossfit.sthlp

      {txt}name:  {res}<unnamed>
       {txt}log:  {res}C:\LocalStore\ecomes\Documents\GitHub\ddml\cert\ddml_helpfiles_cert.smcl
  {txt}log type:  {res}smcl
 {txt}closed on:  {res} 8 Aug 2023, 12:06:30
{txt}{.-}
{smcl}
{txt}{sf}{ul off}{smcl}
{txt}{sf}{ul off}{res}{txt}{smcl}
{* *! version 28july2023}{...}
{viewerjumpto "Syntax" "crossfit##syntax"}{...}
{viewerjumpto "Summary" "crossfit##summary"}{...}
{viewerjumpto "Compatible programs" "crossfit##compatibility"}{...}
{viewerjumpto "Examples" "crossfit##examples"}{...}
{viewerjumpto "Saved results" "crossfit##results"}{...}
{viewerjumpto "References" "crossfit##references"}{...}
{viewerjumpto "Authors" "crossfit##authors"}{...}
{vieweralsosee "ddml main page" "ddml"}{...}
{vieweralsosee "ddml crossfit" "ddml crossfit"}{...}
{vieweralsosee "ddml stacking" "ddml stacking"}{...}
{vieweralsosee "Other" "crossfit##also_see"}{...}
{hline}
{cmd:help crossfit}{right: v1.4.1}
{hline}


{title:crossfit - Stata program for cross-fitting}

{pstd}
{opt crossfit} fits a supervised machine learner on K-1 folds
and returns the out-of-sample predicted values for the holdout fold.
This is done iteratively to obtain out-of-sample ("cross-fitted") fitted values for the whole sample.

{pstd}
{opt crossfit} is an auxiliary program that is internally used by 
{help ddml} and {help qddml}, but can be used for other purposes.


{marker syntax}{...}
{title:Syntax}

{p 8 14 2}
{cmd:crossfit} , 
{opt estring(string)}
{opt g:enerate(stubname)}
[{opt kfolds(integer)}
{opt foldvar(varlist)}
{opt norandom}
{opt reps(integer)}
{opt vtype(string)}]

{synoptset 20}{...}
{synopthdr:Option}
{synoptline}
{synopt:{opt estring(string)}}
An estimation string, e.g. "reg y x1 x2", that will be 
repeatedly invoked. See note on compatible programs 
{help ddml##compatibility:here}.
{p_end}
{synopt:{opt g:enerate(stubname)}}
Name of the new variable to be created;
the resample number is appended to the end of the variable name.
Note that if the variable (including the resample number) already exists, it is overwritten.
{p_end}
{synopt:{opt kfolds(integer)}}
Number of randomly drawn folds; ignored if {opt foldvar(varlist)} is specified; default=5.
{p_end}
{synopt:{opt foldvar(varlist)}}
Integer variable(s) with user-specified cross-fitting folds; one foldvar per resample.
{p_end}
{synopt:{opt norandom}}
Use observations in existing order instead of randomizing before splitting into folds;
if multiple resamples, applies to first resample only;
ignored if user-defined fold variables are provided in {opt foldvar(varlist)}.
{p_end}
{synopt:{opt reps(integer)}}
Number of resampling iterations, i.e., how often the cross-fitting procedure is
repeated on randomly generated folds;
ignored if {opt foldvar(varlist)} is specified;
default=1.
{p_end}
{synopt:{opt vtype(string)}}
Variable type of the variable to be created. Defaults to {it:double}. 
{it:none} can be used to leave the type field blank.
{p_end}


{marker summary}{...}
{title:Summary}

{pstd}
{opt crossfit} fits a supervised machine learner on K-1 folds
and returns the out-of-sample predicted values for the holdout fold.
This process is repeated so that each fold serves once as the holdout fold
for which predictions are created.
At the end of the cross-fitting, a full set of predictions is available
in the new variable specified by the {opt generate} option.
The "supervised machine learner" can be any Stata estimator
that supports standard postestimation prediction.
{p_end}

{pstd}
{opt crossfit}'s default is to generate a single random split into folds.
This can be overridden by specifying user-defined fold variables,
or by the {opt norandom} option (indicating that the split use the data in the existing order).
{p_end}

{pstd}
{opt crossfit} allows multiple resampling,
meaning that the procedure is applied repeatedly
using multiple fold variables that indicate different fold splits.
This can be done via the {opt reps} option,
or by providing multiple user-defined fold variables.
The resample number is appended to the generated predictions.
{p_end}

{pstd}
The output of {opt crossfit} can be seen as the intermediate step
of standard K-fold cross-validation.
In a typical cross-validation exercise, a search is conducted across a range of specifications (e.g. values for a tuning parameter).
The prediction errors for the holdout folds are assembled for each specification,
and the specification with the best prediction performance (e.g. smallest mean squared prediction error) is chosen.
A simple example of how to use {opt crossfit} to do this is below.
{p_end}

{pstd}
{opt crossfit} has integrated support for {opt pystacked} (see the help for {help pystacked} if installed).
{help pystacked} is a front-end for the {browse "https://scikit-learn.org/stable/index.html":scikit-learn}
implementation of stacking regression.
Stacking is a way of combining multiple supervised
machine learners (the "base" or "level-0" learners) into
an ensemble or "meta" learner.
When used in conjunction with {opt crossfit}, the predictions of the {help pystacked} base learners
are generated along with the ensemble predicted values.
{p_end}


{marker compatibility}{...}
{title:Compatible programs}

{pstd} 
See {help ddml##compatibility:here}.


{marker examples}{...}
{title:Examples}

{input}. use http://fmwww.bc.edu/repec/bocode/j/jtpa.dta, clear
{txt}
{input}. global X sex age married black hispanic
{txt}
{input}. set seed 42
{txt}

{pstd}Note that the variable created is called yhat_1 because the number of resamples defaults to 1.{p_end}

{input}. crossfit, estring(reg earnings $X) gen(yhat) kfolds(3)
{res}{txt}Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. sum earnings yhat_1

{txt}    Variable {c |}        Obs        Mean    Std. Dev.       Min        Max
{hline 13}{c +}{hline 57}
{space 4}earnings {c |}{res}     11,204    15815.29    16767.05          0     155760
{txt}{space 6}yhat_1 {c |}{res}     11,204     15812.1    3774.255   6123.432   23867.51
{txt}

{pstd}As above but using 5 resamples.{p_end}

{input}. crossfit, estring(reg earnings $X) gen(yhat) kfolds(3) reps(5)
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. sum earnings yhat*

{txt}    Variable {c |}        Obs        Mean    Std. Dev.       Min        Max
{hline 13}{c +}{hline 57}
{space 4}earnings {c |}{res}     11,204    15815.29    16767.05          0     155760
{txt}{space 6}yhat_1 {c |}{res}     11,204    15817.76    3772.003   5660.687   24048.23
{txt}{space 6}yhat_2 {c |}{res}     11,204    15811.39    3776.824   5764.323   24005.49
{txt}{space 6}yhat_3 {c |}{res}     11,204    15818.01    3777.579   5495.782      24012
{txt}{space 6}yhat_4 {c |}{res}     11,204    15811.81    3777.137   5751.744   23775.22
{txt}{hline 13}{c +}{hline 57}
{space 6}yhat_5 {c |}{res}     11,204    15817.15     3777.96    6044.12   23928.68
{txt}

{pstd}As above but using {help pystacked}.
The default base learners are OLS, CV-lasso and gradient boosting.{p_end}

{input}. crossfit, estring(pystacked earnings $X) gen(yhat) kfolds(3) reps(5)
{res}{txt}calling pystacked on full sample with noestimate option...
N={res}11204
{txt}number of learners = {res}3
{txt}Base learners: {res}ols lassocv gradboost 
{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. sum earnings yhat*

{txt}    Variable {c |}        Obs        Mean    Std. Dev.       Min        Max
{hline 13}{c +}{hline 57}
{space 4}earnings {c |}{res}     11,204    15815.29    16767.05          0     155760
{txt}{space 3}yhat_L1_1 {c |}{res}     11,204    15814.67    3771.158   6154.772   23792.97
{txt}{space 3}yhat_L2_1 {c |}{res}     11,204    15814.67    3765.064   6180.004   23777.85
{txt}{space 3}yhat_L3_1 {c |}{res}     11,204    15816.24    4484.243   1665.902   28229.47
{txt}{space 6}yhat_1 {c |}{res}     11,204    15816.52    4153.282   3465.912   26655.86
{txt}{hline 13}{c +}{hline 57}
{space 3}yhat_L1_2 {c |}{res}     11,204    15814.28     3773.44   5357.084   23895.38
{txt}{space 3}yhat_L2_2 {c |}{res}     11,204    15814.28    3767.491   5381.269   23879.07
{txt}{space 3}yhat_L3_2 {c |}{res}     11,204    15813.21    4482.175  -3728.535   29254.65
{txt}{space 6}yhat_2 {c |}{res}     11,204    15812.08    4174.833  -723.8463   26819.96
{txt}{space 3}yhat_L1_3 {c |}{res}     11,204    15816.28    3782.185   5912.759    23893.9
{txt}{hline 13}{c +}{hline 57}
{space 3}yhat_L2_3 {c |}{res}     11,204     15816.3    3774.708   5960.517   23865.76
{txt}{space 3}yhat_L3_3 {c |}{res}     11,204     15817.7    4492.836   1363.014   34460.92
{txt}{space 6}yhat_3 {c |}{res}     11,204    15817.88    4204.399    3435.11   31379.16
{txt}{space 3}yhat_L1_4 {c |}{res}     11,204    15815.53     3776.09   5301.554      24088
{txt}{space 3}yhat_L2_4 {c |}{res}     11,204    15815.53    3770.267   5327.434   24072.52
{txt}{hline 13}{c +}{hline 57}
{space 3}yhat_L3_4 {c |}{res}     11,204    15821.58     4484.34  -1822.032   31067.63
{txt}{space 6}yhat_4 {c |}{res}     11,204     15819.3    4158.618   1107.619   28814.61
{txt}{space 3}yhat_L1_5 {c |}{res}     11,204    15816.62    3781.457   6159.217   23814.33
{txt}{space 3}yhat_L2_5 {c |}{res}     11,204    15816.62    3775.649   6184.389   23798.95
{txt}{space 3}yhat_L3_5 {c |}{res}     11,204    15804.12    4469.694   818.7079    29594.9
{txt}{hline 13}{c +}{hline 57}
{space 6}yhat_5 {c |}{res}     11,204    15806.92    4184.636   2429.249   27209.38
{txt}

{pstd}A simple example of 3-fold cross-validation with 5 resamples using {opt crossfit}.
{input}. ssc install lassopack
{txt}checking {hilite:lassopack} consistency and verifying not already installed...
{smcl}
installing into C:\LocalStore\ecomes\ado\plus\...
installation complete.
{txt}
We estimate using the following values of the lambda parameter: 2000, 1000, 500, 250.
Each time we call {opt crossfit} to obtain the predicted values.
These could be used after cross-fitting to calculate the MSPE (mean squared prediction error),
but the MSPE is one of the returned results of {opt crossfit} so we just report that.
The specification that minimizes the MSPE for all 5 resamples is lambda=250.
{p_end}

{input}. crossfit, estring(lasso2 earnings $X, lglmnet lambda(2000)) gen(yhat2000) kfolds(3) reps(5)
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. mat list r(mse_list)
{res}
{txt}r(mse_list)[5,1]
                   c1
resample_1 {res} 2.758e+08
{txt}resample_2 {res} 2.759e+08
{txt}resample_3 {res} 2.759e+08
{txt}resample_4 {res} 2.759e+08
{txt}resample_5 {res} 2.758e+08
{reset}{txt}
{input}. crossfit, estring(lasso2 earnings $X, lglmnet lambda(1000)) gen(yhat1000) kfolds(3) reps(5)
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. mat list r(mse_list)
{res}
{txt}r(mse_list)[5,1]
                   c1
resample_1 {res} 2.710e+08
{txt}resample_2 {res} 2.710e+08
{txt}resample_3 {res} 2.709e+08
{txt}resample_4 {res} 2.710e+08
{txt}resample_5 {res} 2.709e+08
{reset}{txt}
{input}. crossfit, estring(lasso2 earnings $X, lglmnet lambda(500)) gen(yhat500) kfolds(3) reps(5)
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. mat list r(mse_list)
{res}
{txt}r(mse_list)[5,1]
                   c1
resample_1 {res} 2.684e+08
{txt}resample_2 {res} 2.686e+08
{txt}resample_3 {res} 2.686e+08
{txt}resample_4 {res} 2.685e+08
{txt}resample_5 {res} 2.684e+08
{reset}{txt}
{input}. crossfit, estring(lasso2 earnings $X, lglmnet lambda(250)) gen(yhat250) kfolds(3) reps(5)
{res}{txt}Resample 1...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 2...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 3...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 4...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}Resample 5...
Cross-fitting fold 1 {res}{txt}2 {res}{txt}3 {res}{txt}...completed cross-fitting
{res}{txt}
{input}. mat list r(mse_list)
{res}
{txt}r(mse_list)[5,1]
                   c1
resample_1 {res} 2.675e+08
{txt}resample_2 {res} 2.676e+08
{txt}resample_3 {res} 2.679e+08
{txt}resample_4 {res} 2.676e+08
{txt}resample_5 {res} 2.673e+08
{reset}{txt}

{pstd}When used as a standalone program, {opt crossfit} leaves behind in Mata a eStruct ("equation struct") called "crossfit".
This object contains information about the estimation, stored on associative arrays.
The utility {help ddml extract} can be used to extract this information.
The example below shows how to list the AA keys
and how to extract the {help pystacked} stacking weights for resample 2.
Rows are base learners; columns are the weights for each learner.{p_end}

{input}. mata: mata desc crossfit

      {txt}# bytes   type                        name and extent
{hline 79}
{res}            8   {txt}struct scalar               {res}crossfit
{txt}{hline 79}
{txt}
{input}. ddml extract, ename(crossfit) keys
{res}{txt}AA keys for eqn crossfit.lrnAA:
                  1             2
     {c TLC}{hline 29}{c TRC}
   1 {c |}  {res}        opt             1{txt}  {c |}
   2 {c |}  {res}        opt             2{txt}  {c |}
   3 {c |}  {res}        opt             3{txt}  {c |}
   4 {c |}  {res}        opt             4{txt}  {c |}
   5 {c |}  {res}        opt             5{txt}  {c |}
   6 {c |}  {res}    yhat250      est_main{txt}  {c |}
   7 {c |}  {res}    yhat250   est_options{txt}  {c |}
   8 {c |}  {res}    yhat250       estring{txt}  {c |}
   9 {c |}  {res}    yhat250       predopt{txt}  {c |}
  10 {c |}  {res}    yhat250         vtype{txt}  {c |}
     {c BLC}{hline 29}{c BRC}
{txt}AA keys for eqn crossfit.resAA:
                1           2           3
     {c TLC}{hline 37}{c TRC}
   1 {c |}  {res}  yhat250         MSE           1{txt}  {c |}
   2 {c |}  {res}  yhat250         MSE           2{txt}  {c |}
   3 {c |}  {res}  yhat250         MSE           3{txt}  {c |}
   4 {c |}  {res}  yhat250         MSE           4{txt}  {c |}
   5 {c |}  {res}  yhat250         MSE           5{txt}  {c |}
   6 {c |}  {res}  yhat250   MSE_folds           1{txt}  {c |}
   7 {c |}  {res}  yhat250   MSE_folds           2{txt}  {c |}
   8 {c |}  {res}  yhat250   MSE_folds           3{txt}  {c |}
   9 {c |}  {res}  yhat250   MSE_folds           4{txt}  {c |}
  10 {c |}  {res}  yhat250   MSE_folds           5{txt}  {c |}
  11 {c |}  {res}  yhat250           N           1{txt}  {c |}
  12 {c |}  {res}  yhat250           N           2{txt}  {c |}
  13 {c |}  {res}  yhat250           N           3{txt}  {c |}
  14 {c |}  {res}  yhat250           N           4{txt}  {c |}
  15 {c |}  {res}  yhat250           N           5{txt}  {c |}
  16 {c |}  {res}  yhat250     N_folds           1{txt}  {c |}
  17 {c |}  {res}  yhat250     N_folds           2{txt}  {c |}
  18 {c |}  {res}  yhat250     N_folds           3{txt}  {c |}
  19 {c |}  {res}  yhat250     N_folds           4{txt}  {c |}
  20 {c |}  {res}  yhat250     N_folds           5{txt}  {c |}
     {c BLC}{hline 37}{c BRC}
{res}{txt}
{input}. ddml extract, ename(crossfit) key1(yhat) key2(stack_base_est)
{res}  0x0
{txt}
{input}. ddml extract, ename(crossfit) key1(yhat) key2(stack_weights) key3(2)
{res}  0x0
{txt}


{marker results}{title:Saved results}

{p}{opt crossfit} saves the following results in {cmd:r()}:

Scalars
{col 4}{opt r(N)}{col 25}Number of observations.
{col 4}{opt r(mse)}{col 25}Mean squared prediction error in the last resample.

Macros
{col 4}{opt r(cmd_list)}{col 25}Estimation command

Matrices
{col 4}{opt r(N_list)}{col 25}Sample size; rows are resamples.
{col 4}{opt r(mse_list)}{col 25}MSPE; rows are resamples.
{col 4}{opt r(N_folds_list)}{col 25}Sample size by fold; rows are resamples.
{col 4}{opt r(mse_folds_list)}{col 25}MSPE by fold; rows are resamples.


{marker references}{title:References}

{phang}
Ahrens, A., Hansen, C.B. and M.E. Schaffer. 2020.
lassopack: model selection and prediction with regularized regression in Stata.
{it:The Stata Journal}, 20(1):176-235.
{browse "https://journals.sagepub.com/doi/abs/10.1177/1536867X20909697"}.
Working paper version: {browse "https://arxiv.org/abs/1901.05397"}.{p_end}

{phang}
Chernozhukov, V., Chetverikov, D., Demirer, M., 
Duflo, E., Hansen, C., Newey, W. and Robins, J. (2018), 
Double/debiased machine learning for 
treatment and structural parameters. 
{it:The Econometrics Journal}, 21: C1-C68. {browse "https://doi.org/10.1111/ectj.12097"}


{marker authors}{title:Authors}

{pstd}
Achim Ahrens, Public Policy Group, ETH Zurich, Switzerland  {break}
achim.ahrens@gess.ethz.ch

{pstd}
Christian B. Hansen, University of Chicago, USA {break}
Christian.Hansen@chicagobooth.edu

{pstd}
Mark E Schaffer, Heriot-Watt University, UK {break}
m.e.schaffer@hw.ac.uk   

{pstd}
Thomas Wiemann, University of Chicago, USA {break}
wiemann@uchicago.edu


{title:Also see (if installed)}

{pstd}
Help: {help ddml}, {help qddml}, {help pystacked}, {help lasso2}, {help cvlasso}.{p_end}
{smcl}
{txt}{sf}{ul off}